{
  "base_model": {
    "accuracy_mean": 0.5,
    "accuracy_std": 0.0002448999942794808,
    "macro_f1_mean": 0.3333333688746723,
    "macro_f1_std": 0.00027211109721144377,
    "mcc_mean": 0.0,
    "mcc_std": 0.0,
    "confusion_matrix": [
      [
        0,
        833
      ],
      [
        0,
        833
      ]
    ],
    "roc_curve": {
      "fpr": [
        0.0,
        0.0012004801920768306,
        0.11404561824729892,
        0.11404561824729892,
        0.11884753901560624,
        0.11884753901560624,
        0.12605042016806722,
        0.12605042016806722,
        0.12725090036014405,
        0.12725090036014405,
        0.12845138055222088,
        0.12845138055222088,
        0.12965186074429771,
        0.12965186074429771,
        0.13085234093637454,
        0.13085234093637454,
        0.1332533013205282,
        0.1332533013205282,
        0.13445378151260504,
        0.13445378151260504,
        0.13565426170468187,
        0.13565426170468187,
        0.13805522208883553,
        0.13805522208883553,
        0.1404561824729892,
        0.1404561824729892,
        0.14405762304921968,
        0.14405762304921968,
        0.1452581032412965,
        0.1452581032412965,
        0.14645858343337334,
        0.14645858343337334,
        0.14765906362545017,
        0.14765906362545017,
        0.148859543817527,
        0.148859543817527,
        0.1524609843937575,
        0.1524609843937575,
        0.15366146458583432,
        0.15366146458583432,
        0.15486194477791115,
        0.15486194477791115,
        0.15606242496998798,
        0.15606242496998798,
        0.15726290516206481,
        0.15726290516206481,
        0.15846338535414164,
        0.15846338535414164,
        0.1608643457382953,
        0.1608643457382953,
        0.16206482593037214,
        0.16206482593037214,
        0.1644657863145258,
        0.1644657863145258,
        0.16686674669867949,
        0.16686674669867949,
        0.16806722689075632,
        0.16806722689075632,
        0.16926770708283315,
        0.16926770708283315,
        0.17046818727490998,
        0.17046818727490998,
        0.1716686674669868,
        0.1716686674669868,
        0.17286914765906364,
        0.17286914765906364,
        0.17406962785114047,
        0.17406962785114047,
        0.1752701080432173,
        0.1752701080432173,
        0.1788715486194478,
        0.1788715486194478,
        0.18007202881152462,
        0.18007202881152462,
        0.1836734693877551,
        0.1836734693877551,
        0.18487394957983194,
        0.18487394957983194,
        0.18847539015606243,
        0.18847539015606243,
        0.18967587034813926,
        0.18967587034813926,
        0.1908763505402161,
        0.1908763505402161,
        0.19207683073229292,
        0.19207683073229292,
        0.19327731092436976,
        0.19327731092436976,
        0.19447779111644659,
        0.19447779111644659,
        0.1992797118847539,
        0.1992797118847539,
        0.2064825930372149,
        0.2064825930372149,
        0.20888355342136855,
        0.21368547418967587,
        0.21368547418967587,
        0.2148859543817527,
        0.2148859543817527,
        0.21968787515006002,
        0.21968787515006002,
        0.22088835534213686,
        0.22088835534213686,
        0.22208883553421369,
        0.22208883553421369,
        0.22448979591836735,
        0.22448979591836735,
        0.22809123649459784,
        0.22809123649459784,
        0.22929171668667467,
        0.22929171668667467,
        0.2304921968787515,
        0.2304921968787515,
        0.23169267707082833,
        0.23169267707082833,
        0.234093637454982,
        0.234093637454982,
        0.2388955582232893,
        0.2388955582232893,
        0.24129651860744297,
        0.24129651860744297,
        0.2424969987995198,
        0.2424969987995198,
        0.24369747899159663,
        0.24369747899159663,
        0.24729891956782712,
        0.24729891956782712,
        0.24969987995198079,
        0.24969987995198079,
        0.25090036014405764,
        0.25090036014405764,
        0.25570228091236497,
        0.25570228091236497,
        0.2605042016806723,
        0.2605042016806723,
        0.2617046818727491,
        0.2617046818727491,
        0.2665066026410564,
        0.2665066026410564,
        0.27010804321728693,
        0.27010804321728693,
        0.27130852340936373,
        0.27130852340936373,
        0.2737094837935174,
        0.2737094837935174,
        0.2773109243697479,
        0.2773109243697479,
        0.2785114045618247,
        0.2785114045618247,
        0.2809123649459784,
        0.2809123649459784,
        0.28211284513805523,
        0.28211284513805523,
        0.2845138055222089,
        0.2845138055222089,
        0.2857142857142857,
        0.2857142857142857,
        0.290516206482593,
        0.290516206482593,
        0.290516206482593,
        0.2917166866746699,
        0.2917166866746699,
        0.29411764705882354,
        0.29411764705882354,
        0.29531812725090034,
        0.297719087635054,
        0.29891956782713086,
        0.29891956782713086,
        0.3013205282112845,
        0.30732292917166865,
        0.30732292917166865,
        0.3097238895558223,
        0.31092436974789917,
        0.31092436974789917,
        0.31212484993997597,
        0.31452581032412963,
        0.3169267707082833,
        0.3169267707082833,
        0.3277310924369748,
        0.33013205282112845,
        0.33133253301320525,
        0.33133253301320525,
        0.33373349339735897,
        0.33613445378151263,
        0.33613445378151263,
        0.34093637454981995,
        0.34213685474189676,
        0.34213685474189676,
        0.3433373349339736,
        0.3433373349339736,
        0.3445378151260504,
        0.3445378151260504,
        0.3469387755102041,
        0.3469387755102041,
        0.34813925570228094,
        0.34813925570228094,
        0.3517406962785114,
        0.3565426170468187,
        0.3589435774309724,
        0.3589435774309724,
        0.368547418967587,
        0.368547418967587,
        0.37815126050420167,
        0.3793517406962785,
        0.38055222088835533,
        0.3817527010804322,
        0.38535414165666265,
        0.38535414165666265,
        0.3865546218487395,
        0.3865546218487395,
        0.39015606242497,
        0.39255702280912363,
        0.39615846338535415,
        0.39615846338535415,
        0.4069627851140456,
        0.40936374549819926,
        0.40936374549819926,
        0.4177671068427371,
        0.4177671068427371,
        0.42016806722689076,
        0.4249699879951981,
        0.4249699879951981,
        0.43217286914765907,
        0.4345738295318127,
        0.44057623049219685,
        0.4429771908763505,
        0.4477791116446579,
        0.4477791116446579,
        0.4525810324129652,
        0.4525810324129652,
        0.453781512605042,
        0.453781512605042,
        0.4561824729891957,
        0.4561824729891957,
        0.4669867947178872,
        0.46938775510204084,
        0.4717887154861945,
        0.47418967587034816,
        0.47539015606242496,
        0.47539015606242496,
        0.503001200480192,
        0.5042016806722689,
        0.5102040816326531,
        0.5102040816326531,
        0.5114045618247299,
        0.5162064825930373,
        0.524609843937575,
        0.5270108043217286,
        0.5306122448979592,
        0.5354141656662665,
        0.5366146458583433,
        0.5366146458583433,
        0.5414165666266506,
        0.5438175270108043,
        0.5558223289315727,
        0.5558223289315727,
        0.5582232893157263,
        0.5594237695078031,
        0.5642256902761105,
        0.5654261704681873,
        0.5702280912364946,
        0.5726290516206483,
        0.5726290516206483,
        0.575030012004802,
        0.575030012004802,
        0.5798319327731093,
        0.581032412965186,
        0.5894357743097239,
        0.5918367346938775,
        0.5930372148859544,
        0.5930372148859544,
        0.602641056422569,
        0.6038415366146459,
        0.6062424969987995,
        0.6218487394957983,
        0.6242496998799519,
        0.6242496998799519,
        0.6326530612244898,
        0.6362545018007203,
        0.6410564225690276,
        0.6434573829531812,
        0.6494597839135654,
        0.6518607442977191,
        0.6566626650660264,
        0.6566626650660264,
        0.65906362545018,
        0.6602641056422569,
        0.6650660264105642,
        0.6674669867947179,
        0.6722689075630253,
        0.6746698679471789,
        0.6830732292917167,
        0.6830732292917167,
        0.6914765906362546,
        0.6938775510204082,
        0.6962785114045619,
        0.6986794717887155,
        0.7022809123649459,
        0.7046818727490997,
        0.7058823529411765,
        0.7082833133253301,
        0.7118847539015606,
        0.7118847539015606,
        0.7154861944777912,
        0.7154861944777912,
        0.7202881152460985,
        0.7202881152460985,
        0.723889555822329,
        0.7262905162064826,
        0.7274909963985594,
        0.7274909963985594,
        0.7334933973589436,
        0.7358943577430972,
        0.737094837935174,
        0.7394957983193278,
        0.7394957983193278,
        0.7527010804321729,
        0.7527010804321729,
        0.7623049219687875,
        0.7647058823529411,
        0.7743097238895558,
        0.7767106842737095,
        0.7791116446578632,
        0.7791116446578632,
        0.7839135654261705,
        0.7863145258103241,
        0.7887154861944778,
        0.7887154861944778,
        0.7899159663865546,
        0.7923169267707083,
        0.7959183673469388,
        0.7983193277310925,
        0.7983193277310925,
        0.8067226890756303,
        0.8067226890756303,
        0.8079231692677071,
        0.8079231692677071,
        0.8139255702280912,
        0.8139255702280912,
        0.8163265306122449,
        0.8187274909963985,
        0.8199279711884754,
        0.8223289315726291,
        0.8235294117647058,
        0.8235294117647058,
        0.8343337334933973,
        0.8367346938775511,
        0.8475390156062425,
        0.8487394957983193,
        0.8499399759903962,
        0.8499399759903962,
        0.8523409363745498,
        0.8547418967587035,
        0.8547418967587035,
        0.8703481392557023,
        0.8703481392557023,
        0.8727490996398559,
        0.8751500600240096,
        0.8751500600240096,
        0.8775510204081632,
        0.8775510204081632,
        0.879951980792317,
        0.8823529411764706,
        0.8823529411764706,
        0.8835534213685474,
        0.8835534213685474,
        0.8883553421368547,
        0.8883553421368547,
        0.8919567827130852,
        0.8931572629051621,
        0.9051620648259304,
        0.9051620648259304,
        0.9099639855942377,
        0.9099639855942377,
        0.9111644657863145,
        0.9111644657863145,
        0.9123649459783914,
        0.9123649459783914,
        0.9135654261704682,
        0.9147659063625451,
        0.9147659063625451,
        0.9159663865546218,
        0.9159663865546218,
        0.9171668667466987,
        0.9171668667466987,
        0.9195678271308524,
        0.9195678271308524,
        0.9279711884753902,
        0.9279711884753902,
        0.929171668667467,
        0.929171668667467,
        0.9303721488595438,
        0.9303721488595438,
        0.936374549819928,
        0.936374549819928,
        0.936374549819928,
        0.9375750300120048,
        0.9375750300120048,
        0.9423769507803121,
        0.9423769507803121,
        0.9459783913565426,
        0.9459783913565426,
        0.9471788715486195,
        0.9471788715486195,
        0.9483793517406963,
        0.9483793517406963,
        0.9495798319327731,
        0.9507803121248499,
        0.9531812725090036,
        0.9531812725090036,
        0.9531812725090036,
        0.9543817527010804,
        0.9543817527010804,
        0.9555822328931572,
        0.9555822328931572,
        0.9591836734693877,
        0.9591836734693877,
        0.9603841536614646,
        0.9603841536614646,
        0.9615846338535414,
        0.9615846338535414,
        0.9615846338535414,
        0.9627851140456183,
        0.9627851140456183,
        0.9651860744297719,
        0.9651860744297719,
        0.9651860744297719,
        0.9651860744297719,
        0.9663865546218487,
        0.9663865546218487,
        0.9675870348139256,
        0.9675870348139256,
        0.9687875150060024,
        0.9699879951980792,
        0.9699879951980792,
        0.9711884753901561,
        0.9711884753901561,
        0.9723889555822329,
        0.9723889555822329,
        0.9735894357743097,
        0.9735894357743097,
        0.9747899159663865,
        0.9747899159663865,
        0.9759903961584634,
        0.9759903961584634,
        0.9771908763505402,
        0.9771908763505402,
        0.978391356542617,
        0.978391356542617,
        0.9795918367346939,
        0.9795918367346939,
        0.9807923169267707,
        0.9807923169267707,
        0.9819927971188476,
        0.9819927971188476,
        0.9831932773109243,
        0.9831932773109243,
        0.9843937575030012,
        0.9843937575030012,
        0.985594237695078,
        0.985594237695078,
        0.9867947178871549,
        0.9867947178871549,
        0.9879951980792316,
        0.9879951980792316,
        0.9891956782713085,
        0.9891956782713085,
        0.9903961584633854,
        0.9903961584633854,
        0.9903961584633854,
        0.9903961584633854,
        0.9915966386554622,
        0.9915966386554622,
        0.992797118847539,
        0.992797118847539,
        0.9939975990396158,
        0.9939975990396158,
        0.9951980792316927,
        0.9987995198079231,
        0.9987995198079231,
        0.9987995198079231,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0
      ],
      "tpr": [
        0.0,
        0.0,
        0.0,
        0.0012004801920768306,
        0.0012004801920768306,
        0.0024009603841536613,
        0.0024009603841536613,
        0.006002400960384154,
        0.006002400960384154,
        0.007202881152460984,
        0.007202881152460984,
        0.008403361344537815,
        0.008403361344537815,
        0.009603841536614645,
        0.009603841536614645,
        0.013205282112845138,
        0.013205282112845138,
        0.015606242496998799,
        0.015606242496998799,
        0.026410564225690276,
        0.026410564225690276,
        0.028811524609843937,
        0.028811524609843937,
        0.031212484993997598,
        0.031212484993997598,
        0.03241296518607443,
        0.03241296518607443,
        0.03361344537815126,
        0.03361344537815126,
        0.03601440576230492,
        0.03601440576230492,
        0.03841536614645858,
        0.03841536614645858,
        0.04081632653061224,
        0.04081632653061224,
        0.04441776710684274,
        0.04441776710684274,
        0.04561824729891957,
        0.0468187274909964,
        0.04921968787515006,
        0.04921968787515006,
        0.05282112845138055,
        0.05282112845138055,
        0.055222088835534214,
        0.055222088835534214,
        0.056422569027611044,
        0.056422569027611044,
        0.057623049219687875,
        0.057623049219687875,
        0.061224489795918366,
        0.061224489795918366,
        0.062424969987995196,
        0.062424969987995196,
        0.06962785114045618,
        0.06962785114045618,
        0.0744297719087635,
        0.0744297719087635,
        0.07923169267707082,
        0.07923169267707082,
        0.08283313325330131,
        0.08283313325330131,
        0.08523409363745499,
        0.08523409363745499,
        0.08763505402160865,
        0.08763505402160865,
        0.09003601440576231,
        0.09003601440576231,
        0.09243697478991597,
        0.09243697478991597,
        0.09603841536614646,
        0.09603841536614646,
        0.10084033613445378,
        0.10084033613445378,
        0.10324129651860744,
        0.10324129651860744,
        0.1056422569027611,
        0.10684273709483794,
        0.10804321728691477,
        0.10804321728691477,
        0.11044417767106843,
        0.11044417767106843,
        0.11284513805522209,
        0.11284513805522209,
        0.11404561824729892,
        0.11404561824729892,
        0.11524609843937575,
        0.11524609843937575,
        0.11764705882352941,
        0.11764705882352941,
        0.1212484993997599,
        0.1212484993997599,
        0.12364945978391356,
        0.12364945978391356,
        0.12484993997599039,
        0.12484993997599039,
        0.12484993997599039,
        0.12605042016806722,
        0.12605042016806722,
        0.12965186074429771,
        0.12965186074429771,
        0.13085234093637454,
        0.13085234093637454,
        0.13445378151260504,
        0.13445378151260504,
        0.13565426170468187,
        0.13565426170468187,
        0.1368547418967587,
        0.1368547418967587,
        0.13925570228091236,
        0.13925570228091236,
        0.1404561824729892,
        0.1404561824729892,
        0.14165666266506602,
        0.14165666266506602,
        0.14285714285714285,
        0.14285714285714285,
        0.14405762304921968,
        0.14405762304921968,
        0.14645858343337334,
        0.14645858343337334,
        0.14765906362545017,
        0.14765906362545017,
        0.148859543817527,
        0.148859543817527,
        0.15126050420168066,
        0.15126050420168066,
        0.15486194477791115,
        0.15486194477791115,
        0.15726290516206481,
        0.15726290516206481,
        0.15846338535414164,
        0.15846338535414164,
        0.15966386554621848,
        0.15966386554621848,
        0.1608643457382953,
        0.1608643457382953,
        0.16326530612244897,
        0.16326530612244897,
        0.1644657863145258,
        0.1644657863145258,
        0.16566626650660263,
        0.16566626650660263,
        0.16686674669867949,
        0.16686674669867949,
        0.16806722689075632,
        0.16806722689075632,
        0.17046818727490998,
        0.17046818727490998,
        0.1716686674669868,
        0.1716686674669868,
        0.17286914765906364,
        0.17286914765906364,
        0.1752701080432173,
        0.1752701080432173,
        0.17767106842737096,
        0.17767106842737096,
        0.1788715486194478,
        0.1788715486194478,
        0.18127250900360145,
        0.18247298919567828,
        0.18247298919567828,
        0.1836734693877551,
        0.1836734693877551,
        0.18487394957983194,
        0.18487394957983194,
        0.18487394957983194,
        0.18487394957983194,
        0.18607442977190877,
        0.18607442977190877,
        0.18607442977190877,
        0.18847539015606243,
        0.18847539015606243,
        0.18967587034813926,
        0.19207683073229292,
        0.19207683073229292,
        0.19207683073229292,
        0.19207683073229292,
        0.19327731092436976,
        0.19327731092436976,
        0.19327731092436976,
        0.19327731092436976,
        0.19447779111644659,
        0.19447779111644659,
        0.19447779111644659,
        0.19567827130852342,
        0.19567827130852342,
        0.19687875150060025,
        0.1992797118847539,
        0.1992797118847539,
        0.2028811524609844,
        0.2028811524609844,
        0.20528211284513806,
        0.20528211284513806,
        0.2064825930372149,
        0.2064825930372149,
        0.20888355342136855,
        0.20888355342136855,
        0.20888355342136855,
        0.20888355342136855,
        0.21008403361344538,
        0.21008403361344538,
        0.21248499399759904,
        0.21248499399759904,
        0.21368547418967587,
        0.21368547418967587,
        0.2148859543817527,
        0.2148859543817527,
        0.21728691476590636,
        0.21728691476590636,
        0.2184873949579832,
        0.2184873949579832,
        0.2184873949579832,
        0.2184873949579832,
        0.21968787515006002,
        0.21968787515006002,
        0.21968787515006002,
        0.22088835534213686,
        0.22088835534213686,
        0.22208883553421369,
        0.22208883553421369,
        0.22208883553421369,
        0.22328931572629052,
        0.22328931572629052,
        0.22328931572629052,
        0.22328931572629052,
        0.22328931572629052,
        0.22328931572629052,
        0.22448979591836735,
        0.22448979591836735,
        0.22569027611044418,
        0.22569027611044418,
        0.22809123649459784,
        0.22809123649459784,
        0.22929171668667467,
        0.22929171668667467,
        0.22929171668667467,
        0.22929171668667467,
        0.22929171668667467,
        0.22929171668667467,
        0.2304921968787515,
        0.2304921968787515,
        0.23169267707082833,
        0.23169267707082833,
        0.23289315726290516,
        0.23289315726290516,
        0.23289315726290516,
        0.23289315726290516,
        0.23289315726290516,
        0.23289315726290516,
        0.23289315726290516,
        0.23289315726290516,
        0.234093637454982,
        0.234093637454982,
        0.234093637454982,
        0.234093637454982,
        0.23529411764705882,
        0.23529411764705882,
        0.23649459783913565,
        0.23649459783913565,
        0.23769507803121248,
        0.23769507803121248,
        0.23769507803121248,
        0.2388955582232893,
        0.2388955582232893,
        0.24009603841536614,
        0.24009603841536614,
        0.24129651860744297,
        0.24129651860744297,
        0.24129651860744297,
        0.24129651860744297,
        0.2424969987995198,
        0.2424969987995198,
        0.24369747899159663,
        0.24369747899159663,
        0.24369747899159663,
        0.24369747899159663,
        0.24489795918367346,
        0.24489795918367346,
        0.24489795918367346,
        0.24489795918367346,
        0.24489795918367346,
        0.24489795918367346,
        0.24489795918367346,
        0.24489795918367346,
        0.2460984393757503,
        0.2460984393757503,
        0.24729891956782712,
        0.24729891956782712,
        0.24729891956782712,
        0.24729891956782712,
        0.24729891956782712,
        0.24729891956782712,
        0.24849939975990396,
        0.24849939975990396,
        0.24849939975990396,
        0.24849939975990396,
        0.24849939975990396,
        0.24849939975990396,
        0.24849939975990396,
        0.24849939975990396,
        0.24849939975990396,
        0.24849939975990396,
        0.24969987995198079,
        0.24969987995198079,
        0.25090036014405764,
        0.25090036014405764,
        0.25210084033613445,
        0.25210084033613445,
        0.25210084033613445,
        0.25210084033613445,
        0.2533013205282113,
        0.2533013205282113,
        0.2533013205282113,
        0.2545018007202881,
        0.2545018007202881,
        0.25570228091236497,
        0.25570228091236497,
        0.25690276110444177,
        0.25690276110444177,
        0.25690276110444177,
        0.25690276110444177,
        0.25690276110444177,
        0.25690276110444177,
        0.2581032412965186,
        0.2581032412965186,
        0.2581032412965186,
        0.2581032412965186,
        0.25930372148859543,
        0.2605042016806723,
        0.2605042016806723,
        0.2605042016806723,
        0.2605042016806723,
        0.2617046818727491,
        0.2617046818727491,
        0.26290516206482595,
        0.26290516206482595,
        0.26410564225690275,
        0.26410564225690275,
        0.2653061224489796,
        0.2653061224489796,
        0.2653061224489796,
        0.2653061224489796,
        0.2653061224489796,
        0.2653061224489796,
        0.2665066026410564,
        0.2665066026410564,
        0.2665066026410564,
        0.2665066026410564,
        0.26770708283313327,
        0.26770708283313327,
        0.27010804321728693,
        0.27010804321728693,
        0.27010804321728693,
        0.2725090036014406,
        0.2725090036014406,
        0.2737094837935174,
        0.2737094837935174,
        0.2737094837935174,
        0.27490996398559425,
        0.27490996398559425,
        0.27611044417767105,
        0.27611044417767105,
        0.27611044417767105,
        0.2785114045618247,
        0.2785114045618247,
        0.2797118847539016,
        0.2797118847539016,
        0.2809123649459784,
        0.2809123649459784,
        0.28211284513805523,
        0.28211284513805523,
        0.28331332533013204,
        0.28331332533013204,
        0.2857142857142857,
        0.2857142857142857,
        0.2917166866746699,
        0.2917166866746699,
        0.29411764705882354,
        0.29411764705882354,
        0.29531812725090034,
        0.297719087635054,
        0.297719087635054,
        0.29891956782713086,
        0.29891956782713086,
        0.30012004801920766,
        0.30012004801920766,
        0.3013205282112845,
        0.3013205282112845,
        0.3025210084033613,
        0.3025210084033613,
        0.3037214885954382,
        0.3037214885954382,
        0.30612244897959184,
        0.30612244897959184,
        0.30732292917166865,
        0.3097238895558223,
        0.3097238895558223,
        0.31092436974789917,
        0.31092436974789917,
        0.31452581032412963,
        0.31452581032412963,
        0.3157262905162065,
        0.3157262905162065,
        0.31812725090036015,
        0.31812725090036015,
        0.32653061224489793,
        0.32653061224489793,
        0.3277310924369748,
        0.3277310924369748,
        0.3325330132052821,
        0.3349339735894358,
        0.3349339735894358,
        0.33733493397358943,
        0.33733493397358943,
        0.34813925570228094,
        0.34813925570228094,
        0.3553421368547419,
        0.3553421368547419,
        0.3589435774309724,
        0.3589435774309724,
        0.36134453781512604,
        0.3637454981992797,
        0.36494597839135656,
        0.3673469387755102,
        0.3673469387755102,
        0.368547418967587,
        0.3709483793517407,
        0.37695078031212487,
        0.37695078031212487,
        0.3817527010804322,
        0.3817527010804322,
        0.382953181272509,
        0.382953181272509,
        0.38415366146458585,
        0.3865546218487395,
        0.3865546218487395,
        0.38895558223289317,
        0.38895558223289317,
        0.39015606242497,
        0.39015606242497,
        0.39135654261704683,
        0.39135654261704683,
        0.3937575030012005,
        0.3937575030012005,
        0.3949579831932773,
        0.3949579831932773,
        0.3985594237695078,
        0.3985594237695078,
        0.4009603841536615,
        0.4009603841536615,
        0.40816326530612246,
        0.40816326530612246,
        0.4105642256902761,
        0.4105642256902761,
        0.4117647058823529,
        0.4117647058823529,
        0.41656662665066024,
        0.41656662665066024,
        0.42136854741896757,
        0.42136854741896757,
        0.4249699879951981,
        0.4249699879951981,
        0.4369747899159664,
        0.4369747899159664,
        0.4381752701080432,
        0.4381752701080432,
        0.4561824729891957,
        0.4561824729891957,
        0.45738295318127253,
        0.4597839135654262,
        0.46338535414165666,
        0.46338535414165666,
        0.4717887154861945,
        0.4717887154861945,
        0.4729891956782713,
        0.47418967587034816,
        0.48139255702280914,
        0.48139255702280914,
        0.48139255702280914,
        0.4837935174069628,
        0.49459783913565425,
        0.49459783913565425,
        0.5066026410564226,
        0.5090036014405762,
        0.5138055222088835,
        0.5162064825930373,
        0.5234093637454982,
        0.5258103241296519,
        0.5402160864345739,
        0.5426170468187275,
        0.5474189675870348,
        0.5498199279711885,
        0.5666266506602641,
        0.5714285714285714,
        0.5834333733493398,
        0.5858343337334934,
        0.5894357743097239,
        0.5918367346938775,
        0.6062424969987995,
        0.60984393757503,
        0.617046818727491,
        0.6194477791116446,
        0.6626650660264105,
        0.6650660264105642,
        0.6662665066026411,
        0.6710684273709484,
        0.673469387755102,
        0.6758703481392557,
        0.6794717887154862,
        0.6818727490996399,
        0.7010804321728692,
        0.7034813925570228,
        0.7046818727490997,
        0.7070828331332533,
        0.7154861944777912,
        0.7178871548619448,
        0.7226890756302521,
        0.7250900360144058,
        0.7406962785114045,
        0.7442977190876351,
        0.7466986794717887,
        0.7490996398559424,
        0.7575030012004802,
        0.7599039615846338,
        0.7623049219687875,
        0.7647058823529411,
        0.7683073229291717,
        0.7707082833133253,
        0.7815126050420168,
        0.7839135654261705,
        0.7863145258103241,
        0.7887154861944778,
        0.7923169267707083,
        0.7971188475390156,
        0.8055222088835534,
        0.8079231692677071,
        0.8127250900360145,
        0.8151260504201681,
        0.8163265306122449,
        0.8187274909963985,
        0.8283313325330132,
        0.8307322929171669,
        0.8343337334933973,
        0.8367346938775511,
        0.8403361344537815,
        0.8427370948379351,
        0.843937575030012,
        0.8475390156062425,
        0.8499399759903962,
        0.8523409363745498,
        0.8535414165666266,
        0.8559423769507803,
        0.8703481392557023,
        0.8751500600240096,
        0.8823529411764706,
        0.885954381752701,
        0.8871548619447779,
        0.8895558223289316,
        0.8979591836734694,
        0.9003601440576231,
        0.9051620648259304,
        0.907563025210084,
        0.9243697478991597,
        0.9267707082833133,
        0.929171668667467,
        0.9339735894357744,
        0.943577430972389,
        0.9459783913565426,
        0.9483793517406963,
        0.9507803121248499,
        0.9591836734693877,
        0.9615846338535414,
        0.9651860744297719,
        0.9675870348139256,
        1.0
      ],
      "thresholds": [
        Infinity,
        0.5082061886787415,
        0.5078610777854919,
        0.5078588128089905,
        0.5078540444374084,
        0.507853627204895,
        0.5078418254852295,
        0.5078383088111877,
        0.5078378915786743,
        0.5078350305557251,
        0.5078334212303162,
        0.5078299641609192,
        0.5078295469284058,
        0.5078292489051819,
        0.5078288912773132,
        0.5078278183937073,
        0.5078262090682983,
        0.5078239440917969,
        0.5078234076499939,
        0.5078163743019104,
        0.5078160166740417,
        0.5078133344650269,
        0.5078092813491821,
        0.5078085064888,
        0.5078064799308777,
        0.5078064203262329,
        0.5078029036521912,
        0.5078006386756897,
        0.5077996253967285,
        0.5077944993972778,
        0.5077943801879883,
        0.507792055606842,
        0.507790207862854,
        0.5077877640724182,
        0.5077868700027466,
        0.5077847242355347,
        0.5077834129333496,
        0.5077826380729675,
        0.5077821612358093,
        0.5077804327011108,
        0.5077754259109497,
        0.5077723264694214,
        0.5077711343765259,
        0.5077697038650513,
        0.5077693462371826,
        0.5077692270278931,
        0.5077688694000244,
        0.5077688097953796,
        0.5077682137489319,
        0.5077646970748901,
        0.5077645778656006,
        0.5077641606330872,
        0.5077627897262573,
        0.5077593326568604,
        0.5077518224716187,
        0.5077447891235352,
        0.5077443718910217,
        0.5077385902404785,
        0.507736086845398,
        0.5077276825904846,
        0.5077247619628906,
        0.5077231526374817,
        0.5077221393585205,
        0.5077173709869385,
        0.5077168941497803,
        0.5077133178710938,
        0.5077117681503296,
        0.5077069997787476,
        0.5077060461044312,
        0.5077016353607178,
        0.5076985359191895,
        0.507694661617279,
        0.5076943039894104,
        0.5076926946640015,
        0.5076897740364075,
        0.5076884627342224,
        0.507685661315918,
        0.5076841711997986,
        0.5076769590377808,
        0.5076743960380554,
        0.5076740384101868,
        0.5076720118522644,
        0.5076716542243958,
        0.5076711177825928,
        0.5076700448989868,
        0.5076693296432495,
        0.5076691508293152,
        0.5076649785041809,
        0.5076614618301392,
        0.5076580047607422,
        0.5076557397842407,
        0.5076524019241333,
        0.5076491832733154,
        0.5076485872268677,
        0.5076479315757751,
        0.5076438188552856,
        0.5076431632041931,
        0.507641077041626,
        0.5076391696929932,
        0.5076364278793335,
        0.5076361894607544,
        0.5076354742050171,
        0.5076338648796082,
        0.5076335668563843,
        0.5076334476470947,
        0.5076320767402649,
        0.5076315402984619,
        0.5076296329498291,
        0.5076279640197754,
        0.5076274275779724,
        0.5076273083686829,
        0.507627010345459,
        0.5076265931129456,
        0.5076265335083008,
        0.507626473903656,
        0.50762540102005,
        0.5076248049736023,
        0.507623016834259,
        0.507622480392456,
        0.5076215267181396,
        0.5076205134391785,
        0.5076203346252441,
        0.507618248462677,
        0.5076175928115845,
        0.5076162219047546,
        0.507614254951477,
        0.5076109766960144,
        0.5076084733009338,
        0.5076055526733398,
        0.5076051950454712,
        0.5076047778129578,
        0.5076016783714294,
        0.5076011419296265,
        0.5075961351394653,
        0.5075929164886475,
        0.5075914263725281,
        0.5075896382331848,
        0.5075851082801819,
        0.5075849294662476,
        0.5075840950012207,
        0.5075828433036804,
        0.507582426071167,
        0.5075822472572327,
        0.5075806379318237,
        0.5075805187225342,
        0.507577657699585,
        0.5075757503509521,
        0.5075750946998596,
        0.5075750350952148,
        0.5075733065605164,
        0.507571816444397,
        0.5075712203979492,
        0.5075695514678955,
        0.5075673460960388,
        0.507566511631012,
        0.5075663924217224,
        0.5075661540031433,
        0.5075642466545105,
        0.507562518119812,
        0.5075623989105225,
        0.5075623393058777,
        0.5075621008872986,
        0.5075607895851135,
        0.507559061050415,
        0.5075587630271912,
        0.5075579285621643,
        0.5075578689575195,
        0.50755774974823,
        0.5075558423995972,
        0.5075505971908569,
        0.5075476169586182,
        0.5075466632843018,
        0.5075463652610779,
        0.507544994354248,
        0.5075448751449585,
        0.5075435042381287,
        0.5075405836105347,
        0.5075398683547974,
        0.5075299739837646,
        0.5075294375419617,
        0.5075286626815796,
        0.5075281858444214,
        0.5075280070304871,
        0.5075277090072632,
        0.507526695728302,
        0.507524311542511,
        0.5075214505195618,
        0.5075199604034424,
        0.5075191259384155,
        0.5075163841247559,
        0.5075158476829529,
        0.5075134038925171,
        0.5075114965438843,
        0.5075114369392395,
        0.5075112581253052,
        0.5075106620788574,
        0.50750732421875,
        0.5075063705444336,
        0.5075047016143799,
        0.507503867149353,
        0.5074973106384277,
        0.5074971318244934,
        0.5074923634529114,
        0.5074922442436218,
        0.5074915885925293,
        0.5074896812438965,
        0.507489025592804,
        0.5074882507324219,
        0.5074880123138428,
        0.5074876546859741,
        0.5074865818023682,
        0.5074863433837891,
        0.5074844360351562,
        0.5074842572212219,
        0.5074802041053772,
        0.507479727268219,
        0.5074794888496399,
        0.5074775815010071,
        0.5074763298034668,
        0.5074760913848877,
        0.507474422454834,
        0.5074729323387146,
        0.5074683427810669,
        0.5074675679206848,
        0.5074665546417236,
        0.5074660778045654,
        0.5074625611305237,
        0.5074620246887207,
        0.5074615478515625,
        0.5074614882469177,
        0.5074613094329834,
        0.5074606537818909,
        0.5074600577354431,
        0.5074597001075745,
        0.507457971572876,
        0.507457435131073,
        0.5074567794799805,
        0.5074563026428223,
        0.5074560046195984,
        0.5074558258056641,
        0.5074463486671448,
        0.5074462294578552,
        0.5074450969696045,
        0.5074439644813538,
        0.507443904876709,
        0.5074429512023926,
        0.5074410438537598,
        0.5074398517608643,
        0.5074392557144165,
        0.507439136505127,
        0.5074390172958374,
        0.5074389576911926,
        0.5074382424354553,
        0.5074381828308105,
        0.5074363946914673,
        0.5074357986450195,
        0.507435142993927,
        0.5074347257614136,
        0.5074344277381897,
        0.5074342489242554,
        0.507433295249939,
        0.5074329972267151,
        0.5074329376220703,
        0.5074325203895569,
        0.5074323415756226,
        0.5074313282966614,
        0.5074308514595032,
        0.5074289441108704,
        0.5074288249015808,
        0.5074287056922913,
        0.5074285268783569,
        0.5074273347854614,
        0.5074271559715271,
        0.5074270963668823,
        0.5074235200881958,
        0.5074230432510376,
        0.5074228048324585,
        0.5074208974838257,
        0.5074206590652466,
        0.5074203014373779,
        0.5074200630187988,
        0.507418692111969,
        0.5074184536933899,
        0.5074175000190735,
        0.5074173808097839,
        0.5074171423912048,
        0.5074165463447571,
        0.5074161887168884,
        0.507415771484375,
        0.5074146389961243,
        0.5074143409729004,
        0.5074135065078735,
        0.5074133276939392,
        0.5074113607406616,
        0.5074111819267273,
        0.507411003112793,
        0.5074109435081482,
        0.5074104070663452,
        0.507409930229187,
        0.5074094533920288,
        0.5074085593223572,
        0.5074080228805542,
        0.5074074268341064,
        0.5074065327644348,
        0.5074064135551453,
        0.5074049234390259,
        0.5074048638343811,
        0.5074039697647095,
        0.5074033737182617,
        0.5074030160903931,
        0.5074028968811035,
        0.5074010491371155,
        0.5074006915092468,
        0.507400631904602,
        0.5074001550674438,
        0.5073999762535095,
        0.5073937773704529,
        0.5073937177658081,
        0.5073921084403992,
        0.507391631603241,
        0.5073887705802917,
        0.5073884129524231,
        0.5073878169059753,
        0.5073876976966858,
        0.5073858499526978,
        0.507385790348053,
        0.5073853135108948,
        0.5073847770690918,
        0.5073845386505127,
        0.507382333278656,
        0.5073820948600769,
        0.5073817372322083,
        0.5073813796043396,
        0.5073796510696411,
        0.5073794722557068,
        0.5073782801628113,
        0.5073781609535217,
        0.507375955581665,
        0.5073758959770203,
        0.5073749423027039,
        0.5073748826980591,
        0.5073745846748352,
        0.5073744654655457,
        0.5073738098144531,
        0.5073736310005188,
        0.5073707103729248,
        0.5073702931404114,
        0.5073676109313965,
        0.5073670148849487,
        0.5073667764663696,
        0.507366418838501,
        0.5073659420013428,
        0.5073655843734741,
        0.5073650479316711,
        0.5073603987693787,
        0.5073602795600891,
        0.5073595643043518,
        0.5073591470718384,
        0.5073589086532593,
        0.5073580145835876,
        0.5073578357696533,
        0.5073574185371399,
        0.5073561072349548,
        0.5073553323745728,
        0.507355272769928,
        0.5073550343513489,
        0.5073526501655579,
        0.507352352142334,
        0.5073515176773071,
        0.5073514580726624,
        0.5073472261428833,
        0.5073453783988953,
        0.5073446035385132,
        0.5073432922363281,
        0.5073422789573669,
        0.5073407888412476,
        0.5073397159576416,
        0.5073388814926147,
        0.5073384642601013,
        0.5073381066322327,
        0.5073359608650208,
        0.5073350071907043,
        0.5073347687721252,
        0.5073344707489014,
        0.5073341727256775,
        0.5073315501213074,
        0.5073313117027283,
        0.5073294639587402,
        0.5073291659355164,
        0.5073291063308716,
        0.5073286294937134,
        0.5073267817497253,
        0.5073259472846985,
        0.5073232054710388,
        0.5073220729827881,
        0.5073205828666687,
        0.5073195099830627,
        0.5073185563087463,
        0.5073163509368896,
        0.5073146224021912,
        0.5073129534721375,
        0.5073126554489136,
        0.5073124170303345,
        0.5073123574256897,
        0.5073103308677673,
        0.5073018670082092,
        0.5073013305664062,
        0.5073010921478271,
        0.507300853729248,
        0.5073000192642212,
        0.5072993636131287,
        0.5072982907295227,
        0.5072975754737854,
        0.5072968006134033,
        0.5072935819625854,
        0.507291853427887,
        0.5072888731956482,
        0.5072888135910034,
        0.5072875618934631,
        0.5072870850563049,
        0.5072846412658691,
        0.5072836875915527,
        0.5072822570800781,
        0.5072811245918274,
        0.5072793960571289,
        0.5072763562202454,
        0.5072756409645081,
        0.5072718858718872,
        0.5072698593139648,
        0.5072680115699768,
        0.5072678923606873,
        0.507267415523529,
        0.5072673559188843,
        0.5072664618492126,
        0.5072663426399231,
        0.5072662830352783,
        0.5072641372680664,
        0.5072610974311829,
        0.5072610378265381,
        0.5072599053382874,
        0.5072585940361023,
        0.5072582364082336,
        0.5072566866874695,
        0.5072556138038635,
        0.5072547197341919,
        0.5072544813156128,
        0.5072507858276367,
        0.5072484016418457,
        0.507247805595398,
        0.507247269153595,
        0.5072430968284607,
        0.5072423815727234,
        0.5072407126426697,
        0.5072405338287354,
        0.5072404742240906,
        0.5072393417358398,
        0.50723797082901,
        0.5072378516197205,
        0.5072353482246399,
        0.5072336196899414,
        0.5072324872016907,
        0.5072318911552429,
        0.507224977016449,
        0.5072249174118042,
        0.5072235465049744,
        0.5072234869003296,
        0.5072170495986938,
        0.5072165727615356,
        0.507215678691864,
        0.5072155594825745,
        0.5072146058082581,
        0.5072143077850342,
        0.5072126388549805,
        0.5072115063667297,
        0.5072110891342163,
        0.5072095394134521,
        0.507206380367279,
        0.5072063207626343,
        0.5072062611579895,
        0.5072060823440552,
        0.5072036981582642,
        0.5072035193443298,
        0.5071990489959717,
        0.5071988701820374,
        0.5071983337402344,
        0.5071980357170105,
        0.5071937441825867,
        0.5071932673454285,
        0.5071869492530823,
        0.5071866512298584,
        0.5071852803230286,
        0.5071852207183838,
        0.5071797966957092,
        0.5071775913238525,
        0.5071700811386108,
        0.5071693062782288,
        0.5071662664413452,
        0.5071661472320557,
        0.5071585774421692,
        0.507158100605011,
        0.507156252861023,
        0.5071559548377991,
        0.5071437358856201,
        0.5071433782577515,
        0.5071429014205933,
        0.5071426630020142,
        0.507142186164856,
        0.5071420073509216,
        0.5071414113044739,
        0.5071412920951843,
        0.5071377754211426,
        0.5071377158164978,
        0.5071375966072083,
        0.5071374773979187,
        0.507135808467865,
        0.5071354508399963,
        0.5071349740028381,
        0.507134735584259,
        0.5071324706077576,
        0.5071322321891785,
        0.5071316957473755,
        0.507131040096283,
        0.507129967212677,
        0.5071298480033875,
        0.5071293711662292,
        0.5071291923522949,
        0.5071287155151367,
        0.5071286559104919,
        0.5071271061897278,
        0.507127046585083,
        0.5071268081665039,
        0.5071267485618591,
        0.5071263313293457,
        0.5071261525154114,
        0.5071252584457397,
        0.5071251392364502,
        0.5071247220039368,
        0.5071246027946472,
        0.5071245431900024,
        0.5071244239807129,
        0.5071229934692383,
        0.507122814655304,
        0.5071220397949219,
        0.5071215629577637,
        0.5071204304695129,
        0.5071203708648682,
        0.5071201324462891,
        0.5071200728416443,
        0.507119357585907,
        0.5071189403533936,
        0.507118821144104,
        0.507118284702301,
        0.5071161985397339,
        0.5071152448654175,
        0.5071144104003906,
        0.5071142911911011,
        0.5071136355400085,
        0.5071133375167847,
        0.5071119070053101,
        0.507111668586731,
        0.5071111917495728,
        0.5071108341217041,
        0.507108747959137,
        0.5071084499359131,
        0.5071081519126892,
        0.5071067810058594,
        0.5071051716804504,
        0.5071050524711609,
        0.5071035027503967,
        0.5071032643318176,
        0.5071002244949341,
        0.5071000456809998,
        0.5070974826812744,
        0.5070971846580505,
        0.5070655345916748
      ]
    },
    "roc_auc": 0.1991262291231018,
    "optimal_threshold": Infinity,
    "precision_mean": 0.5,
    "recall_mean": 1.0
  },
  "ttt_model": {
    "accuracy_mean": 1.0,
    "accuracy_std": 0.0,
    "macro_f1_mean": 1.0,
    "macro_f1_std": 0.0,
    "mcc_mean": 1.0,
    "mcc_std": 0.0,
    "confusion_matrix": [
      [
        500,
        0
      ],
      [
        0,
        500
      ]
    ],
    "roc_curve": {
      "fpr": [
        0.0,
        0.0,
        0.126,
        0.134,
        1.0
      ],
      "tpr": [
        0.0,
        1.0,
        1.0,
        1.0,
        1.0
      ],
      "thresholds": [
        Infinity,
        1.0,
        5.605193857299268e-45,
        1.401298464324817e-45,
        0.0
      ]
    },
    "roc_auc": 1.0,
    "optimal_threshold": 1.0,
    "ttt_adaptation_data": {
      "steps": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50,
        51,
        52,
        53,
        54,
        55,
        56,
        57,
        58,
        59,
        60,
        61,
        62,
        63,
        64,
        65,
        66,
        67,
        68,
        69,
        70,
        71,
        72,
        73,
        74,
        75,
        76,
        77,
        78,
        79,
        80,
        81,
        82,
        83,
        84,
        85,
        86,
        87,
        88,
        89,
        90,
        91,
        92,
        93,
        94,
        95,
        96,
        97,
        98,
        99,
        100,
        101,
        102,
        103,
        104,
        105,
        106,
        107,
        108,
        109,
        110,
        111,
        112,
        113,
        114,
        115,
        116,
        117,
        118,
        119,
        120,
        121,
        122,
        123,
        124,
        125,
        126,
        127,
        128,
        129,
        130,
        131,
        132,
        133,
        134,
        135,
        136,
        137,
        138,
        139,
        140,
        141,
        142,
        143,
        144,
        145,
        146,
        147,
        148,
        149,
        150,
        151,
        152,
        153,
        154,
        155,
        156,
        157,
        158,
        159,
        160,
        161,
        162,
        163,
        164,
        165,
        166,
        167,
        168,
        169,
        170,
        171,
        172,
        173,
        174,
        175,
        176,
        177,
        178,
        179,
        180,
        181,
        182,
        183,
        184,
        185,
        186,
        187,
        188,
        189,
        190,
        191,
        192,
        193,
        194,
        195,
        196,
        197,
        198,
        199
      ],
      "total_losses": [
        0.6957777142524719,
        0.6941012144088745,
        0.6927535533905029,
        0.6928803324699402,
        0.6912697553634644,
        0.6906248331069946,
        0.6891281008720398,
        0.686133623123169,
        0.6805107593536377,
        0.6691216230392456,
        0.661689281463623,
        0.6508810520172119,
        0.6364504098892212,
        0.6188350915908813,
        0.5990347266197205,
        0.5746029019355774,
        0.5352137684822083,
        0.5001651644706726,
        0.46640995144844055,
        0.41896530985832214,
        0.3826940357685089,
        0.3337859809398651,
        0.2845075726509094,
        0.24960140883922577,
        0.20744740962982178,
        0.1723601073026657,
        0.14643900096416473,
        0.1117289736866951,
        0.09431838989257812,
        0.06679487973451614,
        0.05873861163854599,
        0.04478082433342934,
        0.03127770125865936,
        0.02625257521867752,
        0.020034264773130417,
        0.015181130729615688,
        0.012690447270870209,
        0.010877544060349464,
        0.009617325849831104,
        0.008164390921592712,
        0.005043239798396826,
        0.004640583880245686,
        0.0029218296986073256,
        0.0033108009956777096,
        0.0021977340802550316,
        0.00285805924795568,
        0.0034592016600072384,
        0.0015042135491967201,
        0.0019325029570609331,
        0.0017729338724166155,
        0.0015827410388737917,
        0.0016105793183669448,
        0.0011532726930454373,
        0.00185336172580719,
        0.0011551521020010114,
        0.000838900450617075,
        0.0005198559374548495,
        0.00034174631582573056,
        0.0013653350761160254,
        0.00033367154537700117,
        0.0002721490163821727,
        0.00020444999972824007,
        0.0006744286511093378,
        0.0013110738946124911,
        0.00037645225529558957,
        0.0005130021600052714,
        0.0005296427407301962,
        0.00516049237921834,
        0.0005226759822107852,
        0.0003489531227387488,
        0.000382359663490206,
        0.00011489800817798823,
        0.0005050967447459698,
        0.0006515816785395145,
        0.00019963634258601815,
        0.0004197208909317851,
        0.0008317033643834293,
        0.0004236004315316677,
        0.00042376923374831676,
        0.000161748772370629,
        0.0008247410878539085,
        0.0005855830968357623,
        0.0002557262487243861,
        0.0003243909450247884,
        0.0002564725000411272,
        0.0004395784926600754,
        0.0003523487539496273,
        0.00850098766386509,
        7.841840852051973e-05,
        0.0008157841512002051,
        0.0007170841563493013,
        0.0007385138887912035,
        0.00039598048897460103,
        0.0003502574691083282,
        0.0007494859164580703,
        0.00017722589836921543,
        0.0007580159581266344,
        0.0006000421126373112,
        0.0003628151025623083,
        0.0005896008224226534,
        0.0002552200458012521,
        0.00014752017159480602,
        0.0004015603626612574,
        0.00015598491881974041,
        0.001116412808187306,
        0.0006952784606255591,
        0.0009882317390292883,
        0.0004537155036814511,
        0.00047855026787146926,
        0.0005214922712184489,
        0.0002561394649092108,
        0.0002282372151967138,
        0.00041183774010278285,
        0.0004261464346200228,
        0.0003712064935825765,
        0.0003905200574081391,
        0.00010344175825593993,
        0.0005719762993976474,
        0.00079704774543643,
        0.0001306953199673444,
        0.0002484286669641733,
        0.0001404910144628957,
        0.0005134162493050098,
        0.00048436701763421297,
        0.0004638790851458907,
        0.0004035063902847469,
        0.00024431507335975766,
        0.00025055737933143973,
        0.00013160349044483155,
        0.00020834106544498354,
        0.0006980094476602972,
        0.0003098202287219465,
        0.0001328288926742971,
        9.122795017901808e-05,
        0.00038664607563987374,
        0.0002984260208904743,
        0.00019500144117046148,
        0.0007561823586001992,
        8.682190673425794e-05,
        0.0003553153364919126,
        0.00015946583880577236,
        0.00033302471274510026,
        0.00043876515701413155,
        0.00020014583424199373,
        0.00012518790026661009,
        0.0005236244760453701,
        0.0003147100505884737,
        0.0007325808401219547,
        0.00010758227290352806,
        0.0008849531295709312,
        0.00032938140793703496,
        0.0002236924774479121,
        0.00011637566785793751,
        0.0004919349448755383,
        0.00017357848992105573,
        0.00031615205807611346,
        0.00010681151616154239,
        0.0009412257350049913,
        0.00011602882295846939,
        0.00013178499648347497,
        0.0001500107755418867,
        0.0001900059578474611,
        0.00022534483287017792,
        9.482750465394929e-05,
        0.00030718641937710345,
        0.000489754369482398,
        0.0001426212547812611,
        0.00022765967878513038,
        0.0006022935849614441,
        0.00012062180758221075,
        0.0005112193757668138,
        0.0002926523156929761,
        0.00017072063928935677,
        9.871288057183847e-05,
        0.00010971559095196426,
        0.0011517824605107307,
        0.0005046059377491474,
        0.0002381384838372469,
        0.0001506883854744956,
        0.0002358381898375228,
        0.00025762684526853263,
        0.00016725718160159886,
        0.000320384802762419,
        0.00018819440447259694,
        0.00017264526104554534,
        0.0005011242465116084,
        0.0005927585298195481,
        0.0005046164733357728,
        0.0005720353219658136,
        0.0006392120267264545,
        0.00017395945906173438,
        0.00023093870549928397,
        0.00018970679957419634,
        0.0001349351368844509,
        0.00034170623985119164,
        0.0003381813003215939,
        0.0002452202024869621,
        0.00046674965415149927,
        0.00014838416245765984,
        7.847310916986316e-05
      ],
      "support_losses": [
        0.6957777142524719,
        0.6941012144088745,
        0.6927535533905029,
        0.6928803324699402,
        0.6912697553634644,
        0.6906248331069946,
        0.6891281008720398,
        0.686133623123169,
        0.6805107593536377,
        0.6691216230392456,
        0.661689281463623,
        0.6508810520172119,
        0.6364504098892212,
        0.6188350915908813,
        0.5990347266197205,
        0.5746029019355774,
        0.5352137684822083,
        0.5001651644706726,
        0.46640995144844055,
        0.41896530985832214,
        0.3826940357685089,
        0.3337859809398651,
        0.2845075726509094,
        0.24960140883922577,
        0.20744740962982178,
        0.1723601073026657,
        0.14643900096416473,
        0.1117289736866951,
        0.09431838989257812,
        0.06679487973451614,
        0.05873861163854599,
        0.04478082433342934,
        0.03127770125865936,
        0.02625257521867752,
        0.020034264773130417,
        0.015181130729615688,
        0.012690447270870209,
        0.010877544060349464,
        0.009617325849831104,
        0.008164390921592712,
        0.005043239798396826,
        0.004640583880245686,
        0.0029218296986073256,
        0.0033108009956777096,
        0.0021977340802550316,
        0.00285805924795568,
        0.0034592016600072384,
        0.0015042135491967201,
        0.0019325029570609331,
        0.0017729338724166155,
        0.0015827410388737917,
        0.0016105793183669448,
        0.0011532726930454373,
        0.00185336172580719,
        0.0011551521020010114,
        0.000838900450617075,
        0.0005198559374548495,
        0.00034174631582573056,
        0.0013653350761160254,
        0.00033367154537700117,
        0.0002721490163821727,
        0.00020444999972824007,
        0.0006744286511093378,
        0.0013110738946124911,
        0.00037645225529558957,
        0.0005130021600052714,
        0.0005296427407301962,
        0.00516049237921834,
        0.0005226759822107852,
        0.0003489531227387488,
        0.000382359663490206,
        0.00011489800817798823,
        0.0005050967447459698,
        0.0006515816785395145,
        0.00019963634258601815,
        0.0004197208909317851,
        0.0008317033643834293,
        0.0004236004315316677,
        0.00042376923374831676,
        0.000161748772370629,
        0.0008247410878539085,
        0.0005855830968357623,
        0.0002557262487243861,
        0.0003243909450247884,
        0.0002564725000411272,
        0.0004395784926600754,
        0.0003523487539496273,
        0.00850098766386509,
        7.841840852051973e-05,
        0.0008157841512002051,
        0.0007170841563493013,
        0.0007385138887912035,
        0.00039598048897460103,
        0.0003502574691083282,
        0.0007494859164580703,
        0.00017722589836921543,
        0.0007580159581266344,
        0.0006000421126373112,
        0.0003628151025623083,
        0.0005896008224226534,
        0.0002552200458012521,
        0.00014752017159480602,
        0.0004015603626612574,
        0.00015598491881974041,
        0.001116412808187306,
        0.0006952784606255591,
        0.0009882317390292883,
        0.0004537155036814511,
        0.00047855026787146926,
        0.0005214922712184489,
        0.0002561394649092108,
        0.0002282372151967138,
        0.00041183774010278285,
        0.0004261464346200228,
        0.0003712064935825765,
        0.0003905200574081391,
        0.00010344175825593993,
        0.0005719762993976474,
        0.00079704774543643,
        0.0001306953199673444,
        0.0002484286669641733,
        0.0001404910144628957,
        0.0005134162493050098,
        0.00048436701763421297,
        0.0004638790851458907,
        0.0004035063902847469,
        0.00024431507335975766,
        0.00025055737933143973,
        0.00013160349044483155,
        0.00020834106544498354,
        0.0006980094476602972,
        0.0003098202287219465,
        0.0001328288926742971,
        9.122795017901808e-05,
        0.00038664607563987374,
        0.0002984260208904743,
        0.00019500144117046148,
        0.0007561823586001992,
        8.682190673425794e-05,
        0.0003553153364919126,
        0.00015946583880577236,
        0.00033302471274510026,
        0.00043876515701413155,
        0.00020014583424199373,
        0.00012518790026661009,
        0.0005236244760453701,
        0.0003147100505884737,
        0.0007325808401219547,
        0.00010758227290352806,
        0.0008849531295709312,
        0.00032938140793703496,
        0.0002236924774479121,
        0.00011637566785793751,
        0.0004919349448755383,
        0.00017357848992105573,
        0.00031615205807611346,
        0.00010681151616154239,
        0.0009412257350049913,
        0.00011602882295846939,
        0.00013178499648347497,
        0.0001500107755418867,
        0.0001900059578474611,
        0.00022534483287017792,
        9.482750465394929e-05,
        0.00030718641937710345,
        0.000489754369482398,
        0.0001426212547812611,
        0.00022765967878513038,
        0.0006022935849614441,
        0.00012062180758221075,
        0.0005112193757668138,
        0.0002926523156929761,
        0.00017072063928935677,
        9.871288057183847e-05,
        0.00010971559095196426,
        0.0011517824605107307,
        0.0005046059377491474,
        0.0002381384838372469,
        0.0001506883854744956,
        0.0002358381898375228,
        0.00025762684526853263,
        0.00016725718160159886,
        0.000320384802762419,
        0.00018819440447259694,
        0.00017264526104554534,
        0.0005011242465116084,
        0.0005927585298195481,
        0.0005046164733357728,
        0.0005720353219658136,
        0.0006392120267264545,
        0.00017395945906173438,
        0.00023093870549928397,
        0.00018970679957419634,
        0.0001349351368844509,
        0.00034170623985119164,
        0.0003381813003215939,
        0.0002452202024869621,
        0.00046674965415149927,
        0.00014838416245765984,
        7.847310916986316e-05
      ],
      "consistency_losses": [
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0
      ]
    },
    "precision_mean": 1.0,
    "recall_mean": 1.0
  },
  "dataset_info": {
    "name": "Edge-IIoTset",
    "total_samples": 100124,
    "evaluated_samples": 10000,
    "features": 61,
    "attack_types": 15,
    "zero_day_attack": "DDoS_TCP",
    "zero_day_stats": {
      "zero_day_attack": "DDoS_TCP",
      "zero_day_samples": 50062,
      "zero_day_percentage": 8.305695794061482,
      "total_attack_samples": 602743,
      "normal_samples": 1615643,
      "total_samples": 2218386,
      "available_attacks": [
        "Normal",
        "DDoS_UDP",
        "DDoS_ICMP",
        "SQL_injection",
        "Password",
        "Vulnerability_scanner",
        "DDoS_TCP",
        "DDoS_HTTP",
        "Uploading",
        "Backdoor",
        "Port_Scanning",
        "XSS",
        "Ransomware",
        "Fingerprinting",
        "MITM"
      ]
    }
  },
  "final_global_model": {
    "accuracy": 1.0,
    "f1_score": 1.0,
    "mcc": 1.0,
    "roc_auc": 1.0,
    "optimal_threshold": 0.5,
    "roc_curve": {
      "fpr": [
        0.0,
        0.0,
        1.0
      ],
      "tpr": [
        0.0,
        1.0,
        1.0
      ],
      "thresholds": [
        Infinity,
        0.9999998807907104,
        1.0000000116860974e-07
      ]
    },
    "confusion_matrix": [
      [
        2500,
        0
      ],
      [
        0,
        2500
      ]
    ],
    "test_samples": 5000,
    "dataset_info": {
      "name": "Edge-IIoTset",
      "total_samples": 100124,
      "evaluated_samples": 5000,
      "features": 61,
      "attack_types": 15,
      "zero_day_attack": "DDoS_TCP"
    }
  },
  "training_history": [
    {
      "round_number": 0,
      "client_updates": [
        "ClientUpdate(client_id='client_1', model_parameters={'meta_learner.transductive_net.feature_extractors.0.0.weight': tensor([[-0.0375,  0.0718, -0.0125,  ...,  0.0765,  0.0441, -0.0178],\n        [-0.0686, -0.1132, -0.0526,  ...,  0.1061,  0.0016, -0.0529],\n        [ 0.0367,  0.0018,  0.1001,  ..., -0.0537, -0.1066, -0.1268],\n        ...,\n        [ 0.0871,  0.1092,  0.0825,  ...,  0.0541,  0.0525,  0.1052],\n        [ 0.1091,  0.0584, -0.1022,  ...,  0.0318,  0.1029,  0.1156],\n        [-0.0666,  0.0003,  0.0526,  ..., -0.0858,  0.1179, -0.1253]]), 'meta_learner.transductive_net.feature_extractors.0.0.bias': tensor([-0.0171,  0.0447,  0.0235,  0.0672,  0.1105, -0.0852,  0.0544, -0.0756,\n         0.0867, -0.0257,  0.0068,  0.0534, -0.0903, -0.0493, -0.0214, -0.0508,\n         0.1069, -0.0846, -0.1182, -0.0154, -0.0524, -0.1278,  0.0037,  0.0808,\n         0.0743,  0.0713, -0.0306,  0.0712,  0.0092, -0.0395,  0.0535,  0.0954,\n         0.0299, -0.0149, -0.0807, -0.1238,  0.0362, -0.1107, -0.1202, -0.0164,\n        -0.1157, -0.0681, -0.0439,  0.1163,  0.0942, -0.0537, -0.0330,  0.0271,\n        -0.0860, -0.0694, -0.0565,  0.0747,  0.0949,  0.0754,  0.0069,  0.0120,\n         0.0729,  0.0148, -0.0661, -0.0361,  0.1104,  0.0322,  0.0082,  0.1102,\n        -0.0579,  0.0435,  0.0306,  0.0507, -0.0036, -0.0806, -0.0517,  0.1099,\n         0.0872,  0.0922, -0.0854,  0.0133, -0.0943, -0.0254,  0.0439, -0.1310,\n         0.0180,  0.0264,  0.1329,  0.0002, -0.0152,  0.0250, -0.0436, -0.0057,\n        -0.1006,  0.0787,  0.0979,  0.1019, -0.0100, -0.1042, -0.0928,  0.0662,\n         0.1085, -0.0376, -0.1348,  0.0227,  0.0214, -0.0979,  0.0781,  0.1249,\n        -0.0978, -0.0107, -0.1008,  0.0619, -0.0379,  0.1001, -0.0120, -0.0325,\n         0.0588,  0.1122,  0.1041, -0.0846,  0.0053,  0.1261,  0.1005, -0.0221,\n        -0.0971, -0.0853, -0.0455,  0.0812,  0.1146, -0.0711,  0.0581,  0.0985]), 'meta_learner.transductive_net.feature_extractors.1.0.weight': tensor([[-0.0174, -0.0895,  0.0030,  ..., -0.0372, -0.0393,  0.0399],\n        [ 0.0567, -0.0480, -0.1021,  ..., -0.0068, -0.1226,  0.0589],\n        [-0.0509, -0.0022,  0.0957,  ...,  0.0070, -0.0343, -0.0048],\n        ...,\n        [ 0.0789, -0.0413,  0.1121,  ..., -0.0161,  0.0686,  0.0546],\n        [ 0.0745,  0.1281,  0.0861,  ..., -0.0019,  0.1033,  0.0820],\n        [-0.0606,  0.0323,  0.1054,  ..., -0.1067, -0.0867, -0.0130]]), 'meta_learner.transductive_net.feature_extractors.1.0.bias': tensor([ 0.1063, -0.0968,  0.0279,  0.1117, -0.0030, -0.0708,  0.0230, -0.0271,\n        -0.1228,  0.1211, -0.0740,  0.0123,  0.0536, -0.0327, -0.0974, -0.0371,\n         0.0140, -0.0434, -0.1018, -0.1206,  0.0748,  0.0915,  0.0819,  0.0220,\n        -0.0497, -0.1084, -0.0058,  0.1136, -0.0921,  0.1162,  0.0452, -0.0601,\n         0.1180, -0.0553, -0.0864, -0.0422,  0.0058, -0.0650, -0.0739, -0.0864,\n         0.0944,  0.0500,  0.0763, -0.0866,  0.0400, -0.0233,  0.0388, -0.0118,\n        -0.0959,  0.0702,  0.0507,  0.0289,  0.1133,  0.0702, -0.1126,  0.0600,\n        -0.0971,  0.0508, -0.0878,  0.0467,  0.0590,  0.0625,  0.0933,  0.0840]), 'meta_learner.transductive_net.feature_extractors.2.0.weight': tensor([[-0.0606,  0.0095, -0.0559,  ...,  0.1121,  0.1044,  0.0575],\n        [-0.0716, -0.0959, -0.0814,  ...,  0.0493,  0.0415,  0.0899],\n        [-0.0678,  0.0451, -0.1028,  ...,  0.1064, -0.0517, -0.0130],\n        ...,\n        [-0.1208,  0.1124,  0.0849,  ...,  0.1204,  0.1163,  0.0425],\n        [-0.0571,  0.0532,  0.0063,  ...,  0.0427,  0.0442, -0.0243],\n        [ 0.1225,  0.0598, -0.0666,  ..., -0.1016, -0.1255, -0.0906]]), 'meta_learner.transductive_net.feature_extractors.2.0.bias': tensor([-0.0104, -0.1114,  0.1088, -0.0883, -0.0361,  0.1190,  0.0206, -0.0609,\n         0.0476, -0.1165, -0.0187,  0.0080, -0.0076, -0.0876, -0.0010,  0.1103,\n         0.0120, -0.0855, -0.0839, -0.0117,  0.0382,  0.0769,  0.0724,  0.0056,\n         0.0497,  0.0631,  0.0418,  0.0112, -0.1068, -0.0124,  0.0058,  0.0226,\n        -0.0837, -0.0993, -0.0675,  0.0561,  0.0595, -0.1241,  0.0586, -0.0806,\n        -0.1183,  0.0329,  0.0150,  0.0145, -0.0053,  0.0881,  0.0723, -0.0938,\n         0.0563, -0.0441, -0.0933, -0.0526,  0.0110, -0.0411,  0.0034, -0.0306,\n         0.1282, -0.0926, -0.0323,  0.0443,  0.1120, -0.0265,  0.0816,  0.0245,\n        -0.0495,  0.1005, -0.0456,  0.0926,  0.0566, -0.0511,  0.0855, -0.0426,\n        -0.0719, -0.0906, -0.0245, -0.0260, -0.0663, -0.1362, -0.0734, -0.0717,\n        -0.0828, -0.0436, -0.0698, -0.1158, -0.0296,  0.1259, -0.0002,  0.0718,\n         0.0943, -0.0998, -0.0208, -0.0921,  0.0494,  0.0494,  0.0710, -0.1174,\n         0.0824,  0.1109, -0.0918, -0.0624,  0.0904, -0.0745,  0.1220,  0.0720,\n        -0.0440, -0.0586,  0.0385,  0.0453,  0.0148,  0.0836,  0.0083,  0.0023,\n         0.0796, -0.0942, -0.0669, -0.0357,  0.0226,  0.0897, -0.0400, -0.0753,\n         0.0949,  0.0724, -0.0040, -0.0610,  0.0986, -0.1230, -0.0404,  0.1157,\n         0.0708, -0.0766,  0.0316, -0.0935, -0.0977, -0.1256, -0.0821, -0.0513,\n        -0.0416, -0.1088, -0.0136,  0.0371,  0.0422, -0.0751,  0.0434, -0.1211,\n        -0.0179, -0.0183,  0.1152,  0.0789,  0.0122, -0.1023, -0.0338, -0.0832,\n        -0.1149,  0.0514,  0.0559, -0.0039, -0.0438,  0.0425,  0.0422,  0.0919,\n         0.0135, -0.0362,  0.0870, -0.0181, -0.0958,  0.0547,  0.0866, -0.0423,\n        -0.1006, -0.1307,  0.0756, -0.0409, -0.0968, -0.0652,  0.0324, -0.0020,\n         0.0205, -0.0390, -0.1214,  0.0860, -0.0112, -0.1225,  0.0790, -0.0171,\n         0.1031,  0.0952, -0.1051,  0.0783,  0.0631,  0.0436, -0.0865,  0.0522,\n        -0.1235, -0.0791, -0.0332, -0.0255, -0.0575,  0.0133, -0.0865,  0.0143,\n        -0.0552,  0.1285, -0.0906, -0.0937, -0.0430, -0.0669,  0.0270, -0.0107,\n        -0.1047,  0.0752,  0.0486, -0.0293, -0.0918, -0.0546, -0.0730,  0.0087,\n         0.0237,  0.0673,  0.0923,  0.1046, -0.0722, -0.0156,  0.0463, -0.0155,\n        -0.0831,  0.1071, -0.1057,  0.0441,  0.0799, -0.1180, -0.0958, -0.0574,\n        -0.1113,  0.0903,  0.0536,  0.0679, -0.0658,  0.0663,  0.0424, -0.0927,\n         0.0330,  0.0986, -0.0574,  0.1111, -0.0851, -0.0501, -0.0733,  0.1089,\n        -0.0308,  0.0814,  0.1137,  0.0459,  0.0218,  0.1044,  0.0778, -0.1142]), 'meta_learner.transductive_net.feature_projection.0.weight': tensor([[-0.0006, -0.0017,  0.0038,  ...,  0.0229,  0.0055,  0.0148],\n        [ 0.0264, -0.0250,  0.0158,  ..., -0.0099,  0.0096, -0.0173],\n        [ 0.0053,  0.0350, -0.0228,  ...,  0.0342, -0.0082, -0.0064],\n        ...,\n        [-0.0317,  0.0053,  0.0323,  ...,  0.0067, -0.0109,  0.0004],\n        [-0.0372, -0.0124,  0.0436,  ..., -0.0304, -0.0388,  0.0269],\n        [ 0.0313, -0.0278, -0.0028,  ...,  0.0114, -0.0451,  0.0165]]), 'meta_learner.transductive_net.feature_projection.0.bias': tensor([-0.0203, -0.0255,  0.0302, -0.0433, -0.0286, -0.0419,  0.0298,  0.0551,\n         0.0037,  0.0294,  0.0049,  0.0044,  0.0013,  0.0091, -0.0155,  0.0268,\n        -0.0339,  0.0160, -0.0273, -0.0209,  0.0032, -0.0410,  0.0391, -0.0343,\n         0.0386, -0.0053,  0.0068,  0.0511,  0.0087, -0.0346,  0.0029,  0.0111,\n        -0.0100,  0.0119, -0.0355, -0.0237,  0.0217,  0.0277,  0.0155,  0.0047,\n         0.0042, -0.0491,  0.0432, -0.0259, -0.0132, -0.0512,  0.0273, -0.0341,\n         0.0345,  0.0244,  0.0159, -0.0022, -0.0067,  0.0142, -0.0225, -0.0150,\n         0.0382,  0.0470,  0.0035, -0.0299, -0.0485,  0.0082, -0.0250,  0.0320]), 'meta_learner.transductive_net.classifier.0.weight': tensor([[-0.0798, -0.0640,  0.0618,  ...,  0.0527,  0.0367,  0.0822],\n        [-0.0040, -0.1191, -0.0035,  ...,  0.0933,  0.0983,  0.0601],\n        [ 0.0670,  0.0584,  0.0060,  ..., -0.0976,  0.0120,  0.0117],\n        ...,\n        [ 0.0551, -0.0309, -0.1068,  ...,  0.1001, -0.1050,  0.0780],\n        [ 0.0739,  0.1224,  0.1199,  ..., -0.0623, -0.0779,  0.1068],\n        [ 0.0644, -0.0783,  0.0179,  ..., -0.0204,  0.0500,  0.0563]]), 'meta_learner.transductive_net.classifier.0.bias': tensor([ 0.0656,  0.0336,  0.0476, -0.0905,  0.0997, -0.0569,  0.0177, -0.1162,\n         0.0851, -0.0893, -0.0266,  0.0108,  0.0409,  0.1078, -0.0202, -0.1224,\n         0.0186, -0.1141,  0.0118,  0.0528, -0.0667, -0.0512, -0.0785, -0.0906,\n         0.0695,  0.1188, -0.0726, -0.0963,  0.0445, -0.0802,  0.0792, -0.0965,\n         0.0865,  0.0096,  0.0255,  0.0686,  0.0611,  0.0731, -0.0303, -0.0435,\n         0.0484,  0.0172, -0.0874, -0.0368, -0.1078, -0.1175, -0.0441,  0.0548,\n         0.0855, -0.0047, -0.0034,  0.0959,  0.0237,  0.1151, -0.1079,  0.0732,\n         0.1070, -0.1015, -0.0578,  0.0614, -0.0659,  0.0146, -0.0099, -0.0957]), 'meta_learner.transductive_net.classifier.3.weight': tensor([[ 0.1065, -0.0779,  0.0968,  ...,  0.0141,  0.0302, -0.0750],\n        [-0.0277,  0.0981, -0.0718,  ..., -0.0334, -0.1013, -0.0261],\n        [ 0.0943,  0.0987,  0.0076,  ...,  0.0046, -0.0965,  0.0512],\n        ...,\n        [-0.0224,  0.0322, -0.0572,  ..., -0.1148,  0.0458,  0.0291],\n        [-0.0934,  0.0273,  0.0449,  ...,  0.0975, -0.1055, -0.0207],\n        [ 0.1057, -0.1157,  0.0164,  ..., -0.0576,  0.0692,  0.0161]]), 'meta_learner.transductive_net.classifier.3.bias': tensor([-0.1186, -0.0605,  0.0666, -0.0332, -0.1057,  0.0863,  0.0786,  0.0594,\n         0.0878, -0.1002,  0.1002,  0.0085,  0.0675,  0.0037, -0.1052, -0.0554,\n         0.1141, -0.0934,  0.0576, -0.0649, -0.0117, -0.0542,  0.0931,  0.0945,\n         0.1216, -0.1164, -0.0991,  0.0269,  0.0266, -0.1201,  0.1130,  0.0329]), 'meta_learner.transductive_net.classifier.6.weight': tensor([[-0.0363, -0.0641,  0.1458, -0.1371, -0.1528, -0.1109,  0.0028, -0.0071,\n         -0.0895, -0.1368,  0.1051, -0.0672,  0.1422,  0.0030,  0.0782,  0.0820,\n         -0.1669,  0.0545,  0.1328, -0.0003,  0.0359, -0.0707, -0.1340, -0.1245,\n         -0.1623,  0.1280, -0.0214,  0.0753, -0.0647,  0.0840,  0.1069,  0.1239],\n        [ 0.1580, -0.0028, -0.0283, -0.0836,  0.1478, -0.1306,  0.1247,  0.1585,\n          0.0179, -0.0550,  0.0716, -0.0747,  0.0611, -0.1072, -0.0103, -0.1081,\n         -0.1482, -0.0897,  0.1630,  0.1430, -0.0792,  0.1295, -0.0601, -0.1046,\n          0.0111, -0.0628, -0.0953, -0.0590,  0.1021,  0.1488, -0.0243,  0.1719]]), 'meta_learner.transductive_net.classifier.6.bias': tensor([0.0991, 0.1264]), 'meta_learner.transductive_net.self_attention.in_proj_weight': tensor([[ 0.0875,  0.1425, -0.1586,  ...,  0.0752, -0.0579,  0.0277],\n        [ 0.0947,  0.1543,  0.1344,  ..., -0.1226, -0.0940,  0.0530],\n        [ 0.1063,  0.0219,  0.0272,  ..., -0.0160, -0.0658,  0.0780],\n        ...,\n        [-0.0622,  0.0858,  0.0372,  ...,  0.0043, -0.1125,  0.0635],\n        [-0.0388, -0.0711, -0.1253,  ...,  0.1237, -0.0035,  0.0151],\n        [-0.0513, -0.0657, -0.1229,  ...,  0.0499,  0.1246,  0.1083]]), 'meta_learner.transductive_net.self_attention.in_proj_bias': tensor([ 4.2708e-03, -8.1722e-03,  4.3437e-03,  1.0822e-02,  7.5650e-03,\n        -5.4276e-03, -5.6843e-03,  9.1790e-03,  5.2252e-03, -1.8930e-03,\n        -4.2104e-03, -1.0107e-02, -2.9184e-03,  2.9221e-03, -1.0593e-03,\n         5.2385e-03, -8.8472e-03, -1.1561e-02,  3.6264e-03,  6.5803e-03,\n         9.5496e-04, -8.5622e-03, -7.4604e-04, -1.1980e-02, -5.7923e-03,\n         6.2078e-03, -5.3332e-03,  4.5799e-03,  1.1049e-02,  3.5941e-03,\n        -5.1175e-03, -4.0004e-03, -7.2933e-03,  1.8983e-03,  8.4996e-04,\n        -7.7744e-03,  7.6418e-03, -8.8665e-03, -1.4412e-03, -2.8483e-03,\n         3.2641e-03, -7.4403e-03, -4.8061e-03, -4.0527e-03, -3.6890e-03,\n         3.4715e-03, -4.9058e-03,  1.5164e-03,  9.3364e-03,  1.0993e-02,\n        -1.6615e-03,  4.0064e-03,  1.2655e-02,  5.0624e-03, -1.1249e-02,\n         3.8663e-03,  2.6358e-03,  4.6319e-03, -3.5371e-03, -5.9416e-03,\n         1.9494e-04, -3.0124e-03,  7.4032e-04,  5.3745e-03,  9.4834e-05,\n        -2.5684e-05, -1.9275e-05,  5.8863e-05, -1.7616e-06, -5.6433e-05,\n         4.5341e-07, -1.1019e-05, -5.9572e-05, -4.7171e-05, -9.5086e-05,\n        -1.0120e-06, -1.1920e-05,  2.5398e-05, -1.0594e-04, -2.3236e-05,\n        -6.6720e-05,  2.3296e-05, -2.6974e-05, -4.1046e-05,  1.1008e-04,\n        -9.0914e-05,  2.6441e-05, -7.3075e-05, -1.0665e-04,  6.0752e-06,\n        -9.4657e-05,  1.0156e-05, -1.7221e-04, -5.0825e-05,  2.5452e-05,\n        -5.5251e-05, -3.3175e-05,  7.4938e-05, -1.9766e-05,  3.0984e-05,\n        -1.3305e-06,  2.9692e-05, -2.7903e-05, -1.5157e-05,  1.1928e-04,\n         2.3220e-05, -5.0674e-06,  1.9259e-05,  7.0934e-05,  8.1673e-05,\n        -3.7193e-05,  7.1565e-06, -2.2003e-05,  2.5979e-05, -5.0178e-05,\n         1.0243e-04,  3.8039e-05, -1.6521e-06, -3.5077e-05,  3.2858e-05,\n        -4.0592e-05,  1.4046e-05, -2.9079e-05,  1.6655e-05, -4.0866e-05,\n        -4.0867e-06, -1.1549e-04, -1.5321e-05,  1.6043e-04,  2.8485e-04,\n        -8.2277e-05,  8.7128e-04,  3.6546e-04,  2.8461e-05,  5.3847e-05,\n        -2.2705e-04,  9.3744e-04, -3.9406e-04, -9.7735e-05,  5.7588e-04,\n        -7.9752e-05, -3.3378e-04, -2.8330e-04,  4.1098e-04,  3.1066e-04,\n         9.7759e-05, -3.7645e-04,  1.1784e-05, -1.5128e-05,  4.4624e-04,\n        -5.1766e-05, -2.0113e-04, -6.4334e-05, -2.6025e-04,  1.0967e-04,\n         4.9102e-04, -4.1868e-04,  6.7041e-04, -3.2025e-04, -6.6815e-04,\n        -3.7276e-05, -5.1113e-04,  3.1325e-04,  2.1155e-04,  1.5304e-04,\n        -3.2213e-04, -2.5150e-04,  1.0485e-04, -6.8803e-04, -1.5271e-04,\n         1.4040e-04, -2.0331e-04, -1.9968e-04,  4.4213e-04,  2.9273e-04,\n         1.2668e-04, -2.6085e-04,  3.0593e-04, -2.4403e-04,  7.2674e-05,\n        -1.7983e-04, -4.0729e-04,  4.5271e-05,  4.8956e-05, -4.9188e-04,\n        -6.2341e-04,  8.6124e-05, -4.8237e-04, -5.0211e-04,  8.3820e-05,\n         4.7744e-04,  4.6006e-04]), 'meta_learner.transductive_net.self_attention.out_proj.weight': tensor([[ 0.0137,  0.0636, -0.0714,  ..., -0.0001, -0.0484, -0.1037],\n        [ 0.0473,  0.0281, -0.0493,  ...,  0.0219,  0.0588,  0.0641],\n        [-0.0131, -0.0312,  0.1155,  ..., -0.1060, -0.1058,  0.1053],\n        ...,\n        [ 0.0463,  0.1194, -0.0873,  ...,  0.0920, -0.0151, -0.0103],\n        [-0.0481, -0.1043, -0.0151,  ..., -0.0908,  0.0538, -0.0340],\n        [ 0.0820,  0.0102,  0.0578,  ..., -0.0828, -0.0130, -0.0767]]), 'meta_learner.transductive_net.self_attention.out_proj.bias': tensor([-5.6384e-04,  2.9018e-05,  1.6209e-05, -8.8295e-05, -6.9357e-04,\n         3.1561e-04,  7.2093e-05, -3.0999e-04,  3.1540e-04, -3.4361e-04,\n        -9.3808e-04,  3.1504e-04,  2.1526e-04, -1.8772e-04,  2.5508e-04,\n         2.4524e-04,  2.1982e-04,  2.3650e-04, -7.8273e-05,  5.8309e-04,\n         5.2451e-04, -7.7062e-04,  6.7985e-04, -4.5385e-04,  4.7079e-04,\n         9.0565e-04, -2.0546e-04, -6.5518e-04,  4.8101e-04, -2.0540e-04,\n         2.8280e-04,  3.5355e-04, -5.7285e-04,  1.1025e-03, -8.6094e-05,\n        -3.9067e-05, -2.0188e-04, -3.2686e-04,  7.2447e-04,  6.0998e-04,\n        -1.2725e-04,  4.1644e-04, -4.0129e-04,  2.2268e-04, -1.1309e-04,\n         3.8404e-04, -1.8855e-04,  2.2764e-04, -4.4956e-04, -6.5699e-04,\n        -1.8659e-04, -6.8550e-06,  8.5195e-05, -7.4792e-04,  5.4942e-04,\n         2.1172e-04, -2.1877e-04,  4.1629e-05, -6.6159e-04,  4.5175e-04,\n        -1.6155e-05,  2.0071e-04, -3.2577e-04, -1.3192e-04]), 'meta_learner.transductive_net.layer_norm.weight': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'meta_learner.transductive_net.layer_norm.bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}, sample_count=38077, training_loss=np.float64(0.1514964339137077), validation_accuracy=np.float64(0.6180000126361846), validation_precision=0.0, validation_recall=0.0, validation_f1_score=0.0, timestamp=1760224051.6613455, model_hash='8c9cc87317b7a3a1818692330888c296a974d2c2441fc1b8b371601a3d3159af', ipfs_cid=None, blockchain_tx_hash=None)",
        "ClientUpdate(client_id='client_2', model_parameters={'meta_learner.transductive_net.feature_extractors.0.0.weight': tensor([[-0.0486,  0.0607, -0.0039,  ...,  0.0774,  0.0362, -0.0178],\n        [-0.0673, -0.1119, -0.0512,  ...,  0.0981, -0.0002, -0.0529],\n        [ 0.0368,  0.0019,  0.1113,  ..., -0.0540, -0.0967, -0.1268],\n        ...,\n        [ 0.0922,  0.1143,  0.0781,  ...,  0.0546,  0.0622,  0.1052],\n        [ 0.1222,  0.0715, -0.0892,  ...,  0.0294,  0.0912,  0.1156],\n        [-0.0639,  0.0030,  0.0508,  ..., -0.0736,  0.1083, -0.1253]]), 'meta_learner.transductive_net.feature_extractors.0.0.bias': tensor([-0.0060,  0.0434,  0.0235,  0.0630,  0.1138, -0.0859,  0.0671, -0.0736,\n         0.0795, -0.0490,  0.0093,  0.0541, -0.1008, -0.0563, -0.0439, -0.0541,\n         0.1234, -0.0821, -0.1118, -0.0172, -0.0486, -0.1137,  0.0048,  0.0840,\n         0.0666,  0.0698, -0.0341,  0.0726,  0.0225, -0.0450,  0.0606,  0.0902,\n         0.0007, -0.0202, -0.0723, -0.1203,  0.0431, -0.1066, -0.1099, -0.0100,\n        -0.0992, -0.0702, -0.0454,  0.1337,  0.0954, -0.0514, -0.0420,  0.0311,\n        -0.0761, -0.0684, -0.0616,  0.0693,  0.1065,  0.0763,  0.0014,  0.0106,\n         0.0798,  0.0100, -0.0682, -0.0244,  0.1104,  0.0213,  0.0160,  0.1120,\n        -0.0565,  0.0419,  0.0346,  0.0573, -0.0112, -0.0858, -0.0679,  0.1077,\n         0.0916,  0.1029, -0.0949,  0.0083, -0.0839, -0.0264,  0.0353, -0.1427,\n        -0.0027,  0.0266,  0.1165, -0.0010, -0.0074,  0.0143, -0.0326, -0.0049,\n        -0.1008,  0.0777,  0.1213,  0.1043, -0.0197, -0.0989, -0.0808,  0.0705,\n         0.0945, -0.0323, -0.1259,  0.0210,  0.0161, -0.0967,  0.0822,  0.1091,\n        -0.0962, -0.0166, -0.0896,  0.0735, -0.0330,  0.1070, -0.0112, -0.0353,\n         0.0611,  0.1067,  0.1008, -0.0752,  0.0140,  0.1266,  0.0856, -0.0135,\n        -0.1011, -0.0867, -0.0490,  0.0815,  0.1143, -0.0763,  0.0450,  0.0958]), 'meta_learner.transductive_net.feature_extractors.1.0.weight': tensor([[-0.0207, -0.0927, -0.0003,  ..., -0.0493, -0.0467,  0.0399],\n        [ 0.0595, -0.0452, -0.0993,  ...,  0.0022, -0.1107,  0.0589],\n        [-0.0514, -0.0027,  0.0968,  ...,  0.0062, -0.0357, -0.0048],\n        ...,\n        [ 0.0653, -0.0549,  0.1062,  ..., -0.0180,  0.0725,  0.0546],\n        [ 0.0693,  0.1229,  0.0873,  ..., -0.0136,  0.0967,  0.0820],\n        [-0.0690,  0.0239,  0.1052,  ..., -0.1274, -0.0715, -0.0130]]), 'meta_learner.transductive_net.feature_extractors.1.0.bias': tensor([ 0.1095, -0.0996,  0.0285,  0.1227,  0.0070, -0.0703,  0.0260, -0.0361,\n        -0.1270,  0.1179, -0.0846,  0.0126,  0.0618, -0.0283, -0.0883, -0.0226,\n         0.0173, -0.0466, -0.0964, -0.1133,  0.0829,  0.1034,  0.0834,  0.0208,\n        -0.0630, -0.1128, -0.0099,  0.1205, -0.0941,  0.1129,  0.0534, -0.0617,\n         0.1174, -0.0562, -0.0913, -0.0485,  0.0128, -0.0859, -0.0704, -0.0833,\n         0.0940,  0.0526,  0.0785, -0.0728,  0.0352, -0.0125,  0.0333, -0.0123,\n        -0.1091,  0.0753,  0.0663,  0.0202,  0.1177,  0.0817, -0.1096,  0.0715,\n        -0.1037,  0.0545, -0.0787,  0.0524,  0.0544,  0.0761,  0.0986,  0.0924]), 'meta_learner.transductive_net.feature_extractors.2.0.weight': tensor([[-0.0625,  0.0076, -0.0578,  ...,  0.1314,  0.1330,  0.0575],\n        [-0.0759, -0.1002, -0.0847,  ...,  0.0553,  0.0385,  0.0899],\n        [-0.0668,  0.0460, -0.1020,  ...,  0.1085, -0.0399, -0.0130],\n        ...,\n        [-0.1279,  0.1052,  0.0900,  ...,  0.1283,  0.1256,  0.0425],\n        [-0.0460,  0.0643,  0.0167,  ...,  0.0315,  0.0349, -0.0243],\n        [ 0.1208,  0.0580, -0.0709,  ..., -0.0895, -0.1194, -0.0906]]), 'meta_learner.transductive_net.feature_extractors.2.0.bias': tensor([-0.0085, -0.1071,  0.1079, -0.0932, -0.0375,  0.1004,  0.0181, -0.0488,\n         0.0336, -0.1228, -0.0182,  0.0130, -0.0083, -0.0829,  0.0096,  0.1220,\n         0.0181, -0.0814, -0.0817, -0.0195,  0.0338,  0.0819,  0.0644, -0.0089,\n         0.0608,  0.0492,  0.0263,  0.0192, -0.0953, -0.0170,  0.0013,  0.0323,\n        -0.0936, -0.0898, -0.0587,  0.0425,  0.0613, -0.1246,  0.0789, -0.0829,\n        -0.1166,  0.0391,  0.0112,  0.0130, -0.0052,  0.0904,  0.0644, -0.1055,\n         0.0580, -0.0398, -0.0910, -0.0521,  0.0160, -0.0409,  0.0137, -0.0192,\n         0.1142, -0.0832, -0.0412,  0.0499,  0.1074, -0.0326,  0.1019,  0.0309,\n        -0.0439,  0.1161, -0.0581,  0.0995,  0.0590, -0.0439,  0.0847, -0.0443,\n        -0.0662, -0.0848, -0.0131, -0.0352, -0.0702, -0.1362, -0.0823, -0.0735,\n        -0.0934, -0.0492, -0.0866, -0.1157, -0.0469,  0.1144, -0.0073,  0.0716,\n         0.0922, -0.1033, -0.0367, -0.0891,  0.0375,  0.0560,  0.0814, -0.1027,\n         0.0870,  0.1035, -0.0845, -0.0673,  0.0842, -0.0615,  0.1021,  0.0869,\n        -0.0471, -0.0554,  0.0227,  0.0437,  0.0208,  0.0863,  0.0258,  0.0037,\n         0.0807, -0.0999, -0.0619, -0.0300,  0.0266,  0.0939, -0.0345, -0.0757,\n         0.0833,  0.0731, -0.0114, -0.0664,  0.0888, -0.1201, -0.0378,  0.1170,\n         0.0876, -0.0861,  0.0413, -0.0936, -0.0843, -0.1280, -0.0825, -0.0498,\n        -0.0416, -0.1075, -0.0332,  0.0247,  0.0368, -0.0870,  0.0408, -0.1165,\n        -0.0306, -0.0132,  0.1096,  0.0721,  0.0012, -0.1070, -0.0326, -0.0835,\n        -0.1188,  0.0575,  0.0538,  0.0033, -0.0448,  0.0344,  0.0440,  0.0770,\n         0.0203, -0.0386,  0.0772, -0.0161, -0.1027,  0.0520,  0.0790, -0.0535,\n        -0.0967, -0.1353,  0.0836, -0.0308, -0.1062, -0.0575,  0.0297, -0.0170,\n         0.0243, -0.0467, -0.1323,  0.0791, -0.0125, -0.1277,  0.0761, -0.0282,\n         0.0938,  0.0988, -0.0928,  0.0803,  0.0481,  0.0387, -0.0871,  0.0607,\n        -0.1291, -0.0705, -0.0465, -0.0334, -0.0649,  0.0234, -0.0895,  0.0155,\n        -0.0513,  0.1241, -0.0730, -0.0922, -0.0541, -0.0714,  0.0327, -0.0199,\n        -0.1085,  0.0682,  0.0613, -0.0287, -0.1093, -0.0560, -0.0629, -0.0006,\n         0.0025,  0.0820,  0.0852,  0.1123, -0.0773, -0.0102,  0.0493, -0.0117,\n        -0.0632,  0.1072, -0.1144,  0.0525,  0.0779, -0.1262, -0.0966, -0.0549,\n        -0.0923,  0.0781,  0.0528,  0.0656, -0.0679,  0.0696,  0.0265, -0.0976,\n         0.0331,  0.0881, -0.0693,  0.1272, -0.0938, -0.0467, -0.0659,  0.1163,\n        -0.0293,  0.0803,  0.1105,  0.0438,  0.0199,  0.1116,  0.0668, -0.1125]), 'meta_learner.transductive_net.feature_projection.0.weight': tensor([[ 6.0298e-03,  1.8491e-03,  1.4911e-02,  ...,  3.3180e-02,\n         -7.0047e-05,  3.3214e-02],\n        [ 4.2069e-02, -2.1873e-02,  2.9598e-02,  ..., -1.2018e-02,\n          4.9938e-03,  2.8056e-03],\n        [ 1.2877e-03,  3.9629e-02, -1.0886e-02,  ...,  4.0809e-02,\n         -1.5127e-02, -6.2157e-04],\n        ...,\n        [-2.9882e-02,  1.4904e-02,  3.4297e-02,  ...,  1.5126e-02,\n         -1.7639e-02, -5.2626e-03],\n        [-5.1655e-02, -7.7162e-03,  3.8801e-02,  ..., -2.5688e-02,\n         -3.3271e-02,  1.0690e-02],\n        [ 2.6903e-02, -1.9936e-02, -9.6430e-03,  ...,  1.7225e-02,\n         -3.2624e-02,  8.2623e-03]]), 'meta_learner.transductive_net.feature_projection.0.bias': tensor([-0.0202, -0.0141,  0.0388, -0.0542, -0.0219, -0.0413,  0.0363,  0.0437,\n         0.0093,  0.0307,  0.0029, -0.0112, -0.0019,  0.0088, -0.0235,  0.0184,\n        -0.0352,  0.0166, -0.0342, -0.0170, -0.0104, -0.0392,  0.0391, -0.0428,\n         0.0436, -0.0057,  0.0092,  0.0335,  0.0144, -0.0138, -0.0006,  0.0043,\n        -0.0193,  0.0199, -0.0439, -0.0299,  0.0259,  0.0399,  0.0087, -0.0009,\n        -0.0033, -0.0450,  0.0244, -0.0206, -0.0073, -0.0385,  0.0367, -0.0350,\n         0.0184,  0.0322,  0.0190, -0.0124,  0.0093,  0.0096, -0.0227, -0.0116,\n         0.0361,  0.0427,  0.0108, -0.0476, -0.0374,  0.0113, -0.0287,  0.0292]), 'meta_learner.transductive_net.classifier.0.weight': tensor([[-0.0798, -0.0640,  0.0618,  ...,  0.0527,  0.0367,  0.0822],\n        [-0.0040, -0.1191, -0.0035,  ...,  0.0933,  0.0983,  0.0601],\n        [ 0.0670,  0.0584,  0.0060,  ..., -0.0976,  0.0120,  0.0117],\n        ...,\n        [ 0.0551, -0.0309, -0.1068,  ...,  0.1001, -0.1050,  0.0780],\n        [ 0.0739,  0.1224,  0.1199,  ..., -0.0623, -0.0779,  0.1068],\n        [ 0.0644, -0.0783,  0.0179,  ..., -0.0204,  0.0500,  0.0563]]), 'meta_learner.transductive_net.classifier.0.bias': tensor([ 0.0656,  0.0336,  0.0476, -0.0905,  0.0997, -0.0569,  0.0177, -0.1162,\n         0.0851, -0.0893, -0.0266,  0.0108,  0.0409,  0.1078, -0.0202, -0.1224,\n         0.0186, -0.1141,  0.0118,  0.0528, -0.0667, -0.0512, -0.0785, -0.0906,\n         0.0695,  0.1188, -0.0726, -0.0963,  0.0445, -0.0802,  0.0792, -0.0965,\n         0.0865,  0.0096,  0.0255,  0.0686,  0.0611,  0.0731, -0.0303, -0.0435,\n         0.0484,  0.0172, -0.0874, -0.0368, -0.1078, -0.1175, -0.0441,  0.0548,\n         0.0855, -0.0047, -0.0034,  0.0959,  0.0237,  0.1151, -0.1079,  0.0732,\n         0.1070, -0.1015, -0.0578,  0.0614, -0.0659,  0.0146, -0.0099, -0.0957]), 'meta_learner.transductive_net.classifier.3.weight': tensor([[ 0.1065, -0.0779,  0.0968,  ...,  0.0141,  0.0302, -0.0750],\n        [-0.0277,  0.0981, -0.0718,  ..., -0.0334, -0.1013, -0.0261],\n        [ 0.0943,  0.0987,  0.0076,  ...,  0.0046, -0.0965,  0.0512],\n        ...,\n        [-0.0224,  0.0322, -0.0572,  ..., -0.1148,  0.0458,  0.0291],\n        [-0.0934,  0.0273,  0.0449,  ...,  0.0975, -0.1055, -0.0207],\n        [ 0.1057, -0.1157,  0.0164,  ..., -0.0576,  0.0692,  0.0161]]), 'meta_learner.transductive_net.classifier.3.bias': tensor([-0.1186, -0.0605,  0.0666, -0.0332, -0.1057,  0.0863,  0.0786,  0.0594,\n         0.0878, -0.1002,  0.1002,  0.0085,  0.0675,  0.0037, -0.1052, -0.0554,\n         0.1141, -0.0934,  0.0576, -0.0649, -0.0117, -0.0542,  0.0931,  0.0945,\n         0.1216, -0.1164, -0.0991,  0.0269,  0.0266, -0.1201,  0.1130,  0.0329]), 'meta_learner.transductive_net.classifier.6.weight': tensor([[-0.0363, -0.0641,  0.1458, -0.1371, -0.1528, -0.1109,  0.0028, -0.0071,\n         -0.0895, -0.1368,  0.1051, -0.0672,  0.1422,  0.0030,  0.0782,  0.0820,\n         -0.1669,  0.0545,  0.1328, -0.0003,  0.0359, -0.0707, -0.1340, -0.1245,\n         -0.1623,  0.1280, -0.0214,  0.0753, -0.0647,  0.0840,  0.1069,  0.1239],\n        [ 0.1580, -0.0028, -0.0283, -0.0836,  0.1478, -0.1306,  0.1247,  0.1585,\n          0.0179, -0.0550,  0.0716, -0.0747,  0.0611, -0.1072, -0.0103, -0.1081,\n         -0.1482, -0.0897,  0.1630,  0.1430, -0.0792,  0.1295, -0.0601, -0.1046,\n          0.0111, -0.0628, -0.0953, -0.0590,  0.1021,  0.1488, -0.0243,  0.1719]]), 'meta_learner.transductive_net.classifier.6.bias': tensor([0.0991, 0.1264]), 'meta_learner.transductive_net.self_attention.in_proj_weight': tensor([[ 0.0686,  0.1224, -0.1518,  ...,  0.0857, -0.0467,  0.0221],\n        [ 0.1010,  0.1565,  0.1291,  ..., -0.1256, -0.1031,  0.0486],\n        [ 0.1016,  0.0097,  0.0170,  ...,  0.0008, -0.0602,  0.0889],\n        ...,\n        [-0.0684,  0.0894,  0.0297,  ..., -0.0016, -0.1157,  0.0621],\n        [-0.0383, -0.0691, -0.1342,  ...,  0.1207, -0.0104,  0.0170],\n        [-0.0481, -0.0560, -0.1146,  ...,  0.0452,  0.1235,  0.1189]]), 'meta_learner.transductive_net.self_attention.in_proj_bias': tensor([-6.9108e-03, -2.6982e-03, -5.2388e-03,  1.5123e-03, -4.1977e-04,\n        -9.9270e-03, -3.7353e-03,  3.3937e-03,  9.3304e-03, -7.0001e-03,\n         4.6375e-03,  1.3934e-02, -4.8149e-04,  1.0674e-02, -7.3507e-03,\n        -1.4839e-02, -6.0354e-03, -8.1678e-03,  3.1289e-03,  2.4956e-03,\n        -8.1787e-03, -3.0882e-03, -7.0862e-03, -3.4124e-03, -2.0739e-03,\n        -2.7555e-03, -4.7579e-03,  3.4596e-03,  1.3953e-03, -3.6011e-03,\n        -2.8446e-05, -5.4784e-03,  1.1016e-03, -1.4802e-03, -3.7892e-03,\n         6.1390e-03, -2.0884e-03, -3.1090e-03,  1.6483e-03,  4.2568e-03,\n        -2.3454e-04,  5.7960e-03, -1.5758e-04, -6.1610e-04,  6.4829e-03,\n         7.5990e-03, -4.0963e-04, -2.8295e-03, -7.0886e-03,  6.7806e-03,\n        -1.7825e-03,  2.7321e-03,  9.7224e-03,  6.4905e-03, -6.5929e-03,\n        -7.0539e-03,  2.0252e-03,  9.7813e-03, -8.4579e-03,  2.1422e-03,\n        -3.5620e-03, -4.3088e-03, -2.5820e-03, -2.3672e-03, -6.8318e-05,\n         1.1228e-04,  9.4621e-05,  9.4752e-05,  1.2294e-04, -3.2771e-05,\n        -1.2843e-04,  1.6459e-04, -9.9604e-05, -3.6064e-05, -4.3006e-05,\n         8.2288e-05,  2.2000e-05, -1.5281e-04,  1.9137e-04, -2.0361e-04,\n        -2.0707e-04, -7.8246e-05,  9.3432e-05,  1.4409e-04,  2.3214e-04,\n        -3.2339e-05,  1.4143e-04,  1.7004e-04, -2.5244e-04,  5.6522e-05,\n         7.9766e-05, -6.6886e-05, -1.4627e-04,  1.5003e-05,  8.5683e-06,\n         2.0751e-04,  3.3044e-05,  4.9644e-05,  2.4162e-07,  1.3111e-05,\n         1.6188e-05, -5.5209e-06, -5.2026e-05, -1.7190e-04,  4.5033e-05,\n        -7.5258e-05, -2.0705e-06, -2.7278e-05,  8.5680e-05,  8.0075e-05,\n         4.6337e-05,  3.7044e-06,  1.5630e-05,  5.5083e-05, -1.7821e-05,\n        -1.8250e-05,  6.3237e-05, -5.9759e-05,  4.6156e-06,  1.0701e-04,\n        -2.2093e-05,  1.4108e-06,  5.6623e-05, -5.7783e-08, -8.3718e-06,\n         1.6454e-05, -5.6161e-05,  1.0601e-05, -5.6474e-04,  3.0948e-04,\n        -1.2309e-04, -7.3622e-04,  7.4850e-05,  5.5916e-04,  3.1716e-04,\n         4.3790e-04,  6.6856e-04, -8.2259e-04,  7.3378e-04,  4.2168e-04,\n        -6.7168e-04,  3.8531e-04,  2.0446e-04, -3.5783e-04, -1.7629e-04,\n         7.5460e-04,  4.7229e-04, -2.4718e-04,  1.1644e-03,  2.1607e-04,\n         1.2655e-05, -3.1154e-04,  5.7578e-05,  4.8419e-04, -2.1778e-04,\n        -4.8030e-04, -1.1872e-04, -1.1346e-04,  4.7775e-04, -3.8592e-04,\n        -3.7497e-04,  1.3301e-04, -1.4147e-04,  5.0954e-04,  4.8486e-04,\n         5.1877e-05, -2.1066e-04, -9.7774e-04, -3.3001e-04,  3.3387e-04,\n         3.3897e-04,  1.9275e-05,  1.9830e-04,  6.3390e-04,  1.6277e-04,\n         3.3997e-04,  2.3277e-04, -7.2524e-04,  3.9145e-04, -3.3339e-04,\n        -1.8030e-04,  1.2954e-05, -3.0190e-04,  7.2495e-05,  2.0685e-05,\n         3.2897e-04,  1.4710e-05, -5.6385e-04, -5.0605e-04,  3.5003e-04,\n         4.9090e-04,  7.4954e-04]), 'meta_learner.transductive_net.self_attention.out_proj.weight': tensor([[ 0.0238,  0.0619, -0.0791,  ..., -0.0094, -0.0539, -0.1111],\n        [ 0.0432,  0.0312, -0.0448,  ...,  0.0217,  0.0593,  0.0492],\n        [-0.0079, -0.0247,  0.0911,  ..., -0.1036, -0.1122,  0.0975],\n        ...,\n        [ 0.0470,  0.1177, -0.0752,  ...,  0.0948, -0.0077, -0.0113],\n        [-0.0527, -0.1132, -0.0070,  ..., -0.0912,  0.0552, -0.0336],\n        [ 0.0710,  0.0007,  0.0590,  ..., -0.0726, -0.0146, -0.0684]]), 'meta_learner.transductive_net.self_attention.out_proj.bias': tensor([-1.0036e-04,  1.8127e-04, -4.9547e-04,  2.6143e-04,  7.1464e-04,\n        -1.0761e-04,  3.8257e-04,  1.3378e-04, -3.6485e-04, -1.4016e-05,\n         3.7717e-05, -6.7345e-04,  1.1427e-04, -5.5107e-04,  1.3758e-04,\n         2.4933e-04,  6.1258e-04, -2.5703e-04, -7.8848e-04,  8.0717e-04,\n        -3.8819e-04, -4.3311e-04, -2.5832e-04, -8.1718e-04, -3.6390e-04,\n        -2.5230e-04,  1.1400e-04, -3.4170e-04,  3.5207e-04, -5.1237e-04,\n        -4.0996e-05,  4.4971e-04,  4.5282e-04,  5.4699e-04, -1.2656e-04,\n        -2.8581e-04, -1.4991e-04,  1.3797e-04,  4.7370e-05,  7.8758e-04,\n         3.9107e-06, -3.9004e-04,  1.0584e-04,  4.0900e-04,  2.6681e-04,\n        -6.0725e-04,  2.6399e-04, -5.2475e-04, -2.0811e-04, -4.7648e-04,\n         8.0289e-04, -3.2148e-05,  1.7588e-05, -1.7528e-04,  1.5807e-04,\n         5.1146e-04, -7.5036e-04,  4.6059e-04,  6.1382e-04, -1.9009e-04,\n         6.5509e-05, -6.3340e-05, -1.3663e-04, -1.4932e-04]), 'meta_learner.transductive_net.layer_norm.weight': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'meta_learner.transductive_net.layer_norm.bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}, sample_count=76988, training_loss=np.float64(0.12517704132944346), validation_accuracy=np.float64(0.7440000081062317), validation_precision=0.0, validation_recall=0.0, validation_f1_score=0.0, timestamp=1760224051.9456825, model_hash='b0ca4100cb1a16c3959dba9dd8b9be182b182d00720ea50b3cfff955d0e7feef', ipfs_cid=None, blockchain_tx_hash=None)",
        "ClientUpdate(client_id='client_3', model_parameters={'meta_learner.transductive_net.feature_extractors.0.0.weight': tensor([[-0.0476,  0.0620, -0.0002,  ...,  0.0633,  0.0311, -0.0178],\n        [-0.0630, -0.1076, -0.0469,  ...,  0.0945, -0.0015, -0.0529],\n        [ 0.0402,  0.0054,  0.1051,  ..., -0.0555, -0.0954, -0.1268],\n        ...,\n        [ 0.1055,  0.1274,  0.0699,  ...,  0.0508,  0.0664,  0.1052],\n        [ 0.1023,  0.0515, -0.1082,  ...,  0.0411,  0.1032,  0.1156],\n        [-0.0691, -0.0023,  0.0557,  ..., -0.0706,  0.1051, -0.1253]]), 'meta_learner.transductive_net.feature_extractors.0.0.bias': tensor([ 0.0035,  0.0391,  0.0281,  0.0607,  0.1101, -0.0952,  0.0592, -0.0612,\n         0.0906, -0.0365,  0.0145,  0.0606, -0.0999, -0.0519, -0.0453, -0.0507,\n         0.1226, -0.0760, -0.1134, -0.0260, -0.0629, -0.1139,  0.0039,  0.0729,\n         0.0765,  0.0676, -0.0424,  0.0713,  0.0114, -0.0413,  0.0719,  0.0939,\n         0.0162, -0.0143, -0.0813, -0.1204,  0.0430, -0.1138, -0.1058, -0.0205,\n        -0.1246, -0.0648, -0.0493,  0.1343,  0.0862, -0.0444, -0.0407,  0.0250,\n        -0.0785, -0.0582, -0.0636,  0.0759,  0.1035,  0.0636,  0.0048,  0.0221,\n         0.0801,  0.0187, -0.0519, -0.0383,  0.1273,  0.0192,  0.0006,  0.1172,\n        -0.0707,  0.0394,  0.0227,  0.0586, -0.0108, -0.0850, -0.0569,  0.1005,\n         0.0931,  0.1012, -0.0903,  0.0162, -0.0960, -0.0388,  0.0584, -0.1322,\n         0.0155,  0.0227,  0.1301, -0.0094, -0.0070,  0.0236, -0.0446,  0.0026,\n        -0.0988,  0.0771,  0.1099,  0.1052, -0.0274, -0.0960, -0.0936,  0.0616,\n         0.1105, -0.0338, -0.1282,  0.0180,  0.0166, -0.1086,  0.0838,  0.1119,\n        -0.1143, -0.0070, -0.0837,  0.0543, -0.0393,  0.0999, -0.0152, -0.0299,\n         0.0740,  0.1169,  0.0922, -0.0701,  0.0072,  0.1313,  0.0946, -0.0061,\n        -0.1060, -0.0915, -0.0447,  0.0775,  0.0981, -0.0920,  0.0641,  0.1011]), 'meta_learner.transductive_net.feature_extractors.1.0.weight': tensor([[-0.0331, -0.1052, -0.0127,  ..., -0.0573, -0.0313,  0.0399],\n        [ 0.0615, -0.0432, -0.0974,  ..., -0.0070, -0.1196,  0.0589],\n        [-0.0591, -0.0103,  0.0940,  ...,  0.0116, -0.0402, -0.0048],\n        ...,\n        [ 0.0708, -0.0489,  0.1075,  ..., -0.0215,  0.0735,  0.0546],\n        [ 0.0573,  0.1108,  0.0824,  ..., -0.0180,  0.1158,  0.0820],\n        [-0.0690,  0.0239,  0.1091,  ..., -0.1167, -0.0661, -0.0130]]), 'meta_learner.transductive_net.feature_extractors.1.0.bias': tensor([ 0.1220, -0.1016,  0.0361,  0.1199, -0.0101, -0.0689,  0.0228, -0.0258,\n        -0.1152,  0.1071, -0.0802,  0.0069,  0.0480, -0.0305, -0.1014, -0.0299,\n         0.0285, -0.0487, -0.1013, -0.1242,  0.0836,  0.1034,  0.0866,  0.0236,\n        -0.0557, -0.1032,  0.0087,  0.1053, -0.0789,  0.1122,  0.0411, -0.0648,\n         0.1145, -0.0591, -0.0783, -0.0333,  0.0116, -0.0741, -0.0801, -0.0848,\n         0.0904,  0.0428,  0.0652, -0.0743,  0.0160, -0.0232,  0.0288, -0.0093,\n        -0.0954,  0.0621,  0.0614,  0.0141,  0.1100,  0.0787, -0.1071,  0.0656,\n        -0.1131,  0.0575, -0.0842,  0.0497,  0.0586,  0.0724,  0.1106,  0.0924]), 'meta_learner.transductive_net.feature_extractors.2.0.weight': tensor([[-0.0657,  0.0044, -0.0610,  ...,  0.1154,  0.1093,  0.0575],\n        [-0.0703, -0.0946, -0.0766,  ...,  0.0617,  0.0418,  0.0899],\n        [-0.0673,  0.0464, -0.1115,  ...,  0.1073, -0.0458, -0.0130],\n        ...,\n        [-0.1313,  0.1017,  0.0878,  ...,  0.1238,  0.1232,  0.0425],\n        [-0.0554,  0.0554, -0.0020,  ...,  0.0315,  0.0420, -0.0243],\n        [ 0.1170,  0.0547, -0.0776,  ..., -0.1013, -0.1281, -0.0906]]), 'meta_learner.transductive_net.feature_extractors.2.0.bias': tensor([-0.0053, -0.1128,  0.1137, -0.0869, -0.0363,  0.1052,  0.0367, -0.0473,\n         0.0390, -0.1240, -0.0253,  0.0097, -0.0016, -0.0750,  0.0220,  0.1185,\n         0.0033, -0.0748, -0.0764, -0.0120,  0.0186,  0.0840,  0.0594, -0.0068,\n         0.0606,  0.0559,  0.0276,  0.0106, -0.1059, -0.0141, -0.0132,  0.0253,\n        -0.0833, -0.0859, -0.0588,  0.0453,  0.0590, -0.1154,  0.0642, -0.0806,\n        -0.1188,  0.0383,  0.0073,  0.0173, -0.0024,  0.0843,  0.0642, -0.1122,\n         0.0677, -0.0593, -0.0913, -0.0427,  0.0035, -0.0314,  0.0156, -0.0163,\n         0.1145, -0.0972, -0.0418,  0.0543,  0.1103, -0.0348,  0.0892,  0.0269,\n        -0.0590,  0.0971, -0.0457,  0.0863,  0.0621, -0.0273,  0.0874, -0.0424,\n        -0.0680, -0.0821, -0.0216, -0.0242, -0.0838, -0.1160, -0.0800, -0.0493,\n        -0.0717, -0.0474, -0.0855, -0.1098, -0.0250,  0.1340, -0.0029,  0.0682,\n         0.1009, -0.0874, -0.0353, -0.0945,  0.0498,  0.0538,  0.0680, -0.1109,\n         0.0717,  0.1087, -0.1005, -0.0566,  0.1011, -0.0702,  0.1163,  0.0705,\n        -0.0506, -0.0489,  0.0220,  0.0364,  0.0145,  0.0720,  0.0124, -0.0005,\n         0.0792, -0.0950, -0.0586, -0.0366,  0.0156,  0.0959, -0.0372, -0.0762,\n         0.0899,  0.0825, -0.0024, -0.0664,  0.0937, -0.1197, -0.0486,  0.1160,\n         0.0723, -0.0857,  0.0321, -0.0971, -0.0904, -0.1158, -0.0829, -0.0629,\n        -0.0448, -0.1082, -0.0185,  0.0169,  0.0360, -0.0794,  0.0333, -0.1099,\n        -0.0300, -0.0292,  0.1221,  0.0723,  0.0102, -0.0928, -0.0328, -0.0808,\n        -0.1239,  0.0457,  0.0612,  0.0034, -0.0341,  0.0426,  0.0410,  0.0955,\n         0.0231, -0.0321,  0.0778, -0.0121, -0.0955,  0.0473,  0.0836, -0.0379,\n        -0.1093, -0.1237,  0.0767, -0.0324, -0.1149, -0.0714,  0.0205, -0.0063,\n         0.0273, -0.0406, -0.1190,  0.0880,  0.0002, -0.1190,  0.0744, -0.0234,\n         0.0924,  0.0938, -0.0961,  0.0855,  0.0770,  0.0466, -0.0997,  0.0514,\n        -0.1291, -0.0577, -0.0421, -0.0246, -0.0670,  0.0289, -0.0940,  0.0060,\n        -0.0661,  0.1231, -0.0722, -0.0822, -0.0449, -0.0622,  0.0345, -0.0214,\n        -0.1082,  0.0543,  0.0719, -0.0410, -0.1032, -0.0484, -0.0709,  0.0038,\n         0.0138,  0.0786,  0.0942,  0.1116, -0.0731, -0.0023,  0.0479, -0.0076,\n        -0.0750,  0.1069, -0.1021,  0.0695,  0.0861, -0.1287, -0.1119, -0.0613,\n        -0.1083,  0.0741,  0.0582,  0.0781, -0.0696,  0.0713,  0.0433, -0.1002,\n         0.0214,  0.0854, -0.0672,  0.1189, -0.1025, -0.0681, -0.0687,  0.1322,\n        -0.0385,  0.0773,  0.1053,  0.0268,  0.0316,  0.1106,  0.0892, -0.1084]), 'meta_learner.transductive_net.feature_projection.0.weight': tensor([[-0.0056, -0.0031,  0.0115,  ...,  0.0132,  0.0120,  0.0144],\n        [ 0.0512, -0.0149,  0.0354,  ..., -0.0098,  0.0100, -0.0035],\n        [ 0.0204,  0.0423, -0.0078,  ...,  0.0481, -0.0097,  0.0134],\n        ...,\n        [-0.0422,  0.0073,  0.0326,  ...,  0.0039, -0.0141, -0.0036],\n        [-0.0464, -0.0122,  0.0284,  ..., -0.0178, -0.0159,  0.0023],\n        [ 0.0495, -0.0173, -0.0086,  ...,  0.0108, -0.0457,  0.0206]]), 'meta_learner.transductive_net.feature_projection.0.bias': tensor([-0.0263, -0.0113,  0.0400, -0.0473, -0.0244, -0.0360,  0.0284,  0.0473,\n         0.0204,  0.0403,  0.0043, -0.0036,  0.0062,  0.0083, -0.0287,  0.0273,\n        -0.0309,  0.0180, -0.0343, -0.0151,  0.0115, -0.0469,  0.0298, -0.0248,\n         0.0412, -0.0138,  0.0063,  0.0495,  0.0227, -0.0172, -0.0007,  0.0058,\n        -0.0120,  0.0309, -0.0402, -0.0255,  0.0194,  0.0171,  0.0172, -0.0100,\n        -0.0012, -0.0412,  0.0329, -0.0291, -0.0157, -0.0306,  0.0191, -0.0305,\n         0.0263,  0.0294,  0.0238, -0.0092, -0.0041,  0.0178, -0.0254, -0.0237,\n         0.0229,  0.0297, -0.0034, -0.0536, -0.0310,  0.0102, -0.0132,  0.0268]), 'meta_learner.transductive_net.classifier.0.weight': tensor([[-0.0798, -0.0640,  0.0618,  ...,  0.0527,  0.0367,  0.0822],\n        [-0.0040, -0.1191, -0.0035,  ...,  0.0933,  0.0983,  0.0601],\n        [ 0.0670,  0.0584,  0.0060,  ..., -0.0976,  0.0120,  0.0117],\n        ...,\n        [ 0.0551, -0.0309, -0.1068,  ...,  0.1001, -0.1050,  0.0780],\n        [ 0.0739,  0.1224,  0.1199,  ..., -0.0623, -0.0779,  0.1068],\n        [ 0.0644, -0.0783,  0.0179,  ..., -0.0204,  0.0500,  0.0563]]), 'meta_learner.transductive_net.classifier.0.bias': tensor([ 0.0656,  0.0336,  0.0476, -0.0905,  0.0997, -0.0569,  0.0177, -0.1162,\n         0.0851, -0.0893, -0.0266,  0.0108,  0.0409,  0.1078, -0.0202, -0.1224,\n         0.0186, -0.1141,  0.0118,  0.0528, -0.0667, -0.0512, -0.0785, -0.0906,\n         0.0695,  0.1188, -0.0726, -0.0963,  0.0445, -0.0802,  0.0792, -0.0965,\n         0.0865,  0.0096,  0.0255,  0.0686,  0.0611,  0.0731, -0.0303, -0.0435,\n         0.0484,  0.0172, -0.0874, -0.0368, -0.1078, -0.1175, -0.0441,  0.0548,\n         0.0855, -0.0047, -0.0034,  0.0959,  0.0237,  0.1151, -0.1079,  0.0732,\n         0.1070, -0.1015, -0.0578,  0.0614, -0.0659,  0.0146, -0.0099, -0.0957]), 'meta_learner.transductive_net.classifier.3.weight': tensor([[ 0.1065, -0.0779,  0.0968,  ...,  0.0141,  0.0302, -0.0750],\n        [-0.0277,  0.0981, -0.0718,  ..., -0.0334, -0.1013, -0.0261],\n        [ 0.0943,  0.0987,  0.0076,  ...,  0.0046, -0.0965,  0.0512],\n        ...,\n        [-0.0224,  0.0322, -0.0572,  ..., -0.1148,  0.0458,  0.0291],\n        [-0.0934,  0.0273,  0.0449,  ...,  0.0975, -0.1055, -0.0207],\n        [ 0.1057, -0.1157,  0.0164,  ..., -0.0576,  0.0692,  0.0161]]), 'meta_learner.transductive_net.classifier.3.bias': tensor([-0.1186, -0.0605,  0.0666, -0.0332, -0.1057,  0.0863,  0.0786,  0.0594,\n         0.0878, -0.1002,  0.1002,  0.0085,  0.0675,  0.0037, -0.1052, -0.0554,\n         0.1141, -0.0934,  0.0576, -0.0649, -0.0117, -0.0542,  0.0931,  0.0945,\n         0.1216, -0.1164, -0.0991,  0.0269,  0.0266, -0.1201,  0.1130,  0.0329]), 'meta_learner.transductive_net.classifier.6.weight': tensor([[-0.0363, -0.0641,  0.1458, -0.1371, -0.1528, -0.1109,  0.0028, -0.0071,\n         -0.0895, -0.1368,  0.1051, -0.0672,  0.1422,  0.0030,  0.0782,  0.0820,\n         -0.1669,  0.0545,  0.1328, -0.0003,  0.0359, -0.0707, -0.1340, -0.1245,\n         -0.1623,  0.1280, -0.0214,  0.0753, -0.0647,  0.0840,  0.1069,  0.1239],\n        [ 0.1580, -0.0028, -0.0283, -0.0836,  0.1478, -0.1306,  0.1247,  0.1585,\n          0.0179, -0.0550,  0.0716, -0.0747,  0.0611, -0.1072, -0.0103, -0.1081,\n         -0.1482, -0.0897,  0.1630,  0.1430, -0.0792,  0.1295, -0.0601, -0.1046,\n          0.0111, -0.0628, -0.0953, -0.0590,  0.1021,  0.1488, -0.0243,  0.1719]]), 'meta_learner.transductive_net.classifier.6.bias': tensor([0.0991, 0.1264]), 'meta_learner.transductive_net.self_attention.in_proj_weight': tensor([[ 0.0797,  0.1488, -0.1620,  ...,  0.0784, -0.0463,  0.0220],\n        [ 0.0950,  0.1474,  0.1294,  ..., -0.1155, -0.0921,  0.0527],\n        [ 0.1085,  0.0209,  0.0142,  ..., -0.0137, -0.0640,  0.0810],\n        ...,\n        [-0.0598,  0.0973,  0.0477,  ...,  0.0124, -0.1237,  0.0660],\n        [-0.0391, -0.0579, -0.1109,  ...,  0.1205, -0.0120,  0.0148],\n        [-0.0460, -0.0683, -0.1265,  ...,  0.0419,  0.1326,  0.1194]]), 'meta_learner.transductive_net.self_attention.in_proj_bias': tensor([ 2.3422e-03, -2.5308e-04, -2.3849e-03,  2.4212e-03, -2.6185e-03,\n        -5.6230e-03,  6.9625e-03,  2.5350e-03, -4.5864e-03,  9.7192e-03,\n        -5.4272e-03, -6.2705e-03,  8.9809e-04, -3.1650e-03,  9.8809e-03,\n         2.6477e-04, -1.4003e-03, -1.5020e-03, -5.7213e-03,  1.1246e-02,\n        -5.6135e-03, -5.6562e-03, -9.5027e-03, -1.1099e-02,  8.3213e-03,\n         4.8619e-03,  3.1354e-03,  1.6107e-03,  2.0396e-03, -7.6420e-03,\n         2.3877e-04, -3.7190e-03,  7.4782e-03, -4.2048e-03,  7.1244e-03,\n        -1.1683e-03,  4.0648e-03, -1.0507e-03,  8.1650e-03, -3.9304e-03,\n        -7.1338e-03,  1.0564e-02,  1.2177e-02,  4.1615e-03,  4.1401e-03,\n         1.7122e-03,  3.5736e-04, -4.5892e-04,  3.4216e-03, -1.2350e-02,\n         8.0252e-03, -1.1817e-03,  7.4397e-03,  3.0436e-03, -7.1779e-03,\n        -1.0094e-02,  1.5876e-03, -4.3555e-03,  3.3497e-03,  2.0483e-04,\n        -3.7553e-03,  3.5593e-04, -1.1159e-02, -4.1493e-03, -1.1482e-06,\n        -2.3566e-05,  2.8619e-05, -7.0983e-05,  6.7714e-05, -2.1007e-05,\n         5.5313e-06,  5.6435e-05,  8.2763e-05, -2.8657e-05,  5.1179e-05,\n         5.5730e-06,  1.2506e-04,  1.9117e-05,  2.0254e-05, -1.0440e-05,\n        -5.3698e-06, -3.7286e-05, -5.5026e-05, -5.8549e-05, -1.0243e-04,\n        -3.9604e-05,  5.1149e-05, -2.2419e-05,  3.5666e-05, -3.1172e-05,\n        -4.3741e-05, -2.6369e-05,  2.5034e-05, -2.5814e-05,  1.5300e-05,\n        -3.6567e-05, -1.6750e-05,  2.7010e-05, -1.0316e-05, -6.8438e-05,\n         4.4005e-05, -6.9131e-05,  7.6715e-05, -2.5351e-05, -1.5770e-05,\n        -4.8204e-05, -3.4120e-05,  7.3294e-05,  5.8265e-05, -1.2325e-05,\n         1.1453e-05,  5.7067e-05, -6.2596e-05, -1.5924e-05,  1.8052e-05,\n        -3.0645e-06,  2.2539e-05, -5.4193e-05, -1.4753e-05,  3.9894e-05,\n         1.3980e-04,  3.8576e-05,  6.8878e-05, -7.4418e-05, -4.2651e-05,\n        -2.3366e-05, -2.3933e-05,  6.3791e-05, -2.8016e-04, -5.0895e-04,\n        -3.0074e-05,  1.2177e-04,  2.3994e-04, -5.2286e-04, -6.1665e-04,\n        -9.1486e-05,  1.9408e-04,  1.1707e-03, -7.3482e-04, -2.5962e-05,\n        -5.6922e-04,  1.1238e-05,  2.7766e-06,  2.2826e-04,  4.1854e-04,\n         2.0766e-04, -2.0998e-05,  9.3775e-05,  7.4844e-04,  2.7239e-04,\n        -2.1475e-04, -3.2046e-04,  6.6279e-06,  1.8213e-04, -2.5752e-04,\n         4.5187e-05, -3.8578e-05, -5.5846e-04,  4.2469e-04,  2.7511e-04,\n         2.6571e-04,  1.2688e-04,  3.7593e-04,  2.6464e-04, -1.9310e-04,\n         4.4835e-04, -2.8228e-05, -2.3025e-04, -3.8306e-04,  6.9382e-05,\n        -8.4556e-05,  2.0366e-04, -2.1794e-04,  4.0487e-04,  2.0460e-04,\n        -5.6977e-04, -1.0793e-03, -3.2366e-04, -1.4893e-04,  1.1227e-04,\n        -1.4558e-04,  3.1213e-04, -1.8957e-04,  5.5084e-05, -1.6992e-04,\n        -4.9880e-04,  2.0269e-04, -3.1756e-04,  4.9768e-04,  2.9982e-04,\n        -1.8111e-04,  1.7105e-04]), 'meta_learner.transductive_net.self_attention.out_proj.weight': tensor([[ 0.0123,  0.0591, -0.0657,  ...,  0.0012, -0.0608, -0.1022],\n        [ 0.0428,  0.0296, -0.0329,  ...,  0.0436,  0.0593,  0.0573],\n        [-0.0018, -0.0181,  0.1076,  ..., -0.0996, -0.1129,  0.0974],\n        ...,\n        [ 0.0413,  0.1057, -0.0756,  ...,  0.0806, -0.0048,  0.0062],\n        [-0.0546, -0.1072, -0.0205,  ..., -0.1032,  0.0541, -0.0432],\n        [ 0.0686, -0.0086,  0.0506,  ..., -0.0858, -0.0105, -0.0722]]), 'meta_learner.transductive_net.self_attention.out_proj.bias': tensor([-6.0204e-04,  1.7173e-04, -5.4307e-05,  3.6376e-04, -4.2673e-04,\n         1.2575e-05,  2.9870e-04, -2.2439e-04, -6.2085e-04,  2.9214e-04,\n        -2.5606e-04,  2.7570e-04, -5.8158e-04, -3.7790e-04,  1.0754e-04,\n         3.5158e-04, -2.7447e-04,  1.6105e-04, -1.8862e-04, -4.5297e-04,\n        -3.0718e-04, -1.3437e-04, -1.0537e-03, -2.7830e-05, -1.9081e-04,\n         6.5597e-04,  1.9904e-04,  5.6953e-04,  3.7588e-04,  1.8753e-04,\n         8.1609e-04,  5.5248e-04,  2.5383e-04,  2.4858e-05, -1.3657e-04,\n         1.2430e-04,  1.5816e-04, -3.4155e-04, -1.5622e-04,  6.2957e-04,\n        -1.2751e-04,  2.6233e-04, -9.5920e-05, -1.3279e-04, -1.5358e-04,\n         1.9043e-05,  6.0498e-06, -2.1577e-04, -1.0817e-04, -1.9278e-04,\n         1.0488e-04, -2.8460e-04, -6.8099e-04,  1.5672e-04,  2.9022e-04,\n        -2.3637e-04,  4.8184e-04,  2.1442e-05, -2.3501e-05, -1.1658e-04,\n         2.5623e-04,  3.9133e-05,  2.2123e-04, -9.4522e-05]), 'meta_learner.transductive_net.layer_norm.weight': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'meta_learner.transductive_net.layer_norm.bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}, sample_count=34932, training_loss=np.float64(0.15784794390201567), validation_accuracy=np.float64(0.6240000092983247), validation_precision=0.0, validation_recall=0.0, validation_f1_score=0.0, timestamp=1760224052.2331023, model_hash='af0c863e363c9c05bf516854690db474dd44e76e48f943da540f080251cc873b', ipfs_cid=None, blockchain_tx_hash=None)"
      ],
      "aggregation_result": "AggregationResult(round_number=0, aggregated_parameters={}, client_contributions={'client_1': 0.2538517437015407, 'client_2': 0.5132635986053055, 'client_3': 0.23288465769315386}, aggregation_time=0.001999378204345703, model_hash='model_round_0_1760224063', ipfs_cid='QmZ2Ke3eE1dabgguC1oYmr6thmeAV5uTFXjWT1H1oHhmUc', blockchain_tx_hash='5c37025a58c927bfb37de922464653ff78aedcef798c0a4f4cc63aa9ac739d1d')",
      "timestamp": 1760224066.995453
    }
  ],
  "incentive_history": [],
  "client_addresses": {},
  "config": {
    "data_path": "../DNN-EdgeIIoT-dataset.csv",
    "zero_day_attack": "DDoS_TCP",
    "available_attacks": [
      "DDoS_UDP",
      "DDoS_ICMP",
      "SQL_injection",
      "Password",
      "Vulnerability_scanner",
      "DDoS_TCP",
      "DDoS_HTTP",
      "Uploading",
      "Backdoor",
      "Port_Scanning",
      "XSS",
      "Ransomware",
      "MITM",
      "Fingerprinting"
    ],
    "input_dim": 62,
    "hidden_dim": 128,
    "embedding_dim": 64,
    "use_fully_decentralized": false,
    "support_weight": 0.3,
    "test_weight": 0.7,
    "n_way": 2,
    "k_shot": 5,
    "n_query": 15,
    "n_tasks": 10,
    "num_clients": 3,
    "num_rounds": 1,
    "learning_rate": 0.001,
    "ethereum_rpc_url": "http://localhost:8545",
    "contract_address": "0x1234567890123456789012345678901234567890",
    "ipfs_url": "http://localhost:5001",
    "enable_incentives": true,
    "incentive_contract_address": "0x1234567890123456789012345678901234567890",
    "private_key": "0x1234567890123456789012345678901234567890123456789012345678901234",
    "aggregator_address": "0x1234567890123456789012345678901234567890",
    "batch_size": 32,
    "ttt_steps": 200,
    "support_size": 50,
    "query_size": 450,
    "device": "cuda",
    "enable_blockchain": true,
    "max_samples_per_client": 50000,
    "use_data_sampling": true
  }
}