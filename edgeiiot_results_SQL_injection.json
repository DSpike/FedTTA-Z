{
  "base_model": {
    "accuracy_mean": 0.5,
    "accuracy_std": 0.00012248673581272932,
    "macro_f1_mean": 0.33333334222400035,
    "macro_f1_std": 0.00013609637218145015,
    "mcc_mean": 0.0,
    "mcc_std": 0.0,
    "confusion_matrix": [
      [
        0,
        1666
      ],
      [
        0,
        1667
      ]
    ],
    "roc_curve": {
      "fpr": [
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0006002400960384153,
        0.0006002400960384153,
        0.0012004801920768306,
        0.0012004801920768306,
        0.004801920768307323,
        0.004801920768307323,
        0.006002400960384154,
        0.007202881152460984,
        0.014405762304921969,
        0.014405762304921969,
        0.015606242496998799,
        0.015606242496998799,
        0.015606242496998799,
        0.02581032412965186,
        0.02581032412965186,
        0.02701080432172869,
        0.028211284513805522,
        0.03241296518607443,
        0.03241296518607443,
        0.033013205282112844,
        0.03721488595438175,
        0.040216086434573826,
        0.040216086434573826,
        0.057623049219687875,
        0.057623049219687875,
        0.06062424969987995,
        0.06062424969987995,
        0.06182472989195678,
        0.06182472989195678,
        0.062424969987995196,
        0.062424969987995196,
        0.06302521008403361,
        0.06302521008403361,
        0.06902761104441776,
        0.06902761104441776,
        0.06962785114045618,
        0.06962785114045618,
        0.08403361344537816,
        0.08403361344537816,
        0.08643457382953182,
        0.08643457382953182,
        0.09063625450180073,
        0.09183673469387756,
        0.10024009603841537,
        0.10024009603841537,
        0.10204081632653061,
        0.10204081632653061,
        0.10324129651860744,
        0.10324129651860744,
        0.10444177671068428,
        0.10444177671068428,
        0.10504201680672269,
        0.10504201680672269,
        0.11764705882352941,
        0.11764705882352941,
        0.12004801920768307,
        0.1212484993997599,
        0.12364945978391356,
        0.12364945978391356,
        0.13205282112845138,
        0.13205282112845138,
        0.13385354141656663,
        0.13385354141656663,
        0.13445378151260504,
        0.13445378151260504,
        0.13565426170468187,
        0.13565426170468187,
        0.1368547418967587,
        0.1368547418967587,
        0.14225690276110445,
        0.14225690276110445,
        0.1482593037214886,
        0.1482593037214886,
        0.15126050420168066,
        0.15126050420168066,
        0.1566626650660264,
        0.1566626650660264,
        0.15966386554621848,
        0.15966386554621848,
        0.16686674669867949,
        0.16806722689075632,
        0.17286914765906364,
        0.17286914765906364,
        0.18007202881152462,
        0.18007202881152462,
        0.19807923169267708,
        0.1992797118847539,
        0.20528211284513806,
        0.2064825930372149,
        0.22388955582232895,
        0.22509003601440578,
        0.24369747899159663,
        0.24369747899159663,
        0.24669867947178872,
        0.24669867947178872,
        0.24969987995198079,
        0.25090036014405764,
        0.251500600240096,
        0.2527010804321729,
        0.25570228091236497,
        0.25690276110444177,
        0.258703481392557,
        0.2605042016806723,
        0.2605042016806723,
        0.2617046818727491,
        0.27190876350540216,
        0.2743097238895558,
        0.29471788715486197,
        0.29471788715486197,
        0.297719087635054,
        0.297719087635054,
        0.3025210084033613,
        0.3025210084033613,
        0.30612244897959184,
        0.30612244897959184,
        0.30732292917166865,
        0.30732292917166865,
        0.3115246098439376,
        0.3115246098439376,
        0.31212484993997597,
        0.31212484993997597,
        0.3133253301320528,
        0.3133253301320528,
        0.3175270108043217,
        0.3175270108043217,
        0.3187274909963986,
        0.3187274909963986,
        0.3199279711884754,
        0.3199279711884754,
        0.3205282112845138,
        0.3205282112845138,
        0.32713085234093636,
        0.32713085234093636,
        0.3277310924369748,
        0.3277310924369748,
        0.32953181272509,
        0.33013205282112845,
        0.3325330132052821,
        0.3325330132052821,
        0.33373349339735897,
        0.33373349339735897,
        0.3349339735894358,
        0.3349339735894358,
        0.3469387755102041,
        0.3469387755102041,
        0.3475390156062425,
        0.3475390156062425,
        0.34933973589435774,
        0.34933973589435774,
        0.35114045618247297,
        0.35114045618247297,
        0.3517406962785114,
        0.3517406962785114,
        0.35414165666266506,
        0.35414165666266506,
        0.3547418967587035,
        0.35834333733493395,
        0.3589435774309724,
        0.3589435774309724,
        0.3631452581032413,
        0.3631452581032413,
        0.3667466986794718,
        0.3679471788715486,
        0.36914765906362546,
        0.36914765906362546,
        0.3715486194477791,
        0.3715486194477791,
        0.37334933973589435,
        0.37334933973589435,
        0.3745498199279712,
        0.3745498199279712,
        0.3751500600240096,
        0.3751500600240096,
        0.3793517406962785,
        0.3793517406962785,
        0.38055222088835533,
        0.38055222088835533,
        0.38235294117647056,
        0.38235294117647056,
        0.38535414165666265,
        0.38535414165666265,
        0.3865546218487395,
        0.3865546218487395,
        0.38835534213685474,
        0.38835534213685474,
        0.3895558223289316,
        0.3895558223289316,
        0.39015606242497,
        0.39015606242497,
        0.3979591836734694,
        0.3979591836734694,
        0.39915966386554624,
        0.39915966386554624,
        0.3997599039615846,
        0.3997599039615846,
        0.40396158463385357,
        0.40396158463385357,
        0.40756302521008403,
        0.40756302521008403,
        0.4087635054021609,
        0.4087635054021609,
        0.41236494597839135,
        0.41236494597839135,
        0.4261704681872749,
        0.4261704681872749,
        0.4309723889555822,
        0.4309723889555822,
        0.43337334933973587,
        0.43337334933973587,
        0.4345738295318127,
        0.4345738295318127,
        0.4399759903961585,
        0.4399759903961585,
        0.44657863145258103,
        0.44657863145258103,
        0.44837935174069626,
        0.44837935174069626,
        0.45018007202881155,
        0.45018007202881155,
        0.4507803121248499,
        0.4519807923169268,
        0.4531812725090036,
        0.4531812725090036,
        0.4561824729891957,
        0.45738295318127253,
        0.4579831932773109,
        0.4579831932773109,
        0.45918367346938777,
        0.45918367346938777,
        0.460984393757503,
        0.4657863145258103,
        0.4669867947178872,
        0.468187274909964,
        0.468187274909964,
        0.47478991596638653,
        0.47478991596638653,
        0.4759903961584634,
        0.4759903961584634,
        0.47839135654261705,
        0.47839135654261705,
        0.48259303721488594,
        0.4837935174069628,
        0.4849939975990396,
        0.4849939975990396,
        0.48739495798319327,
        0.48739495798319327,
        0.4879951980792317,
        0.4879951980792317,
        0.4897959183673469,
        0.4897959183673469,
        0.4939975990396158,
        0.4939975990396158,
        0.4951980792316927,
        0.4951980792316927,
        0.49759903961584634,
        0.49759903961584634,
        0.5060024009603842,
        0.5060024009603842,
        0.507202881152461,
        0.5084033613445378,
        0.5084033613445378,
        0.5150060024009604,
        0.5150060024009604,
        0.5162064825930373,
        0.5162064825930373,
        0.5180072028811524,
        0.5180072028811524,
        0.5186074429771909,
        0.5186074429771909,
        0.5258103241296519,
        0.5258103241296519,
        0.5270108043217286,
        0.5294117647058824,
        0.5324129651860744,
        0.5336134453781513,
        0.5336134453781513,
        0.5378151260504201,
        0.5378151260504201,
        0.5408163265306123,
        0.542016806722689,
        0.5648259303721489,
        0.5648259303721489,
        0.5726290516206483,
        0.5744297719087635,
        0.5900360144057623,
        0.5912364945978391,
        0.5936374549819928,
        0.595438175270108,
        0.6368547418967587,
        0.6380552220888356,
        0.6902761104441777,
        0.6914765906362546,
        0.7004801920768308,
        0.7016806722689075,
        0.7022809123649459,
        0.7034813925570228,
        0.7310924369747899,
        0.7322929171668667,
        0.7527010804321729,
        0.7539015606242497,
        0.7557022809123649,
        0.7569027611044418,
        0.7683073229291717,
        0.7695078031212484,
        0.7785114045618248,
        0.7809123649459784,
        0.7815126050420168,
        0.7833133253301321,
        0.7857142857142857,
        0.7869147659063626,
        0.8127250900360145,
        0.8139255702280912,
        0.8919567827130852,
        0.8931572629051621,
        0.9687875150060024,
        0.9699879951980792,
        1.0
      ],
      "tpr": [
        0.0,
        0.0005998800239952009,
        0.03779244151169766,
        0.038992201559688064,
        0.060587882423515295,
        0.0623875224955009,
        0.09118176364727054,
        0.09238152369526095,
        0.09718056388722256,
        0.09838032393521295,
        0.10257948410317937,
        0.10377924415116976,
        0.10497900419916016,
        0.10617876424715057,
        0.1277744451109778,
        0.13017396520695862,
        0.16736652669466107,
        0.16856628674265148,
        0.1817636472705459,
        0.1829634073185363,
        0.21295740851829634,
        0.21415716856628675,
        0.23875224955008997,
        0.23995200959808038,
        0.2501499700059988,
        0.2513497300539892,
        0.2633473305338932,
        0.26454709058188364,
        0.277744451109778,
        0.28014397120575885,
        0.2897420515896821,
        0.29094181163767247,
        0.3119376124775045,
        0.3131373725254949,
        0.33353329334133175,
        0.33473305338932213,
        0.34013197360527897,
        0.34133173365326935,
        0.34433113377324537,
        0.34553089382123575,
        0.34613077384523094,
        0.3473305338932214,
        0.355128974205159,
        0.35632873425314937,
        0.3767246550689862,
        0.3779244151169766,
        0.39592081583683264,
        0.397120575884823,
        0.42291541691661666,
        0.4241151769646071,
        0.4295140971805639,
        0.43071385722855426,
        0.47690461907618475,
        0.47810437912417514,
        0.5200959808038392,
        0.5212957408518296,
        0.5260947810437913,
        0.5272945410917816,
        0.5320935812837433,
        0.5332933413317337,
        0.5362927414517097,
        0.5374925014997001,
        0.5392921415716857,
        0.5404919016196761,
        0.5590881823635273,
        0.5602879424115177,
        0.5626874625074985,
        0.5644871025794841,
        0.5692861427714457,
        0.5704859028194361,
        0.5788842231553689,
        0.5800839832033593,
        0.5836832633473306,
        0.584883023395321,
        0.587882423515297,
        0.5890821835632873,
        0.5920815836832634,
        0.5932813437312537,
        0.6004799040191962,
        0.6016796640671865,
        0.6076784643071386,
        0.608878224355129,
        0.6136772645470906,
        0.614877024595081,
        0.6214757048590281,
        0.6226754649070186,
        0.6304739052189562,
        0.6316736652669466,
        0.6370725854829035,
        0.6382723455308938,
        0.6424715056988602,
        0.6436712657468506,
        0.6502699460107978,
        0.6514697060587883,
        0.6604679064187162,
        0.6616676664667066,
        0.6622675464907019,
        0.6634673065386922,
        0.6646670665866826,
        0.6658668266346731,
        0.6922615476904619,
        0.6934613077384523,
        0.7330533893221356,
        0.734253149370126,
        0.7480503899220156,
        0.7498500299940012,
        0.7750449910017997,
        0.7762447510497901,
        0.7774445110977805,
        0.7786442711457708,
        0.7810437912417516,
        0.7822435512897421,
        0.7996400719856028,
        0.8020395920815837,
        0.8104379124175165,
        0.8116376724655069,
        0.8170365926814637,
        0.8182363527294542,
        0.8380323935212958,
        0.8392321535692862,
        0.8668266346730654,
        0.8680263947210558,
        0.9160167966406718,
        0.9160167966406718,
        0.9166166766646671,
        0.9166166766646671,
        0.9172165566886623,
        0.9172165566886623,
        0.9178164367126574,
        0.9178164367126574,
        0.9178164367126574,
        0.9178164367126574,
        0.9184163167366527,
        0.9184163167366527,
        0.9196160767846431,
        0.9202159568086383,
        0.9202159568086383,
        0.9208158368326335,
        0.9208158368326335,
        0.9208158368326335,
        0.9208158368326335,
        0.9214157168566287,
        0.9214157168566287,
        0.9214157168566287,
        0.9214157168566287,
        0.9220155968806238,
        0.9220155968806238,
        0.9226154769046191,
        0.9226154769046191,
        0.9232153569286142,
        0.9232153569286142,
        0.9238152369526095,
        0.9238152369526095,
        0.9244151169766047,
        0.9244151169766047,
        0.9250149970005999,
        0.9250149970005999,
        0.9256148770245951,
        0.9256148770245951,
        0.9262147570485902,
        0.9262147570485902,
        0.9268146370725855,
        0.9268146370725855,
        0.9274145170965807,
        0.9274145170965807,
        0.9274145170965807,
        0.9274145170965807,
        0.9280143971205759,
        0.9280143971205759,
        0.9286142771445711,
        0.9286142771445711,
        0.9298140371925615,
        0.9298140371925615,
        0.9304139172165566,
        0.9304139172165566,
        0.9310137972405519,
        0.9310137972405519,
        0.9316136772645471,
        0.9316136772645471,
        0.9316136772645471,
        0.9316136772645471,
        0.9328134373125375,
        0.9328134373125375,
        0.9334133173365327,
        0.9334133173365327,
        0.9346130773845231,
        0.9346130773845231,
        0.9352129574085183,
        0.9352129574085183,
        0.9358128374325135,
        0.9358128374325135,
        0.937612477504499,
        0.937612477504499,
        0.9382123575284943,
        0.9382123575284943,
        0.9388122375524895,
        0.9388122375524895,
        0.9400119976004799,
        0.9400119976004799,
        0.9406118776244751,
        0.9406118776244751,
        0.9418116376724655,
        0.9418116376724655,
        0.9418116376724655,
        0.9418116376724655,
        0.9424115176964607,
        0.9424115176964607,
        0.943011397720456,
        0.943011397720456,
        0.943011397720456,
        0.943011397720456,
        0.943011397720456,
        0.943011397720456,
        0.943011397720456,
        0.943011397720456,
        0.9436112777444511,
        0.9436112777444511,
        0.9442111577684463,
        0.9442111577684463,
        0.9442111577684463,
        0.9442111577684463,
        0.9442111577684463,
        0.9442111577684463,
        0.9442111577684463,
        0.9442111577684463,
        0.9442111577684463,
        0.9448110377924415,
        0.9448110377924415,
        0.9448110377924415,
        0.9448110377924415,
        0.9448110377924415,
        0.9454109178164367,
        0.9454109178164367,
        0.946010797840432,
        0.946010797840432,
        0.9472105578884223,
        0.9472105578884223,
        0.9478104379124175,
        0.9478104379124175,
        0.9484103179364127,
        0.9484103179364127,
        0.9490101979604079,
        0.9490101979604079,
        0.9502099580083984,
        0.9502099580083984,
        0.9508098380323935,
        0.9508098380323935,
        0.9514097180563887,
        0.9514097180563887,
        0.9520095980803839,
        0.9520095980803839,
        0.9526094781043791,
        0.9526094781043791,
        0.9532093581283744,
        0.9532093581283744,
        0.9538092381523695,
        0.9538092381523695,
        0.9544091181763648,
        0.9544091181763648,
        0.9550089982003599,
        0.9550089982003599,
        0.9562087582483503,
        0.9562087582483503,
        0.9568086382723455,
        0.9568086382723455,
        0.9580083983203359,
        0.9580083983203359,
        0.9586082783443312,
        0.9586082783443312,
        0.9598080383923215,
        0.9598080383923215,
        0.9604079184163168,
        0.9604079184163168,
        0.9616076784643072,
        0.9616076784643072,
        0.9622075584883023,
        0.9622075584883023,
        0.9628074385122976,
        0.9634073185362927,
        0.9634073185362927,
        0.9634073185362927,
        0.9640071985602879,
        0.9640071985602879,
        0.9652069586082783,
        0.9652069586082783,
        0.9652069586082783,
        0.9652069586082783,
        0.9664067186562687,
        0.9664067186562687,
        0.967006598680264,
        0.967006598680264,
        0.9676064787042592,
        0.9676064787042592,
        0.9682063587282543,
        0.9682063587282543,
        0.9688062387522496,
        0.9688062387522496,
        0.9694061187762447,
        0.9694061187762447,
        0.97000599880024,
        0.97000599880024,
        0.9706058788242351,
        0.9706058788242351,
        0.9712057588482303,
        0.9712057588482303,
        0.9718056388722256,
        0.9718056388722256,
        0.9724055188962207,
        0.9724055188962207,
        0.973005398920216,
        0.973005398920216,
        0.9736052789442111,
        0.9736052789442111,
        0.9748050389922016,
        0.9748050389922016,
        0.9754049190161967,
        0.9754049190161967,
        0.976004799040192,
        0.976004799040192,
        0.9772045590881824,
        0.9772045590881824,
        0.9778044391121775,
        0.9778044391121775,
        0.9784043191361728,
        0.9784043191361728,
        0.979004199160168,
        0.979004199160168,
        0.9796040791841631,
        0.9796040791841631,
        0.9802039592081584,
        0.9802039592081584,
        0.9808038392321535,
        0.9808038392321535,
        0.9814037192561488,
        0.9814037192561488,
        0.9826034793041392,
        0.9826034793041392,
        0.9832033593281344,
        0.9832033593281344,
        0.9838032393521295,
        0.9838032393521295,
        0.9844031193761248,
        0.9844031193761248,
        0.9844031193761248,
        0.9844031193761248,
        0.9850029994001199,
        0.9850029994001199,
        0.9850029994001199,
        0.9850029994001199,
        0.9856028794241152,
        0.9856028794241152,
        0.9862027594481104,
        0.9862027594481104,
        0.9862027594481104,
        0.9862027594481104,
        0.9862027594481104,
        0.9868026394721056,
        0.9868026394721056,
        0.9874025194961008,
        0.9874025194961008,
        0.9880023995200959,
        0.9880023995200959,
        0.9886022795440912,
        0.9886022795440912,
        0.9886022795440912,
        0.9886022795440912,
        0.9892021595680864,
        0.9892021595680864,
        0.9898020395920816,
        0.9898020395920816,
        0.9904019196160768,
        0.9904019196160768,
        0.991001799640072,
        0.991001799640072,
        0.9916016796640672,
        0.9916016796640672,
        0.9922015596880623,
        0.9922015596880623,
        0.9928014397120576,
        0.9928014397120576,
        0.994001199760048,
        0.994001199760048,
        0.994001199760048,
        0.9946010797840432,
        0.9946010797840432,
        0.9952009598080384,
        0.9952009598080384,
        0.9958008398320336,
        0.9958008398320336,
        0.9964007198560288,
        0.9964007198560288,
        0.9976004799040192,
        0.9976004799040192,
        0.9982003599280144,
        0.9982003599280144,
        0.9982003599280144,
        0.9982003599280144,
        0.9982003599280144,
        0.9988002399520096,
        0.9988002399520096,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0
      ],
      "thresholds": [
        Infinity,
        0.5618825554847717,
        0.561792254447937,
        0.5617893934249878,
        0.5617374777793884,
        0.5617362260818481,
        0.5616987347602844,
        0.561698317527771,
        0.5616852045059204,
        0.5616850852966309,
        0.5616816282272339,
        0.5616785883903503,
        0.5616757869720459,
        0.5616706013679504,
        0.5615014433860779,
        0.5614935159683228,
        0.5613765120506287,
        0.5613746643066406,
        0.5613220930099487,
        0.5613206624984741,
        0.561001181602478,
        0.5609996318817139,
        0.5609617829322815,
        0.5609617233276367,
        0.5609463453292847,
        0.5609443187713623,
        0.5609349012374878,
        0.5609337091445923,
        0.5609244108200073,
        0.5609235763549805,
        0.5609140992164612,
        0.5609135627746582,
        0.5608867406845093,
        0.5608857870101929,
        0.5608639121055603,
        0.5608633756637573,
        0.560857355594635,
        0.5608572959899902,
        0.5608527660369873,
        0.5608516931533813,
        0.5608512759208679,
        0.5608497262001038,
        0.5608398914337158,
        0.5608396530151367,
        0.5608172416687012,
        0.5608169436454773,
        0.5607861876487732,
        0.5607841610908508,
        0.5607348680496216,
        0.5607345700263977,
        0.5607241988182068,
        0.5607227683067322,
        0.560655951499939,
        0.5606551766395569,
        0.5606134533882141,
        0.5606124401092529,
        0.5606064200401306,
        0.560604453086853,
        0.5606024265289307,
        0.560601532459259,
        0.5605998635292053,
        0.5605996251106262,
        0.5605983734130859,
        0.5605980753898621,
        0.5605785250663757,
        0.560578465461731,
        0.5605759024620056,
        0.560575544834137,
        0.5605712532997131,
        0.5605711936950684,
        0.560560405254364,
        0.5605603456497192,
        0.5605546832084656,
        0.5605541467666626,
        0.5605519413948059,
        0.5605518221855164,
        0.5605475902557373,
        0.5605472922325134,
        0.5605388879776001,
        0.5605364441871643,
        0.5605324506759644,
        0.5605316162109375,
        0.5605244040489197,
        0.5605239272117615,
        0.5605149865150452,
        0.5605149269104004,
        0.5605032444000244,
        0.5605030655860901,
        0.5604954361915588,
        0.5604934096336365,
        0.5604904294013977,
        0.5604896545410156,
        0.560481607913971,
        0.5604813694953918,
        0.560473620891571,
        0.5604735612869263,
        0.5604721307754517,
        0.5604719519615173,
        0.5604703426361084,
        0.5604696273803711,
        0.5604305267333984,
        0.5604296922683716,
        0.5603792071342468,
        0.5603790879249573,
        0.5603609085083008,
        0.560360848903656,
        0.5603405237197876,
        0.560339629650116,
        0.5603366494178772,
        0.5603365898132324,
        0.5603355169296265,
        0.5603335499763489,
        0.560302734375,
        0.5603024363517761,
        0.5602825284004211,
        0.5602823495864868,
        0.5602732300758362,
        0.5602705478668213,
        0.5602179765701294,
        0.5602174997329712,
        0.5601427555084229,
        0.5601388216018677,
        0.5597791075706482,
        0.559769332408905,
        0.5597677826881409,
        0.5597670674324036,
        0.5597638487815857,
        0.5597566366195679,
        0.5597555041313171,
        0.5597537755966187,
        0.5597530603408813,
        0.5597262978553772,
        0.5597262382507324,
        0.5597163438796997,
        0.5597162842750549,
        0.5597147345542908,
        0.5596649646759033,
        0.5596604347229004,
        0.5596559643745422,
        0.5596523880958557,
        0.5596387982368469,
        0.5596380233764648,
        0.5596196055412292,
        0.5596169829368591,
        0.5595874786376953,
        0.5595857501029968,
        0.5594748258590698,
        0.5594711899757385,
        0.5594577193260193,
        0.5594531893730164,
        0.5593860745429993,
        0.5593849420547485,
        0.5593807697296143,
        0.5593751072883606,
        0.5593723654747009,
        0.5593655109405518,
        0.5593070983886719,
        0.5593066215515137,
        0.559304416179657,
        0.5593008399009705,
        0.559240996837616,
        0.5592398047447205,
        0.559235692024231,
        0.5592349171638489,
        0.5592155456542969,
        0.5592149496078491,
        0.5591827034950256,
        0.559179961681366,
        0.5591714978218079,
        0.5591679811477661,
        0.5591657757759094,
        0.5591625571250916,
        0.559158205986023,
        0.5591508746147156,
        0.5591485500335693,
        0.5591453909873962,
        0.5591009259223938,
        0.559099018573761,
        0.559090793132782,
        0.559086799621582,
        0.5590763688087463,
        0.5590705871582031,
        0.5590412020683289,
        0.5590353012084961,
        0.559010922908783,
        0.559002161026001,
        0.5590019226074219,
        0.5589990615844727,
        0.5589877367019653,
        0.5589802861213684,
        0.5589655041694641,
        0.5589619278907776,
        0.5589389204978943,
        0.5589386224746704,
        0.5589131116867065,
        0.558910608291626,
        0.5588934421539307,
        0.5588774681091309,
        0.5588513016700745,
        0.5588493943214417,
        0.5588334798812866,
        0.5588229298591614,
        0.5587920546531677,
        0.5587912797927856,
        0.5587844848632812,
        0.5587836503982544,
        0.5587804913520813,
        0.5587804317474365,
        0.5587703585624695,
        0.5587702989578247,
        0.5587652325630188,
        0.5587651133537292,
        0.5587534308433533,
        0.5587533712387085,
        0.5587393045425415,
        0.5587387084960938,
        0.5587376952171326,
        0.5587373971939087,
        0.5587354898452759,
        0.5587350726127625,
        0.5587345957756042,
        0.5587344169616699,
        0.5587326884269714,
        0.5587324500083923,
        0.558731734752655,
        0.5587309002876282,
        0.5587308406829834,
        0.5587299466133118,
        0.5587209463119507,
        0.5587206482887268,
        0.5586968064308167,
        0.5586966872215271,
        0.5586934089660645,
        0.5586925148963928,
        0.5586865544319153,
        0.5586782693862915,
        0.5586636066436768,
        0.5586608648300171,
        0.5586591958999634,
        0.5586555004119873,
        0.5586274862289429,
        0.5586259961128235,
        0.5586258172988892,
        0.5586225390434265,
        0.558617353439331,
        0.5586135387420654,
        0.5585861206054688,
        0.5585858225822449,
        0.558582603931427,
        0.5585755705833435,
        0.558570146560669,
        0.558569610118866,
        0.5585695505142212,
        0.5585645437240601,
        0.5585199594497681,
        0.5585198402404785,
        0.558513879776001,
        0.5585125684738159,
        0.5585042834281921,
        0.5584998726844788,
        0.558494508266449,
        0.5584917664527893,
        0.5584830045700073,
        0.558481752872467,
        0.5584811568260193,
        0.558479905128479,
        0.5584373474121094,
        0.5584371089935303,
        0.5584350228309631,
        0.5584328174591064,
        0.55842524766922,
        0.5584213137626648,
        0.5584071278572083,
        0.558399498462677,
        0.5583913922309875,
        0.558390736579895,
        0.5583857297897339,
        0.5583803057670593,
        0.5583782196044922,
        0.5583779215812683,
        0.5583727955818176,
        0.5583723187446594,
        0.5583581924438477,
        0.5583496689796448,
        0.5583359003067017,
        0.5583356022834778,
        0.5583323240280151,
        0.5583305954933167,
        0.5583242177963257,
        0.5583202242851257,
        0.5583160519599915,
        0.5583116412162781,
        0.558310329914093,
        0.5583099722862244,
        0.5583062767982483,
        0.5583028793334961,
        0.5582913756370544,
        0.5582908987998962,
        0.5582887530326843,
        0.5582883954048157,
        0.5582858920097351,
        0.5582841634750366,
        0.5582812428474426,
        0.5582808256149292,
        0.5582785606384277,
        0.5582764148712158,
        0.558271586894989,
        0.5582712888717651,
        0.5582695603370667,
        0.5582675337791443,
        0.5582640171051025,
        0.5582627058029175,
        0.5582519173622131,
        0.5582491755485535,
        0.5582485198974609,
        0.5582480430603027,
        0.5582476258277893,
        0.5582455396652222,
        0.5582377910614014,
        0.5582373142242432,
        0.5582287311553955,
        0.5582281947135925,
        0.5582226514816284,
        0.5582208633422852,
        0.558214008808136,
        0.5582126975059509,
        0.5581880211830139,
        0.5581871867179871,
        0.5581789016723633,
        0.5581780076026917,
        0.5581710934638977,
        0.5581703186035156,
        0.5581690073013306,
        0.5581684708595276,
        0.5581592917442322,
        0.5581555366516113,
        0.5581492781639099,
        0.5581486225128174,
        0.5581467747688293,
        0.5581464767456055,
        0.5581426024436951,
        0.5581418871879578,
        0.5581408739089966,
        0.558140754699707,
        0.5581374168395996,
        0.5581363439559937,
        0.5581327080726624,
        0.5581325888633728,
        0.558131754398346,
        0.5581315755844116,
        0.5581300258636475,
        0.5581285953521729,
        0.5581285357475281,
        0.5581207871437073,
        0.5581204295158386,
        0.5581191778182983,
        0.5581163167953491,
        0.5581113696098328,
        0.5581099987030029,
        0.5581094026565552,
        0.5581074953079224,
        0.5581064820289612,
        0.5581058859825134,
        0.5581004619598389,
        0.5580989718437195,
        0.558097779750824,
        0.5580974221229553,
        0.5580926537513733,
        0.5580918788909912,
        0.5580902099609375,
        0.5580891370773315,
        0.558088481426239,
        0.5580880641937256,
        0.5580844879150391,
        0.55808424949646,
        0.5580835342407227,
        0.558083176612854,
        0.5580793619155884,
        0.5580786466598511,
        0.5580698251724243,
        0.5580687522888184,
        0.5580686926841736,
        0.5580660104751587,
        0.5580655932426453,
        0.5580602884292603,
        0.5580597519874573,
        0.5580592155456543,
        0.5580588579177856,
        0.5580576658248901,
        0.558057427406311,
        0.5580561757087708,
        0.5580552816390991,
        0.558048665523529,
        0.5580465793609619,
        0.5580453276634216,
        0.5580428838729858,
        0.5580381751060486,
        0.5580370426177979,
        0.5580369830131531,
        0.5580272078514099,
        0.5580264925956726,
        0.558023989200592,
        0.5580235719680786,
        0.5579978227615356,
        0.557996928691864,
        0.557988166809082,
        0.5579877495765686,
        0.5579726099967957,
        0.557972252368927,
        0.5579693913459778,
        0.5579684376716614,
        0.5579164028167725,
        0.5579155683517456,
        0.5578392148017883,
        0.5578375458717346,
        0.5578199028968811,
        0.5578173398971558,
        0.557815670967102,
        0.55781489610672,
        0.5577802062034607,
        0.5577795505523682,
        0.5577481389045715,
        0.5577471256256104,
        0.557746171951294,
        0.5577457547187805,
        0.557729959487915,
        0.5577293634414673,
        0.5577114224433899,
        0.5577095150947571,
        0.5577093362808228,
        0.5577057003974915,
        0.5577024221420288,
        0.5577022433280945,
        0.5576537251472473,
        0.557650625705719,
        0.5573902726173401,
        0.5573842525482178,
        0.5572154521942139,
        0.5572146773338318,
        0.556997537612915
      ]
    },
    "roc_auc": 0.9747348249437747,
    "optimal_threshold": 0.5597791075706482,
    "precision_mean": 0.5001500150015001,
    "recall_mean": 1.0
  },
  "ttt_model": {
    "accuracy_mean": 1.0,
    "accuracy_std": 0.0,
    "macro_f1_mean": 1.0,
    "macro_f1_std": 0.0,
    "mcc_mean": 1.0,
    "mcc_std": 0.0,
    "confusion_matrix": [
      [
        500,
        0
      ],
      [
        0,
        500
      ]
    ],
    "roc_curve": {
      "fpr": [
        0.0,
        0.0,
        0.228,
        0.232,
        0.234,
        0.242,
        0.246,
        1.0
      ],
      "tpr": [
        0.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0
      ],
      "thresholds": [
        Infinity,
        1.0,
        1.2611686178923354e-44,
        7.006492321624085e-45,
        4.203895392974451e-45,
        2.802596928649634e-45,
        1.401298464324817e-45,
        0.0
      ]
    },
    "roc_auc": 1.0,
    "optimal_threshold": 1.0,
    "ttt_adaptation_data": {
      "steps": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50,
        51,
        52,
        53,
        54,
        55,
        56,
        57,
        58,
        59,
        60,
        61,
        62,
        63,
        64,
        65,
        66,
        67,
        68,
        69,
        70,
        71,
        72,
        73,
        74,
        75,
        76,
        77,
        78,
        79,
        80,
        81,
        82,
        83,
        84,
        85,
        86,
        87,
        88,
        89,
        90,
        91,
        92,
        93,
        94,
        95,
        96,
        97,
        98,
        99,
        100,
        101,
        102,
        103,
        104,
        105,
        106,
        107,
        108,
        109,
        110,
        111,
        112,
        113,
        114,
        115,
        116,
        117,
        118,
        119,
        120,
        121,
        122,
        123,
        124,
        125,
        126,
        127,
        128,
        129,
        130,
        131,
        132,
        133,
        134,
        135,
        136,
        137,
        138,
        139,
        140,
        141,
        142,
        143,
        144,
        145,
        146,
        147,
        148,
        149,
        150,
        151,
        152,
        153,
        154,
        155,
        156,
        157,
        158,
        159,
        160,
        161,
        162,
        163,
        164,
        165,
        166,
        167,
        168,
        169,
        170,
        171,
        172,
        173,
        174,
        175,
        176,
        177,
        178,
        179,
        180,
        181,
        182,
        183,
        184,
        185,
        186,
        187,
        188,
        189,
        190,
        191,
        192,
        193,
        194,
        195,
        196,
        197,
        198,
        199
      ],
      "total_losses": [
        0.7683987617492676,
        0.7648434042930603,
        0.7615993618965149,
        0.7602414488792419,
        0.756126344203949,
        0.7496895790100098,
        0.7406810522079468,
        0.7290571331977844,
        0.7086678147315979,
        0.6898732781410217,
        0.6686863303184509,
        0.6312792301177979,
        0.5930449366569519,
        0.5548222661018372,
        0.5116261839866638,
        0.4566096365451813,
        0.40606793761253357,
        0.353630393743515,
        0.3066699802875519,
        0.2555723190307617,
        0.21078486740589142,
        0.16891224682331085,
        0.1280929148197174,
        0.09878207743167877,
        0.07421334832906723,
        0.0589962974190712,
        0.05650576949119568,
        0.03614533320069313,
        0.026794718578457832,
        0.017446015030145645,
        0.015517149120569229,
        0.019542228430509567,
        0.009362893179059029,
        0.006349883507937193,
        0.00792295578867197,
        0.003976661246269941,
        0.004466762766242027,
        0.016402333974838257,
        0.00533918896690011,
        0.0027709011919796467,
        0.0019446335500106215,
        0.0019499293994158506,
        0.008041083812713623,
        0.002028281334787607,
        0.0014047527220100164,
        0.0014142693253234029,
        0.008195867761969566,
        0.0022700894623994827,
        0.0009500223095528781,
        0.0011527675669640303,
        0.0012323628179728985,
        0.0015272493474185467,
        0.0013576395576819777,
        0.0010257980320602655,
        0.0006111820111982524,
        0.0011528055183589458,
        0.0007701908471062779,
        0.0008033411577343941,
        0.0005253669223748147,
        0.00044831473496742547,
        0.0008455028291791677,
        0.01947891153395176,
        0.0009521475294604897,
        0.0007752475794404745,
        0.0005598795250989497,
        0.026807066053152084,
        0.0014765195082873106,
        0.0026724552735686302,
        0.005289856344461441,
        0.0006671518203802407,
        0.0005603478057309985,
        0.01495768316090107,
        0.00042892707278952,
        0.01303914561867714,
        0.0004472979926504195,
        0.0003730199532583356,
        0.00038478244096040726,
        0.008508804254233837,
        0.0004808030207641423,
        0.0005815410986542702,
        0.000901084509678185,
        0.0007951600127853453,
        0.0003513922856654972,
        0.0008483633282594383,
        0.0007624813006259501,
        0.0006681985687464476,
        0.00046571268467232585,
        0.0008900038083083928,
        0.00037299166433513165,
        0.00031541971839033067,
        0.0007909577107056975,
        0.0006874750833958387,
        0.0005986302276141942,
        0.0014772096183151007,
        0.0004546827985905111,
        0.000720413401722908,
        0.0006043938919901848,
        0.00032554956851527095,
        0.0006268697325140238,
        0.000642141851130873,
        0.0005962270661257207,
        0.0107023436576128,
        0.001009510480798781,
        0.00094662542687729,
        0.00022827176144346595,
        0.0003334560606162995,
        0.0003955056017730385,
        0.0006205373210832477,
        0.0003135044244118035,
        0.0003540197794791311,
        0.00034041740582324564,
        0.0005649664090014994,
        0.0018751326715573668,
        0.001025669276714325,
        0.00021097520948387682,
        0.00033422079286538064,
        0.0003127621312160045,
        0.0006856355466879904,
        0.013318711891770363,
        0.0009313571499660611,
        0.00040827429620549083,
        0.0003715328930411488,
        0.0007793367258273065,
        0.0007066514226607978,
        0.0007971236482262611,
        0.0011724475771188736,
        0.00037716724909842014,
        0.00035144088906235993,
        0.00034003687324002385,
        0.00022966685355640948,
        0.0008370681898668408,
        0.012547352351248264,
        0.0003234214673284441,
        0.0013542138040065765,
        0.007253611460328102,
        0.000501563714351505,
        0.00040685205021873116,
        0.0004985476844012737,
        0.001188038382679224,
        0.0002930937916971743,
        0.0002184610057156533,
        0.0004369349917396903,
        0.007943911477923393,
        0.005091397557407618,
        0.00040725606959313154,
        0.008478596806526184,
        0.0013860487379133701,
        0.0005853416514582932,
        0.0004651369818020612,
        0.00027715603937394917,
        0.0004287031479179859,
        0.0006274730549193919,
        0.00034064409555867314,
        0.00047727691708132625,
        0.00027292754384689033,
        0.0008070378098636866,
        0.0007993439794518054,
        0.000471346837002784,
        0.0001823050552047789,
        0.0004336487327236682,
        0.0003434342215768993,
        0.0006506045465357602,
        0.00812852755188942,
        0.0049013616517186165,
        0.0011841398663818836,
        0.0005501446430571377,
        0.0003773351199924946,
        0.0005002244142815471,
        0.0007262054714374244,
        0.0005806016852147877,
        0.00036875923979096115,
        0.0009036906994879246,
        0.0005993909435346723,
        0.00045764047536067665,
        0.00038838753243908286,
        0.0006215963512659073,
        0.0006255250191316009,
        0.00030423159478232265,
        0.000437303155194968,
        0.0003478194121271372,
        0.0005187861970625818,
        0.0004899584455415606,
        0.0005077032838016748,
        0.0002512943174224347,
        0.000664951279759407,
        0.0002686150255613029,
        0.00047873836592771113,
        0.0049726772122085094,
        0.0003984193317592144,
        0.0006223949603736401,
        0.0006969986716285348,
        0.00023248852812685072,
        0.0004056710167787969,
        0.0002957435790449381,
        0.004988957196474075,
        0.0007817812147550285,
        0.0006044934852980077,
        0.00046807131730020046,
        0.0007968683494254947,
        0.0005248166271485388
      ],
      "support_losses": [
        0.6997694969177246,
        0.6959370374679565,
        0.692552387714386,
        0.6911749243736267,
        0.6870766878128052,
        0.68071049451828,
        0.6717860102653503,
        0.6602457165718079,
        0.6399576663970947,
        0.6213247179985046,
        0.6004136800765991,
        0.5636467933654785,
        0.5263921022415161,
        0.48936164379119873,
        0.4482734203338623,
        0.39656490087509155,
        0.34874266386032104,
        0.30034324526786804,
        0.25863873958587646,
        0.21284399926662445,
        0.1737082302570343,
        0.1375928521156311,
        0.10267896950244904,
        0.0774940773844719,
        0.05871040001511574,
        0.04632355645298958,
        0.04611416906118393,
        0.028528964146971703,
        0.020482460036873817,
        0.012891363352537155,
        0.012096692807972431,
        0.016532188281416893,
        0.0074953725561499596,
        0.004545163828879595,
        0.006291582714766264,
        0.002726830542087555,
        0.0032652404624968767,
        0.015450767241418362,
        0.004620925989001989,
        0.0020281043834984303,
        0.001178255188278854,
        0.0013413290726020932,
        0.007505075540393591,
        0.0015661503421142697,
        0.0009017842239700258,
        0.0009172167046926916,
        0.007870819419622421,
        0.001994410529732704,
        0.000642854196485132,
        0.0008146948530338705,
        0.0009336398215964437,
        0.0013726655161008239,
        0.0009396540117450058,
        0.0008808869170024991,
        0.00040798410191200674,
        0.0009202228975482285,
        0.0004970805021002889,
        0.0005778662743978202,
        0.0003047623613383621,
        0.0002068824105663225,
        0.0006331424810923636,
        0.01924360729753971,
        0.0007522843079641461,
        0.0004893448203802109,
        0.0003486574860289693,
        0.02661692164838314,
        0.0011983015574514866,
        0.0025585046969354153,
        0.005103714298456907,
        0.0005843501421622932,
        0.00038079172372817993,
        0.01486963126808405,
        0.00031834637047722936,
        0.012783098965883255,
        0.0003779664693865925,
        0.00015240923676174134,
        0.00018989626551046968,
        0.008309561759233475,
        0.00019014191639143974,
        0.0003064914490096271,
        0.0007694023661315441,
        0.0006261501694098115,
        6.988927634665743e-05,
        0.0006174582522362471,
        0.0005839784862473607,
        0.0005675885477103293,
        0.00021510264195967466,
        0.0007041659555397928,
        0.00030388840241357684,
        0.00011998289119219407,
        0.0007293052040040493,
        0.0004993347683921456,
        0.00045352819142863154,
        0.0013276950921863317,
        0.0003319256938993931,
        0.0005926767480559647,
        0.0004834388382732868,
        0.00021801197726745158,
        0.0004424879152793437,
        0.0005364345270209014,
        0.00042844185372814536,
        0.010565456934273243,
        0.0008224709890782833,
        0.0008003251859918237,
        0.0001623804564587772,
        0.00021190328698139638,
        0.0002885599678847939,
        0.000512816826812923,
        0.00015073255053721368,
        0.00026698250439949334,
        0.00014027490396983922,
        0.00040522581548430026,
        0.001636248896829784,
        0.0008399531943723559,
        0.00013924590894021094,
        0.00020258563745301217,
        0.00018431874923408031,
        0.0005968037294223905,
        0.013161135837435722,
        0.000873351062182337,
        0.0003038691356778145,
        0.0002929790935013443,
        0.0006312737823463976,
        0.0006076320423744619,
        0.0007333342800848186,
        0.0010546447010710835,
        0.00025028453092090786,
        0.00019870587857440114,
        0.00018057727720588446,
        9.426892211195081e-05,
        0.0005929345497861505,
        0.012374678626656532,
        0.0002474577631801367,
        0.00106437923386693,
        0.007076449692249298,
        0.0002940000267699361,
        0.0002319010382052511,
        0.00043528451351448894,
        0.0011068903841078281,
        0.00021954164549242705,
        0.00015847515896894038,
        0.0003219102509319782,
        0.0077491141855716705,
        0.00495910132303834,
        0.0002486435405444354,
        0.008336791768670082,
        0.0012270581210032105,
        0.00046923820627853274,
        0.0003168154216837138,
        0.00017033120093401521,
        0.00038011642755009234,
        0.00047028835979290307,
        0.00025081803323701024,
        0.00019371403323020786,
        0.00018336261564400047,
        0.0006420279969461262,
        0.0007226590532809496,
        0.0002870165044441819,
        8.585779141867533e-05,
        0.0003832041984423995,
        0.00018236385949421674,
        0.000523979018907994,
        0.007882148027420044,
        0.004749177489429712,
        0.0010560620576143265,
        0.00044835175503976643,
        0.00028997549088671803,
        0.00034865038469433784,
        0.0005542830331251025,
        0.00035371410194784403,
        0.00022033332788851112,
        0.0007551572052761912,
        0.00041846645763143897,
        0.00038700306322425604,
        0.0002497886016499251,
        0.0005435665952973068,
        0.0003416137769818306,
        0.0002227271324954927,
        0.00021697927149944007,
        0.00021590761025436223,
        0.0003425035683903843,
        0.00031351938378065825,
        0.00037426187191158533,
        0.00011044819984817877,
        0.0005669632228091359,
        0.00017541920533403754,
        0.0003258413344155997,
        0.004861945286393166,
        0.00021460268180817366,
        0.00044492457527667284,
        0.00048212011461146176,
        0.00012256407353561372,
        0.00032245932379737496,
        0.00022768951021134853,
        0.004745835904031992,
        0.000566671893466264,
        0.0005122639122419059,
        0.000338572368491441,
        0.0007454807055182755,
        0.00032937584910541773
      ],
      "consistency_losses": [
        0.6862923502922058,
        0.6890636086463928,
        0.6904696822166443,
        0.6906653046607971,
        0.6904966235160828,
        0.6897911429405212,
        0.68895024061203,
        0.6881144046783447,
        0.6871016025543213,
        0.6854857206344604,
        0.6827266216278076,
        0.676324188709259,
        0.666528582572937,
        0.6546059846878052,
        0.6335278153419495,
        0.600447416305542,
        0.5732528567314148,
        0.5328715443611145,
        0.4803124666213989,
        0.4272833466529846,
        0.37076637148857117,
        0.3131939172744751,
        0.2541394531726837,
        0.21288001537322998,
        0.15502949059009552,
        0.1267274022102356,
        0.1039159893989563,
        0.07616368681192398,
        0.06312257796525955,
        0.0455465093255043,
        0.03420455753803253,
        0.03010040707886219,
        0.018675202503800392,
        0.018047194927930832,
        0.01631372980773449,
        0.012498305179178715,
        0.012015220709145069,
        0.009515670128166676,
        0.00718262791633606,
        0.007427968550473452,
        0.0076637836173176765,
        0.006086003500968218,
        0.005360078997910023,
        0.004621308762580156,
        0.005029685329645872,
        0.004970525857061148,
        0.003250483423471451,
        0.0027567900251597166,
        0.0030716811306774616,
        0.00338072725571692,
        0.0029872304294258356,
        0.0015458384295925498,
        0.004179855342954397,
        0.0014491117326542735,
        0.002031979151070118,
        0.0023258263245224953,
        0.0027311036828905344,
        0.002254748484119773,
        0.0022060456685721874,
        0.0024143231566995382,
        0.0021236035972833633,
        0.0023530360776931047,
        0.001998632214963436,
        0.0028590273577719927,
        0.002112220274284482,
        0.0019014349672943354,
        0.00278217950835824,
        0.0011395058827474713,
        0.0018614199943840504,
        0.0008280168403871357,
        0.001795560703612864,
        0.0008805206161923707,
        0.0011058070231229067,
        0.0025604641996324062,
        0.0006933151162229478,
        0.002206107135862112,
        0.0019488617544993758,
        0.001992425648495555,
        0.0029066111892461777,
        0.002750496147200465,
        0.0013168216682970524,
        0.0016900984337553382,
        0.002815030049532652,
        0.002309050876647234,
        0.0017850282602012157,
        0.001006099977530539,
        0.002506100106984377,
        0.001858378411270678,
        0.0006910327356308699,
        0.0019543683156371117,
        0.0006165248341858387,
        0.0018814032664522529,
        0.0014510201290249825,
        0.0014951457269489765,
        0.0012275711633265018,
        0.0012773667695000768,
        0.0012095505371689796,
        0.0010753758251667023,
        0.0018438182305544615,
        0.001057073357515037,
        0.0016778518911451101,
        0.0013688629260286689,
        0.001870395033620298,
        0.0014630024088546634,
        0.0006589129916392267,
        0.0012155277654528618,
        0.0010694563388824463,
        0.0010772051755338907,
        0.0016277189133688807,
        0.0008703726343810558,
        0.0020014250185340643,
        0.0015974059933796525,
        0.0023888382129371166,
        0.0018571612890809774,
        0.0007172929472289979,
        0.0013163515832275152,
        0.0012844337616115808,
        0.0008883182308636606,
        0.001575756585225463,
        0.0005800608778372407,
        0.0010440517216920853,
        0.0007855379953980446,
        0.0014806295512244105,
        0.000990194035694003,
        0.0006378937978297472,
        0.0011780293425545096,
        0.001268827123567462,
        0.001527350046671927,
        0.0015945957275107503,
        0.0013539792271330953,
        0.0024413366336375475,
        0.0017267337534576654,
        0.0007596370414830744,
        0.002898345235735178,
        0.0017716176807880402,
        0.0020756369922310114,
        0.001749509945511818,
        0.0006326314760372043,
        0.0008114795782603323,
        0.0007355213747359812,
        0.0005998584092594683,
        0.001150247291661799,
        0.0019479687325656414,
        0.0013229615287855268,
        0.0015861251158639789,
        0.0014180520083755255,
        0.0015899065183475614,
        0.001161034218966961,
        0.001483215601183474,
        0.0010682482970878482,
        0.0004858671163674444,
        0.001571847009472549,
        0.0008982604485936463,
        0.0028356285765767097,
        0.00089564936934039,
        0.001650097779929638,
        0.0007668493781238794,
        0.001843303325586021,
        0.0009644727106206119,
        0.0005044452263973653,
        0.0016107037663459778,
        0.0012662553926929832,
        0.002463796641677618,
        0.001521841622889042,
        0.0012807785533368587,
        0.0010179287055507302,
        0.0008735961164347827,
        0.0015157399466261268,
        0.0017192241502925754,
        0.002268875716254115,
        0.0014842591481283307,
        0.001485335174947977,
        0.0018092446262016892,
        0.0007063740049488842,
        0.0013859894825145602,
        0.0007802972686477005,
        0.0028391119558364153,
        0.0008150444482453167,
        0.00220323889516294,
        0.0013191178441047668,
        0.0017628263449296355,
        0.0017643903847783804,
        0.0013344141189008951,
        0.0014084610156714916,
        0.0009798803366720676,
        0.0009319580858573318,
        0.0015289703151211143,
        0.0011073194909840822,
        0.0018381662666797638,
        0.0017747038509696722,
        0.0021487853955477476,
        0.0010992444586008787,
        0.0008321168716065586,
        0.0006805407465435565,
        0.0024312150198966265,
        0.0021510932128876448,
        0.0009222954977303743,
        0.0012949892552569509,
        0.0005138763226568699,
        0.001954407896846533
      ]
    },
    "precision_mean": 1.0,
    "recall_mean": 1.0
  },
  "dataset_info": {
    "name": "Edge-IIoTset",
    "total_samples": 102406,
    "evaluated_samples": 10000,
    "features": 61,
    "attack_types": 15,
    "zero_day_attack": "SQL_injection",
    "zero_day_stats": {
      "zero_day_attack": "SQL_injection",
      "zero_day_samples": 51203,
      "zero_day_percentage": 8.494997038538814,
      "total_attack_samples": 602743,
      "normal_samples": 1615643,
      "total_samples": 2218386,
      "available_attacks": [
        "Normal",
        "DDoS_UDP",
        "DDoS_ICMP",
        "SQL_injection",
        "Password",
        "Vulnerability_scanner",
        "DDoS_TCP",
        "DDoS_HTTP",
        "Uploading",
        "Backdoor",
        "Port_Scanning",
        "XSS",
        "Ransomware",
        "Fingerprinting",
        "MITM"
      ]
    }
  },
  "final_global_model": {
    "accuracy": 1.0,
    "f1_score": 1.0,
    "mcc": 1.0,
    "roc_auc": 1.0,
    "optimal_threshold": 0.0,
    "roc_curve": {
      "fpr": [
        0.0,
        0.0,
        1.0
      ],
      "tpr": [
        0.0,
        1.0,
        1.0
      ],
      "thresholds": [
        Infinity,
        0.9999998807907104,
        1.0000000116860974e-07
      ]
    },
    "confusion_matrix": [
      [
        2500,
        0
      ],
      [
        0,
        2500
      ]
    ],
    "test_samples": 5000,
    "dataset_info": {
      "name": "Edge-IIoTset",
      "total_samples": 102406,
      "evaluated_samples": 5000,
      "features": 61,
      "attack_types": 15,
      "zero_day_attack": "SQL_injection"
    }
  },
  "training_history": [
    {
      "round_number": 0,
      "client_updates": [
        "ClientUpdate(client_id='client_1', model_parameters={'meta_learner.transductive_net.feature_extractors.0.0.weight': tensor([[ 0.0463,  0.0619, -0.0615,  ...,  0.0243,  0.0529, -0.0662],\n        [ 0.0858,  0.1113, -0.0720,  ..., -0.0090, -0.0613,  0.0741],\n        [ 0.0017, -0.0938, -0.0427,  ...,  0.0663,  0.0530,  0.0169],\n        ...,\n        [ 0.0621,  0.0276,  0.0712,  ..., -0.0466, -0.0366,  0.1268],\n        [-0.0005,  0.1152, -0.0109,  ..., -0.0794, -0.0590, -0.1171],\n        [-0.0038, -0.1313, -0.0076,  ..., -0.0050,  0.0380,  0.0475]]), 'meta_learner.transductive_net.feature_extractors.0.0.bias': tensor([-0.0842, -0.0952,  0.0628, -0.0133,  0.0581, -0.0754, -0.0213, -0.0701,\n        -0.0210, -0.0492, -0.1170, -0.0448,  0.0073, -0.1040,  0.0473,  0.0402,\n        -0.0648, -0.0007,  0.0992, -0.1057,  0.0770,  0.0462,  0.0648,  0.0808,\n        -0.0332, -0.0804, -0.1268, -0.0565,  0.1128,  0.0160,  0.0669,  0.0313,\n        -0.0037, -0.0451,  0.0584, -0.0284, -0.1106,  0.0176,  0.1175,  0.0765,\n        -0.0831, -0.0998, -0.0617, -0.0407, -0.1106, -0.0098, -0.0247, -0.0606,\n        -0.0734, -0.0037, -0.0777,  0.0151, -0.0659,  0.0229, -0.0691, -0.0750,\n         0.0707,  0.0295,  0.0883,  0.0636,  0.0719, -0.0161,  0.0763,  0.0997,\n        -0.0825, -0.0868,  0.0438, -0.0244, -0.0907, -0.0579, -0.0821,  0.0969,\n         0.0219, -0.0010,  0.0080,  0.0569, -0.1235,  0.0433,  0.0127, -0.0987,\n        -0.1035,  0.0839, -0.0537,  0.0864,  0.0781,  0.0683, -0.1107, -0.0526,\n         0.1122,  0.0207,  0.0312, -0.0813,  0.0658, -0.1054,  0.1244, -0.0697,\n         0.0490, -0.0404, -0.0100, -0.1070,  0.0549, -0.1171, -0.0265,  0.0830,\n         0.0210, -0.0726,  0.0626,  0.0954, -0.0521, -0.0836,  0.0442,  0.0854,\n        -0.1076, -0.0632,  0.0066,  0.0889,  0.0560,  0.0328,  0.0190, -0.0796,\n        -0.0087,  0.0312,  0.0394,  0.1194,  0.0644,  0.0199,  0.0181, -0.1122]), 'meta_learner.transductive_net.feature_extractors.1.0.weight': tensor([[-0.0471, -0.0461, -0.0610,  ..., -0.0183,  0.0652, -0.0366],\n        [ 0.0540, -0.1024,  0.0313,  ..., -0.1016, -0.0314,  0.0064],\n        [-0.1206, -0.1000, -0.0966,  ..., -0.1119, -0.0056, -0.0148],\n        ...,\n        [ 0.0364,  0.0108,  0.0190,  ..., -0.0666,  0.0444,  0.0844],\n        [ 0.0560,  0.0084, -0.1117,  ..., -0.1201, -0.0038,  0.0364],\n        [ 0.0530, -0.0869, -0.0940,  ..., -0.0557, -0.0920, -0.0819]]), 'meta_learner.transductive_net.feature_extractors.1.0.bias': tensor([ 0.0589,  0.0624,  0.1049,  0.0404, -0.0222,  0.0122, -0.0515, -0.0700,\n        -0.0234,  0.0099,  0.0161,  0.1198,  0.0666, -0.1088, -0.1267, -0.0493,\n         0.1234,  0.0133, -0.0482,  0.1148, -0.0361, -0.1217, -0.0797,  0.0751,\n         0.0613,  0.0491, -0.0745,  0.1107, -0.1038,  0.0473,  0.0794, -0.0794,\n        -0.0113,  0.0934,  0.0726,  0.0580, -0.0580,  0.0696,  0.1182,  0.0790,\n         0.0108,  0.0301, -0.0624,  0.0984, -0.1259,  0.0768, -0.0068, -0.0731,\n        -0.0943, -0.0819, -0.0731,  0.0614, -0.0178,  0.0435, -0.0521, -0.0643,\n        -0.0507, -0.0980,  0.0272, -0.0845,  0.1189, -0.0297,  0.0992, -0.1011]), 'meta_learner.transductive_net.feature_extractors.2.0.weight': tensor([[-0.0788,  0.1270,  0.0807,  ...,  0.0023,  0.0208,  0.0295],\n        [ 0.0345,  0.0424,  0.0290,  ...,  0.0136,  0.0031,  0.0942],\n        [-0.0995, -0.0242, -0.1266,  ...,  0.0537,  0.0382, -0.1147],\n        ...,\n        [-0.0864, -0.0191, -0.0162,  ..., -0.0384,  0.0299,  0.0053],\n        [ 0.0248,  0.1090,  0.0212,  ..., -0.0812, -0.1388, -0.1060],\n        [ 0.0069, -0.0712, -0.0219,  ...,  0.0669,  0.0116, -0.0129]]), 'meta_learner.transductive_net.feature_extractors.2.0.bias': tensor([ 1.9107e-02,  2.6844e-02, -9.3703e-02, -1.0953e-01,  5.0950e-02,\n         4.7884e-02,  1.0766e-01, -9.8395e-02, -1.6204e-02, -7.6994e-03,\n        -3.6271e-02,  1.4001e-02,  5.3148e-03, -3.0604e-02,  1.1374e-01,\n        -3.4220e-02,  7.4965e-03, -1.3377e-01, -3.9248e-02,  8.7988e-02,\n         7.1995e-02,  8.3618e-02, -9.8814e-02,  4.4297e-02, -7.0267e-02,\n         3.4014e-02, -3.8281e-02,  2.8011e-04, -6.1258e-02,  9.7110e-03,\n         1.0991e-01, -5.5725e-02,  8.1883e-02,  2.2623e-02,  1.3329e-01,\n         1.5977e-02,  1.0091e-01,  1.2494e-02, -5.0609e-02,  4.5804e-02,\n        -1.1001e-01,  9.6449e-02,  2.4337e-02,  1.4165e-02,  1.3465e-01,\n         7.8434e-02, -2.9048e-02,  7.2174e-02, -2.0821e-02,  2.5137e-03,\n        -7.3977e-02,  2.9508e-02, -8.1027e-02,  8.5295e-02,  4.2192e-05,\n         1.2413e-01,  1.1811e-01,  6.6823e-02, -4.7157e-02,  6.8040e-02,\n         7.8532e-02, -8.9544e-02,  2.6054e-02,  1.1004e-01, -1.2808e-01,\n         4.7518e-02,  1.2200e-01, -8.0789e-02, -8.3385e-02,  1.1322e-01,\n         1.0127e-01,  4.8075e-02,  1.1499e-01, -8.6327e-02, -5.9615e-03,\n         4.3017e-02,  5.1537e-03, -2.6238e-02, -1.0518e-01,  4.0834e-02,\n         1.0617e-01,  7.4070e-02, -8.8199e-02, -3.3530e-03,  7.2355e-02,\n        -2.4663e-02,  2.4661e-02,  4.0882e-02,  6.4988e-02,  1.7275e-02,\n         4.8189e-02, -6.8117e-02,  9.3285e-02, -4.0048e-02,  1.1001e-01,\n         1.2770e-01,  4.8864e-02, -2.1547e-02,  8.7939e-02, -9.3600e-02,\n         9.6054e-02, -6.5918e-02,  1.1730e-01, -6.7767e-02, -3.8484e-02,\n         3.5328e-02, -4.8212e-02,  8.2527e-02, -2.9419e-02, -1.1611e-01,\n        -1.3151e-01, -4.1696e-02, -7.1211e-02,  1.0603e-01,  8.9960e-02,\n         5.9785e-02,  1.1840e-01, -5.8788e-02,  2.1903e-02, -1.0001e-01,\n         6.5912e-02,  7.4182e-02,  7.9910e-02, -1.5918e-03, -4.6959e-02,\n        -3.2772e-02, -1.0250e-01, -4.8888e-02,  3.0382e-02, -1.5696e-02,\n         4.9780e-02, -8.2241e-03, -4.4501e-02,  3.6154e-02,  4.7964e-02,\n        -1.2118e-01,  7.5660e-03, -1.1281e-03,  3.6597e-02, -4.5144e-02,\n         1.9789e-03, -1.1730e-01, -2.2212e-02,  2.5055e-03, -1.2096e-01,\n         1.9494e-02,  8.1434e-02, -1.1407e-02,  1.2258e-01,  1.0503e-01,\n         8.0610e-02,  7.8617e-03,  1.0511e-01,  6.9548e-02,  4.2771e-02,\n        -1.2514e-01,  9.3495e-02, -1.0705e-01, -2.3176e-02,  3.6384e-02,\n         3.2372e-02, -6.4287e-03, -1.3555e-01,  3.1947e-02,  1.0806e-01,\n        -1.0397e-01, -8.3065e-02, -6.5879e-02,  8.3885e-02,  2.1417e-02,\n        -6.6270e-02, -1.2252e-01,  6.9040e-02,  7.6686e-02,  3.2072e-02,\n        -9.8910e-03,  4.5181e-02,  4.0609e-02,  5.2565e-03,  9.5278e-02,\n         7.8651e-02, -7.8615e-02, -6.5317e-02,  1.0716e-01,  2.4559e-02,\n        -2.6096e-02,  8.0413e-02, -1.1658e-01, -8.9059e-02, -1.1640e-01,\n        -1.2524e-01, -2.5288e-03, -4.2249e-02,  7.6084e-02,  8.6394e-02,\n         7.8277e-02,  8.7253e-03,  1.1410e-01, -1.2124e-02, -5.6828e-02,\n        -4.2495e-02,  6.0844e-02, -3.0134e-02,  1.8235e-02,  6.1600e-02,\n        -5.1466e-02,  4.8938e-03, -8.0504e-02,  2.5296e-02,  1.2440e-01,\n         2.7578e-02, -4.9954e-02,  1.2856e-01, -1.1728e-01, -4.2132e-02,\n         4.0586e-02,  3.8407e-03, -1.2721e-01, -8.7335e-03, -4.0140e-03,\n         6.2021e-02,  1.0992e-01, -8.6320e-03,  9.1552e-03,  1.1135e-01,\n        -1.0826e-01,  1.1960e-01, -7.1721e-02, -8.5316e-02,  3.8513e-02,\n        -1.5271e-03, -1.0536e-01, -2.8553e-02,  7.1488e-02,  1.0235e-01,\n        -8.8920e-02, -8.6932e-02,  1.1720e-01, -3.7419e-02, -2.6876e-02,\n         7.3789e-02, -1.1031e-01, -1.4170e-02, -6.8104e-02, -6.4921e-02,\n         9.5410e-02,  2.5002e-02,  3.7616e-02, -3.1058e-02, -1.0029e-01,\n        -9.8138e-02, -8.0539e-02,  1.0798e-01,  4.5891e-02,  2.1076e-02,\n         7.1110e-02]), 'meta_learner.transductive_net.feature_projection.0.weight': tensor([[ 0.0262,  0.0392, -0.0079,  ..., -0.0196,  0.0510, -0.0035],\n        [ 0.0330,  0.0420, -0.0012,  ..., -0.0059, -0.0212, -0.0325],\n        [ 0.0056,  0.0014,  0.0233,  ...,  0.0065,  0.0385, -0.0446],\n        ...,\n        [ 0.0430, -0.0253, -0.0189,  ...,  0.0333,  0.0464,  0.0208],\n        [-0.0035, -0.0143, -0.0091,  ..., -0.0005, -0.0344, -0.0440],\n        [ 0.0274, -0.0365, -0.0165,  ...,  0.0348, -0.0186,  0.0122]]), 'meta_learner.transductive_net.feature_projection.0.bias': tensor([ 0.0383, -0.0337, -0.0198, -0.0306, -0.0112,  0.0259, -0.0500,  0.0159,\n        -0.0012,  0.0309, -0.0295, -0.0256,  0.0150, -0.0598,  0.0055,  0.0295,\n        -0.0210,  0.0366, -0.0026,  0.0139,  0.0127,  0.0089, -0.0324, -0.0138,\n        -0.0226, -0.0108,  0.0502, -0.0358,  0.0312, -0.0222, -0.0308,  0.0278,\n         0.0060, -0.0120, -0.0344,  0.0162, -0.0286,  0.0101,  0.0320,  0.0401,\n         0.0115, -0.0081,  0.0455, -0.0390,  0.0031, -0.0171,  0.0108, -0.0300,\n        -0.0214, -0.0320,  0.0017, -0.0500,  0.0198, -0.0099, -0.0122,  0.0403,\n         0.0260, -0.0123, -0.0265, -0.0482,  0.0193,  0.0425,  0.0059, -0.0304]), 'meta_learner.transductive_net.classifier.0.weight': tensor([[ 0.0717, -0.0804,  0.0465,  ..., -0.0225,  0.0733,  0.0837],\n        [-0.0651, -0.0565,  0.0410,  ..., -0.0781, -0.1016, -0.0100],\n        [-0.1076,  0.0647,  0.0747,  ...,  0.0049, -0.0335, -0.1130],\n        ...,\n        [-0.1147,  0.0261, -0.1212,  ..., -0.0713, -0.1189,  0.0434],\n        [ 0.0031, -0.0050,  0.0960,  ...,  0.0906, -0.0885,  0.0328],\n        [-0.0457, -0.0833, -0.1142,  ..., -0.0711, -0.1097,  0.0251]]), 'meta_learner.transductive_net.classifier.0.bias': tensor([ 0.0238, -0.0064,  0.1070, -0.0295,  0.0291, -0.0182,  0.0019,  0.0263,\n        -0.0815,  0.0424,  0.0183,  0.0328, -0.0971,  0.1128, -0.0815, -0.1221,\n         0.0405,  0.0482,  0.1096, -0.0868,  0.0017,  0.0079,  0.0842,  0.0309,\n        -0.0947,  0.1216, -0.0554, -0.0919, -0.0366,  0.0273,  0.0405, -0.0070,\n         0.1236, -0.0978, -0.0574,  0.0134, -0.1068, -0.0940,  0.0867,  0.0952,\n         0.0572, -0.0494,  0.0244, -0.1016,  0.0124, -0.1166, -0.0232, -0.1090,\n         0.0415,  0.0695,  0.0357,  0.0921,  0.0827, -0.0747, -0.0100,  0.0852,\n         0.0728,  0.1053,  0.0468,  0.0556,  0.0617,  0.0686, -0.0294, -0.0296]), 'meta_learner.transductive_net.classifier.3.weight': tensor([[-4.6429e-02,  1.0003e-01,  1.9178e-05,  ...,  6.1526e-02,\n          6.1236e-02,  6.9374e-02],\n        [ 3.8632e-02,  8.2375e-02,  3.3821e-02,  ...,  1.1482e-01,\n          9.9284e-03,  7.9468e-02],\n        [ 2.7745e-02, -9.0051e-03, -2.8994e-02,  ...,  8.7031e-02,\n         -4.2891e-02, -5.4357e-02],\n        ...,\n        [-3.1249e-02,  1.2378e-01, -5.0974e-02,  ..., -3.0723e-02,\n          8.4047e-02,  4.9875e-02],\n        [-3.8756e-02, -1.0168e-01,  1.8436e-02,  ...,  5.5887e-03,\n         -1.0875e-03, -9.9167e-05],\n        [ 1.1189e-01,  1.2428e-01,  4.1206e-02,  ...,  3.1893e-02,\n          3.3560e-02,  1.0983e-01]]), 'meta_learner.transductive_net.classifier.3.bias': tensor([-0.1046,  0.0883,  0.0814, -0.0237,  0.0236, -0.0928, -0.0143,  0.0730,\n         0.0767,  0.0694,  0.0180,  0.0803, -0.0463, -0.0667, -0.0257,  0.0963,\n         0.0669,  0.0086, -0.0753,  0.0643, -0.0542,  0.0117, -0.0064, -0.0365,\n        -0.0885,  0.0064,  0.0590, -0.0888, -0.0935,  0.0537, -0.0983,  0.0029]), 'meta_learner.transductive_net.classifier.6.weight': tensor([[-0.0446, -0.0506,  0.1760, -0.0712, -0.1167,  0.1742, -0.0514, -0.1187,\n          0.0647, -0.0336, -0.1118,  0.1458,  0.0586, -0.0199, -0.1588,  0.1473,\n         -0.1061,  0.1672, -0.1626, -0.0116,  0.0493,  0.1262,  0.1219,  0.0069,\n          0.1500, -0.0579, -0.0195, -0.1544,  0.1074, -0.1345,  0.0002, -0.1222],\n        [ 0.1432,  0.1606, -0.0237,  0.1192,  0.1584,  0.0441,  0.1487,  0.0045,\n          0.0715,  0.1482, -0.1194,  0.1631, -0.1762,  0.0043, -0.1497, -0.0594,\n         -0.1368,  0.1553,  0.0912,  0.0618, -0.0717, -0.1578,  0.1408,  0.0899,\n         -0.0392, -0.0742,  0.0106, -0.0593, -0.1116, -0.1296,  0.1618, -0.1333]]), 'meta_learner.transductive_net.classifier.6.bias': tensor([-0.1458,  0.0698]), 'meta_learner.transductive_net.self_attention.in_proj_weight': tensor([[ 0.1516, -0.0969, -0.0815,  ..., -0.1046,  0.0158, -0.0757],\n        [ 0.0491,  0.1240,  0.0696,  ..., -0.0231,  0.0490,  0.0367],\n        [-0.0412,  0.0212,  0.0187,  ..., -0.0074, -0.0306,  0.1516],\n        ...,\n        [ 0.1048,  0.0658, -0.0366,  ...,  0.0767, -0.0397,  0.1083],\n        [ 0.0441,  0.0920, -0.0211,  ...,  0.0463,  0.0069, -0.0163],\n        [-0.0221, -0.0819,  0.0177,  ..., -0.1033, -0.1100, -0.0678]]), 'meta_learner.transductive_net.self_attention.in_proj_bias': tensor([-7.6084e-04, -6.4567e-03, -7.5335e-03, -7.0269e-03, -7.8576e-03,\n         4.7884e-03,  1.7790e-03, -6.0318e-03,  3.2076e-04, -2.9476e-03,\n         3.8471e-03,  1.7151e-03, -3.8097e-03,  8.5410e-04,  2.9492e-03,\n         1.9902e-04, -4.4201e-03,  9.5501e-04,  3.2235e-04,  5.0141e-03,\n        -7.0631e-03, -2.6737e-03, -3.0930e-03, -5.1987e-03, -4.9680e-03,\n        -2.7142e-03,  5.9979e-03, -2.9132e-03, -8.6926e-03, -2.3789e-03,\n         2.0530e-03, -6.0485e-03, -4.0229e-03,  1.7936e-03, -1.2325e-02,\n         1.5117e-03,  2.7511e-03,  3.6401e-03, -3.8372e-04,  5.7052e-04,\n         1.2048e-03, -5.8204e-03, -2.1107e-03, -5.7559e-04,  4.2494e-03,\n         5.7566e-03, -1.9825e-03,  4.5099e-03,  3.0770e-04,  1.1339e-02,\n        -1.4327e-03, -2.9878e-03,  2.5928e-03,  1.2899e-05, -6.5014e-04,\n        -4.4424e-03, -2.9779e-03,  7.0475e-03,  1.5621e-03,  3.8745e-05,\n        -1.6719e-03,  3.6695e-03,  4.7346e-03, -1.4814e-03, -8.7248e-05,\n         9.4183e-05,  1.4856e-04,  1.4863e-05,  5.0931e-05,  1.0501e-04,\n        -7.7579e-05,  4.5603e-05,  3.8799e-05,  1.3544e-04, -1.0241e-04,\n        -1.0621e-04, -1.5904e-04,  2.4004e-04, -4.9088e-05,  6.1402e-05,\n        -4.2327e-05,  1.9517e-04, -7.6830e-05, -2.3215e-05,  2.7770e-05,\n         1.2662e-04,  5.6323e-05, -4.3556e-05,  1.0662e-04, -1.1451e-04,\n        -5.9104e-05,  3.6064e-05,  4.9152e-05,  4.0417e-05, -2.1024e-05,\n        -5.0851e-05,  7.0079e-05,  2.9208e-05, -9.7430e-05, -3.2039e-05,\n         5.2891e-05,  1.3371e-04,  3.4475e-05, -7.9514e-05, -3.9935e-05,\n         5.9857e-05,  1.1756e-04,  2.9659e-05,  9.1539e-05, -5.1626e-05,\n        -1.8563e-05,  1.8716e-04, -8.1994e-05, -3.9021e-05, -8.2706e-05,\n        -1.0042e-04, -2.1922e-04,  2.8841e-05,  5.5188e-05,  1.8974e-05,\n        -2.3194e-05, -2.2233e-05, -1.4322e-04, -1.3362e-04, -6.4823e-05,\n        -1.3061e-04,  5.6258e-07, -4.3033e-05,  2.2890e-04, -3.3190e-04,\n         4.0936e-05,  2.0331e-05, -6.6047e-04, -3.1247e-04,  2.4485e-05,\n         4.5136e-04,  9.6149e-05,  9.6437e-05, -1.2205e-04,  4.4937e-04,\n        -3.1935e-04,  2.4745e-05, -3.7370e-04,  1.8725e-04,  5.4958e-04,\n         2.8794e-04,  3.6564e-04, -4.4280e-04,  2.0512e-04,  6.2867e-05,\n        -2.5356e-04, -2.1092e-04, -1.7600e-04, -2.9461e-04, -5.7626e-04,\n        -2.0195e-04, -1.2415e-04,  1.8068e-04,  3.8600e-04, -1.1844e-04,\n         3.3446e-07, -2.0234e-04, -1.4222e-04,  1.0358e-04, -4.7577e-04,\n        -1.5678e-04,  8.2942e-04, -4.3954e-04, -5.4114e-04,  2.0932e-05,\n        -4.0742e-04, -4.0497e-04, -8.2381e-04, -5.9731e-05, -1.6437e-04,\n         3.4785e-04, -7.1299e-04,  5.7473e-04, -1.6590e-05, -1.0975e-04,\n         8.8996e-06, -5.1937e-04,  4.1572e-04, -2.0668e-04,  9.7290e-04,\n         3.3855e-04, -2.1759e-04,  6.4390e-05, -1.1765e-04,  4.5403e-04,\n        -1.3622e-03, -4.2519e-04]), 'meta_learner.transductive_net.self_attention.out_proj.weight': tensor([[ 0.0005,  0.0839, -0.1069,  ..., -0.0274,  0.0206, -0.0400],\n        [ 0.1173, -0.0646,  0.0702,  ..., -0.0830, -0.0793, -0.0639],\n        [-0.0199, -0.0880, -0.0437,  ..., -0.0347, -0.0134, -0.0281],\n        ...,\n        [ 0.0626, -0.0839,  0.0133,  ..., -0.0801, -0.0050,  0.0797],\n        [ 0.1190,  0.0589,  0.0686,  ..., -0.0096,  0.0511,  0.0342],\n        [-0.1024, -0.0601, -0.0985,  ..., -0.0714, -0.1294, -0.1240]]), 'meta_learner.transductive_net.self_attention.out_proj.bias': tensor([ 3.3997e-04,  1.9042e-04,  3.4733e-04, -1.4245e-04, -2.4507e-04,\n         9.2058e-04,  7.3753e-05,  2.2424e-04, -3.2082e-04,  8.6777e-05,\n        -1.0919e-04,  2.5948e-04,  3.3356e-04, -8.8559e-05,  3.0947e-04,\n         8.9846e-04,  2.4271e-05,  6.1691e-04,  7.8686e-04, -1.2366e-04,\n         2.8658e-04, -7.1933e-04, -3.2224e-04, -4.7671e-04,  3.1003e-04,\n         1.0765e-05, -6.4299e-04,  6.7687e-06,  5.0970e-04,  2.9156e-04,\n        -4.0651e-04, -7.4830e-05,  7.0508e-04, -3.1441e-04, -3.7986e-04,\n         4.1024e-04, -7.6483e-05, -1.9448e-05,  1.8691e-04,  1.6802e-04,\n         7.5760e-06,  2.9412e-05,  2.7985e-05, -5.9497e-04, -2.7955e-04,\n        -3.8804e-04,  2.5568e-04, -5.4236e-04,  1.4553e-04,  5.0419e-04,\n         3.7379e-04, -3.2612e-04,  1.7283e-04, -4.4806e-04, -2.6488e-04,\n        -6.9607e-05,  2.5856e-05, -1.2920e-04,  7.0677e-05,  6.6221e-04,\n         4.4130e-05, -7.4673e-05, -3.2058e-04,  2.0099e-04]), 'meta_learner.transductive_net.layer_norm.weight': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'meta_learner.transductive_net.layer_norm.bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}, sample_count=53923, training_loss=np.float64(0.11820732872933151), validation_accuracy=np.float64(0.7260000097751618), validation_precision=0.0, validation_recall=0.0, validation_f1_score=0.0, timestamp=1760230538.899923, model_hash='a454303a86f20821525b495b6341a5f9f86c578b356701af8e751f0f24637bfb', ipfs_cid='QmefoL2yox5hkb3pxc9rkZjrMpXKzS9rJuKdqMwJ9XGn84', blockchain_tx_hash='f29c2e49af67365d7a47e6f7b9efbccf199ab6bb9bb5f870901baff2919ea7c7')",
        "ClientUpdate(client_id='client_2', model_parameters={'meta_learner.transductive_net.feature_extractors.0.0.weight': tensor([[ 0.0418,  0.0575, -0.0659,  ...,  0.0144,  0.0370, -0.0662],\n        [ 0.0813,  0.1068, -0.0700,  ..., -0.0083, -0.0754,  0.0741],\n        [-0.0048, -0.1004, -0.0351,  ...,  0.0695,  0.0429,  0.0169],\n        ...,\n        [ 0.0712,  0.0367,  0.0874,  ..., -0.0485, -0.0492,  0.1268],\n        [-0.0039,  0.1118, -0.0025,  ..., -0.0679, -0.0781, -0.1171],\n        [ 0.0104, -0.1170, -0.0031,  ..., -0.0137,  0.0405,  0.0475]]), 'meta_learner.transductive_net.feature_extractors.0.0.bias': tensor([-0.0798, -0.0907,  0.0693, -0.0146,  0.0620, -0.0812, -0.0226, -0.0760,\n        -0.0194, -0.0411, -0.1216, -0.0564,  0.0170, -0.0962,  0.0485,  0.0291,\n        -0.0620, -0.0025,  0.1075, -0.1005,  0.0814,  0.0492,  0.0464,  0.0750,\n        -0.0278, -0.0769, -0.1270, -0.0604,  0.1128,  0.0299,  0.0664,  0.0241,\n         0.0061, -0.0406,  0.0572, -0.0162, -0.1135,  0.0164,  0.1190,  0.0831,\n        -0.1032, -0.0988, -0.0605, -0.0536, -0.1015, -0.0081, -0.0033, -0.0639,\n        -0.0674, -0.0134, -0.0713,  0.0231, -0.0656,  0.0356, -0.0720, -0.0555,\n         0.0672,  0.0270,  0.0913,  0.0533,  0.0607, -0.0250,  0.0588,  0.1070,\n        -0.0778, -0.0831,  0.0480, -0.0289, -0.0908, -0.0591, -0.0858,  0.0915,\n         0.0240, -0.0051,  0.0083,  0.0678, -0.1168,  0.0346, -0.0014, -0.0970,\n        -0.1120,  0.0827, -0.0629,  0.0906,  0.0741,  0.0737, -0.1051, -0.0553,\n         0.1318,  0.0126,  0.0299, -0.0652,  0.0769, -0.0970,  0.1294, -0.0598,\n         0.0520, -0.0434, -0.0112, -0.1096,  0.0733, -0.1176, -0.0171,  0.0889,\n         0.0298, -0.0805,  0.0524,  0.0818, -0.0636, -0.0882,  0.0364,  0.0737,\n        -0.1148, -0.0642,  0.0046,  0.0825,  0.0502,  0.0282,  0.0049, -0.0671,\n        -0.0107,  0.0352,  0.0356,  0.1049,  0.0684,  0.0109,  0.0215, -0.1265]), 'meta_learner.transductive_net.feature_extractors.1.0.weight': tensor([[-0.0440, -0.0430, -0.0578,  ..., -0.0142,  0.0665, -0.0366],\n        [ 0.0485, -0.1078,  0.0329,  ..., -0.1092, -0.0329,  0.0064],\n        [-0.1115, -0.0910, -0.1080,  ..., -0.1010,  0.0103, -0.0148],\n        ...,\n        [ 0.0358,  0.0102,  0.0293,  ..., -0.0530,  0.0489,  0.0844],\n        [ 0.0455, -0.0021, -0.1222,  ..., -0.1130,  0.0148,  0.0364],\n        [ 0.0543, -0.0856, -0.0890,  ..., -0.0564, -0.1116, -0.0819]]), 'meta_learner.transductive_net.feature_extractors.1.0.bias': tensor([ 0.0558,  0.0678,  0.0958,  0.0398, -0.0210,  0.0035, -0.0449, -0.0733,\n        -0.0214,  0.0117,  0.0233,  0.1210,  0.0721, -0.1054, -0.1201, -0.0474,\n         0.1108,  0.0132, -0.0499,  0.1115, -0.0497, -0.1267, -0.0777,  0.0804,\n         0.0570,  0.0582, -0.0777,  0.1090, -0.1043,  0.0542,  0.0765, -0.0751,\n        -0.0101,  0.0948,  0.0816,  0.0725, -0.0642,  0.0691,  0.1097,  0.0835,\n         0.0251,  0.0222, -0.0578,  0.0903, -0.1317,  0.0742, -0.0106, -0.0752,\n        -0.1001, -0.0663, -0.0880,  0.0633, -0.0290,  0.0432, -0.0597, -0.0569,\n        -0.0512, -0.0991,  0.0219, -0.0835,  0.1092, -0.0291,  0.1097, -0.1024]), 'meta_learner.transductive_net.feature_extractors.2.0.weight': tensor([[-0.0884,  0.1174,  0.0775,  ...,  0.0050,  0.0214,  0.0295],\n        [ 0.0368,  0.0447,  0.0255,  ...,  0.0246,  0.0099,  0.0942],\n        [-0.1055, -0.0301, -0.1272,  ...,  0.0556,  0.0311, -0.1147],\n        ...,\n        [-0.0934, -0.0260, -0.0232,  ..., -0.0352,  0.0358,  0.0053],\n        [ 0.0254,  0.1096,  0.0234,  ..., -0.0719, -0.1222, -0.1060],\n        [ 0.0160, -0.0621, -0.0128,  ...,  0.0590,  0.0038, -0.0129]]), 'meta_learner.transductive_net.feature_extractors.2.0.bias': tensor([ 0.0287,  0.0245, -0.0877, -0.1242,  0.0615,  0.0517,  0.1018, -0.0902,\n        -0.0316, -0.0151, -0.0220,  0.0110,  0.0064, -0.0501,  0.1072, -0.0356,\n         0.0110, -0.1351, -0.0369,  0.0651,  0.0788,  0.0781, -0.0843,  0.0412,\n        -0.0627,  0.0399, -0.0427, -0.0124, -0.0526,  0.0048,  0.1094, -0.0651,\n         0.0902,  0.0195,  0.1135,  0.0147,  0.1136,  0.0192, -0.0552,  0.0363,\n        -0.1037,  0.1048,  0.0286,  0.0155,  0.1230,  0.0914, -0.0266,  0.0766,\n        -0.0141, -0.0036, -0.0617,  0.0275, -0.0937,  0.0740, -0.0206,  0.1267,\n         0.1239,  0.0697, -0.0393,  0.0721,  0.0694, -0.0712,  0.0320,  0.1087,\n        -0.1303,  0.0432,  0.1132, -0.0934, -0.0876,  0.0976,  0.1034,  0.0535,\n         0.1122, -0.0837, -0.0175,  0.0629, -0.0046, -0.0214, -0.1128,  0.0289,\n         0.0964,  0.0861, -0.0806, -0.0042,  0.0784, -0.0252,  0.0307,  0.0425,\n         0.0456,  0.0057,  0.0694, -0.0871,  0.1008, -0.0335,  0.1082,  0.1115,\n         0.0353, -0.0184,  0.0872, -0.0960,  0.0907, -0.0494,  0.1109, -0.0757,\n        -0.0385,  0.0237, -0.0560,  0.0906, -0.0176, -0.1178, -0.1082, -0.0492,\n        -0.0972,  0.1040,  0.0747,  0.0635,  0.1286, -0.0552,  0.0098, -0.1123,\n         0.0649,  0.0816,  0.0829, -0.0006, -0.0242, -0.0339, -0.1077, -0.0558,\n         0.0236, -0.0101,  0.0489, -0.0027, -0.0311,  0.0402,  0.0631, -0.1210,\n         0.0102,  0.0041,  0.0387, -0.0409,  0.0115, -0.1118, -0.0257, -0.0010,\n        -0.1159,  0.0198,  0.0819, -0.0115,  0.1205,  0.1025,  0.0860,  0.0030,\n         0.0975,  0.0935,  0.0496, -0.1268,  0.1073, -0.1046, -0.0215,  0.0381,\n         0.0191,  0.0118, -0.1210,  0.0369,  0.1087, -0.1040, -0.0969, -0.0564,\n         0.0885,  0.0337, -0.0810, -0.1173,  0.0655,  0.0812,  0.0184, -0.0160,\n         0.0455,  0.0441,  0.0040,  0.0897,  0.0649, -0.0654, -0.0680,  0.1203,\n         0.0207, -0.0330,  0.0827, -0.1140, -0.1009, -0.0943, -0.1202, -0.0030,\n        -0.0530,  0.0873,  0.0744,  0.0918,  0.0110,  0.1112, -0.0118, -0.0711,\n        -0.0305,  0.0692, -0.0415,  0.0136,  0.0570, -0.0549,  0.0119, -0.0871,\n         0.0172,  0.1199,  0.0257, -0.0518,  0.1277, -0.1240, -0.0401,  0.0572,\n         0.0012, -0.1319, -0.0157, -0.0073,  0.0559,  0.1051, -0.0099,  0.0019,\n         0.1098, -0.1134,  0.1180, -0.0593, -0.1046,  0.0369, -0.0115, -0.1106,\n        -0.0140,  0.0789,  0.1058, -0.0971, -0.0951,  0.1321, -0.0265, -0.0109,\n         0.0857, -0.1208, -0.0142, -0.0781, -0.0510,  0.0925,  0.0234,  0.0414,\n        -0.0323, -0.0932, -0.1030, -0.0775,  0.1163,  0.0528,  0.0204,  0.0620]), 'meta_learner.transductive_net.feature_projection.0.weight': tensor([[ 0.0221,  0.0151,  0.0049,  ..., -0.0291,  0.0395, -0.0175],\n        [ 0.0335,  0.0391, -0.0028,  ..., -0.0113, -0.0352, -0.0407],\n        [ 0.0067,  0.0060,  0.0197,  ...,  0.0187,  0.0438, -0.0261],\n        ...,\n        [ 0.0315, -0.0222, -0.0295,  ...,  0.0438,  0.0370,  0.0145],\n        [-0.0145, -0.0080,  0.0039,  ...,  0.0021, -0.0280, -0.0435],\n        [ 0.0165, -0.0425, -0.0041,  ...,  0.0217, -0.0178, -0.0024]]), 'meta_learner.transductive_net.feature_projection.0.bias': tensor([ 0.0265, -0.0490, -0.0033, -0.0303, -0.0249,  0.0092, -0.0460,  0.0052,\n        -0.0012,  0.0292, -0.0176, -0.0362,  0.0058, -0.0529,  0.0051,  0.0375,\n        -0.0272,  0.0284,  0.0012,  0.0279, -0.0072,  0.0039, -0.0421, -0.0107,\n        -0.0155, -0.0111,  0.0418, -0.0426,  0.0511, -0.0174, -0.0322,  0.0206,\n         0.0051, -0.0102, -0.0309,  0.0195, -0.0304,  0.0213,  0.0471,  0.0262,\n         0.0123, -0.0063,  0.0302, -0.0337, -0.0002, -0.0164,  0.0009, -0.0215,\n        -0.0202, -0.0332,  0.0104, -0.0349,  0.0070, -0.0025, -0.0160,  0.0427,\n         0.0221, -0.0103, -0.0286, -0.0475,  0.0213,  0.0462,  0.0145, -0.0435]), 'meta_learner.transductive_net.classifier.0.weight': tensor([[ 0.0717, -0.0804,  0.0465,  ..., -0.0225,  0.0733,  0.0837],\n        [-0.0651, -0.0565,  0.0410,  ..., -0.0781, -0.1016, -0.0100],\n        [-0.1076,  0.0647,  0.0747,  ...,  0.0049, -0.0335, -0.1130],\n        ...,\n        [-0.1147,  0.0261, -0.1212,  ..., -0.0713, -0.1189,  0.0434],\n        [ 0.0031, -0.0050,  0.0960,  ...,  0.0906, -0.0885,  0.0328],\n        [-0.0457, -0.0833, -0.1142,  ..., -0.0711, -0.1097,  0.0251]]), 'meta_learner.transductive_net.classifier.0.bias': tensor([ 0.0238, -0.0064,  0.1070, -0.0295,  0.0291, -0.0182,  0.0019,  0.0263,\n        -0.0815,  0.0424,  0.0183,  0.0328, -0.0971,  0.1128, -0.0815, -0.1221,\n         0.0405,  0.0482,  0.1096, -0.0868,  0.0017,  0.0079,  0.0842,  0.0309,\n        -0.0947,  0.1216, -0.0554, -0.0919, -0.0366,  0.0273,  0.0405, -0.0070,\n         0.1236, -0.0978, -0.0574,  0.0134, -0.1068, -0.0940,  0.0867,  0.0952,\n         0.0572, -0.0494,  0.0244, -0.1016,  0.0124, -0.1166, -0.0232, -0.1090,\n         0.0415,  0.0695,  0.0357,  0.0921,  0.0827, -0.0747, -0.0100,  0.0852,\n         0.0728,  0.1053,  0.0468,  0.0556,  0.0617,  0.0686, -0.0294, -0.0296]), 'meta_learner.transductive_net.classifier.3.weight': tensor([[-4.6429e-02,  1.0003e-01,  1.9178e-05,  ...,  6.1526e-02,\n          6.1236e-02,  6.9374e-02],\n        [ 3.8632e-02,  8.2375e-02,  3.3821e-02,  ...,  1.1482e-01,\n          9.9284e-03,  7.9468e-02],\n        [ 2.7745e-02, -9.0051e-03, -2.8994e-02,  ...,  8.7031e-02,\n         -4.2891e-02, -5.4357e-02],\n        ...,\n        [-3.1249e-02,  1.2378e-01, -5.0974e-02,  ..., -3.0723e-02,\n          8.4047e-02,  4.9875e-02],\n        [-3.8756e-02, -1.0168e-01,  1.8436e-02,  ...,  5.5887e-03,\n         -1.0875e-03, -9.9167e-05],\n        [ 1.1189e-01,  1.2428e-01,  4.1206e-02,  ...,  3.1893e-02,\n          3.3560e-02,  1.0983e-01]]), 'meta_learner.transductive_net.classifier.3.bias': tensor([-0.1046,  0.0883,  0.0814, -0.0237,  0.0236, -0.0928, -0.0143,  0.0730,\n         0.0767,  0.0694,  0.0180,  0.0803, -0.0463, -0.0667, -0.0257,  0.0963,\n         0.0669,  0.0086, -0.0753,  0.0643, -0.0542,  0.0117, -0.0064, -0.0365,\n        -0.0885,  0.0064,  0.0590, -0.0888, -0.0935,  0.0537, -0.0983,  0.0029]), 'meta_learner.transductive_net.classifier.6.weight': tensor([[-0.0446, -0.0506,  0.1760, -0.0712, -0.1167,  0.1742, -0.0514, -0.1187,\n          0.0647, -0.0336, -0.1118,  0.1458,  0.0586, -0.0199, -0.1588,  0.1473,\n         -0.1061,  0.1672, -0.1626, -0.0116,  0.0493,  0.1262,  0.1219,  0.0069,\n          0.1500, -0.0579, -0.0195, -0.1544,  0.1074, -0.1345,  0.0002, -0.1222],\n        [ 0.1432,  0.1606, -0.0237,  0.1192,  0.1584,  0.0441,  0.1487,  0.0045,\n          0.0715,  0.1482, -0.1194,  0.1631, -0.1762,  0.0043, -0.1497, -0.0594,\n         -0.1368,  0.1553,  0.0912,  0.0618, -0.0717, -0.1578,  0.1408,  0.0899,\n         -0.0392, -0.0742,  0.0106, -0.0593, -0.1116, -0.1296,  0.1618, -0.1333]]), 'meta_learner.transductive_net.classifier.6.bias': tensor([-0.1458,  0.0698]), 'meta_learner.transductive_net.self_attention.in_proj_weight': tensor([[ 0.1291, -0.1104, -0.0712,  ..., -0.1003,  0.0057, -0.0688],\n        [ 0.0306,  0.1046,  0.0588,  ..., -0.0184,  0.0628,  0.0173],\n        [-0.0387,  0.0161,  0.0310,  ...,  0.0041, -0.0403,  0.1448],\n        ...,\n        [ 0.1012,  0.0772, -0.0381,  ...,  0.0774, -0.0602,  0.1028],\n        [ 0.0479,  0.0872, -0.0224,  ...,  0.0533,  0.0131, -0.0119],\n        [-0.0227, -0.0977,  0.0077,  ..., -0.0933, -0.0940, -0.0609]]), 'meta_learner.transductive_net.self_attention.in_proj_bias': tensor([-1.1562e-03,  3.5078e-03,  1.3253e-03, -1.2615e-03,  7.0440e-04,\n         2.8362e-03,  8.6855e-03,  2.6343e-03,  3.8536e-03,  2.4695e-03,\n        -6.5583e-03,  4.6688e-03, -1.1405e-02,  2.1584e-03, -6.8477e-03,\n         3.6017e-03,  4.8106e-03,  6.6648e-03, -5.1730e-03,  3.3064e-03,\n        -1.2744e-03,  2.3605e-03, -4.6488e-03,  1.1839e-02,  4.8311e-04,\n        -5.6314e-03,  1.5613e-03,  6.6333e-05, -5.3246e-04,  1.1591e-03,\n         6.6879e-03, -6.3202e-03, -2.3554e-03, -1.6174e-02, -1.6169e-03,\n         9.2600e-03, -1.1288e-02, -2.0698e-03, -5.2251e-03,  9.0427e-04,\n         9.6303e-03,  5.2808e-03, -4.1782e-03, -3.3476e-03, -3.3498e-03,\n        -3.0270e-03,  7.7601e-03,  7.6998e-03, -5.5849e-03,  5.5030e-03,\n        -7.2709e-03, -2.9704e-03,  8.7765e-03,  1.1847e-02, -1.2350e-03,\n        -5.0149e-04, -7.6741e-04, -7.6585e-04,  1.7711e-03,  6.8790e-03,\n        -7.6785e-04,  7.8814e-04,  8.1912e-04, -3.1769e-03, -8.2980e-05,\n        -4.4689e-06,  3.9140e-05,  3.8446e-05,  5.0527e-05, -2.8855e-05,\n        -4.8385e-06, -2.0087e-05, -4.4081e-05,  3.5256e-06, -8.6682e-05,\n         5.6053e-05,  6.5652e-06, -9.1954e-05, -4.8765e-05,  4.8229e-05,\n        -6.1502e-05,  8.2352e-06, -1.1891e-04,  7.7645e-05,  4.3255e-05,\n         4.3661e-05,  2.4103e-05,  3.9168e-05, -1.2245e-04, -3.7115e-07,\n         9.3724e-07,  1.2713e-05,  5.6368e-05, -1.1357e-04, -6.0919e-05,\n         6.7399e-05,  4.6435e-05, -5.3294e-06, -3.6179e-05, -6.2068e-05,\n         2.8360e-05, -1.4742e-05,  3.5417e-05, -2.4926e-05,  5.3898e-06,\n        -5.1627e-06, -4.4958e-05,  1.3498e-05, -2.0301e-05, -1.1923e-05,\n         6.7074e-05,  2.3688e-05, -1.2027e-05, -4.7456e-05, -7.2702e-05,\n         1.8228e-05, -7.1358e-05, -4.9848e-05, -1.5583e-05, -8.1617e-05,\n         3.7333e-06, -1.0487e-04, -6.2268e-05,  2.2339e-06,  2.0748e-05,\n        -4.0908e-06, -8.4074e-05,  3.9116e-06, -4.8311e-04, -5.5132e-04,\n         4.4480e-04, -3.4783e-04,  3.6389e-04,  3.0323e-04,  1.9459e-04,\n         3.3131e-04,  4.7402e-04, -3.7429e-04, -4.1370e-04, -2.8391e-05,\n         1.1174e-04,  8.5970e-05,  6.3096e-05, -4.1209e-04,  4.8946e-04,\n         6.5605e-06,  5.4787e-05, -1.8626e-04,  4.0967e-04,  9.2430e-05,\n         2.9909e-04, -1.6076e-06,  1.8146e-04, -2.5339e-04, -1.0628e-04,\n        -6.1144e-04, -5.9648e-04, -4.7969e-04, -2.8128e-04, -3.3048e-04,\n         3.4259e-04, -3.8028e-04, -3.1713e-04, -5.5504e-04,  1.6013e-04,\n         2.4498e-04,  6.3882e-04, -3.1202e-04,  7.2969e-06, -2.2234e-06,\n        -5.2322e-04,  7.3575e-05, -3.5791e-04,  5.0997e-05, -3.5995e-04,\n         2.0480e-04,  4.8553e-04,  6.0139e-04, -1.5049e-04, -9.3336e-05,\n        -2.7317e-05,  4.8878e-04,  4.0204e-04, -2.5595e-04, -2.2897e-04,\n        -1.6454e-04, -4.0149e-04, -1.9673e-04, -1.1957e-03,  3.3849e-04,\n         1.8905e-04,  1.0242e-04]), 'meta_learner.transductive_net.self_attention.out_proj.weight': tensor([[ 0.0123,  0.0883, -0.1167,  ..., -0.0120,  0.0345, -0.0342],\n        [ 0.1126, -0.0863,  0.0845,  ..., -0.0971, -0.0787, -0.0598],\n        [-0.0377, -0.0910, -0.0342,  ..., -0.0431, -0.0156, -0.0286],\n        ...,\n        [ 0.0761, -0.0720,  0.0129,  ..., -0.0877, -0.0145,  0.0837],\n        [ 0.1102,  0.0562,  0.0839,  ..., -0.0112,  0.0456,  0.0194],\n        [-0.0836, -0.0568, -0.1035,  ..., -0.0567, -0.1196, -0.1143]]), 'meta_learner.transductive_net.self_attention.out_proj.bias': tensor([-2.9658e-04, -2.6879e-04, -3.8359e-05, -3.0066e-05, -6.2236e-04,\n         4.9830e-04, -1.9914e-04, -3.2174e-04, -2.6220e-04,  3.8388e-04,\n         2.7225e-04, -1.3356e-04, -2.5073e-04, -1.9961e-05,  7.0383e-05,\n         2.7601e-05,  2.4378e-04,  8.8378e-05, -3.8025e-05, -3.7103e-04,\n        -1.5210e-04,  5.2375e-04, -2.2820e-04,  3.0015e-04, -3.8177e-04,\n         4.4867e-04, -7.5917e-04, -3.5274e-04, -2.9401e-04, -3.5310e-04,\n        -4.0059e-04, -1.6158e-04,  6.0927e-04,  1.0662e-04,  1.3858e-04,\n         7.3086e-04, -2.9690e-04,  4.9037e-04,  1.2388e-05,  1.0993e-05,\n        -2.2484e-04, -5.9746e-04, -7.3533e-04, -1.2025e-05, -8.4132e-05,\n        -5.5144e-04, -2.2203e-04,  2.4039e-05,  1.0204e-04,  1.9817e-04,\n        -2.4656e-04,  7.1510e-05,  3.5888e-04,  2.5635e-05, -1.7648e-04,\n        -3.5292e-04, -4.5898e-04, -6.7146e-05,  3.7039e-05, -2.0149e-04,\n        -1.0861e-04,  1.3166e-04,  6.7320e-04,  3.7263e-04]), 'meta_learner.transductive_net.layer_norm.weight': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'meta_learner.transductive_net.layer_norm.bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}, sample_count=89041, training_loss=np.float64(0.1438493335992098), validation_accuracy=np.float64(0.6760000026226043), validation_precision=0.0, validation_recall=0.0, validation_f1_score=0.0, timestamp=1760230542.283713, model_hash='b5285f93e483401ddf50e2fa45c26ab0f78b1aefbb2dd24c89313c220c039f14', ipfs_cid='QmbDpyjsBjTBSwfFyyTUVxHm76G8AzsamCi4iU9GPx5HW8', blockchain_tx_hash='edb4e7528b41b164a1bdaccfe25e01c19987590660b0e1491ee70b8c779c2ac9')",
        "ClientUpdate(client_id='client_3', model_parameters={'meta_learner.transductive_net.feature_extractors.0.0.weight': tensor([[ 0.0490,  0.0649, -0.0628,  ...,  0.0148,  0.0400, -0.0662],\n        [ 0.0764,  0.1022, -0.0780,  ..., -0.0140, -0.0599,  0.0741],\n        [-0.0009, -0.0964, -0.0381,  ...,  0.0843,  0.0540,  0.0169],\n        ...,\n        [ 0.0702,  0.0357,  0.0820,  ..., -0.0528, -0.0475,  0.1268],\n        [-0.0033,  0.1124, -0.0134,  ..., -0.0773, -0.0473, -0.1171],\n        [-0.0050, -0.1324, -0.0074,  ..., -0.0156,  0.0382,  0.0475]]), 'meta_learner.transductive_net.feature_extractors.0.0.bias': tensor([-0.0829, -0.0857,  0.0654,  0.0029,  0.0605, -0.0833, -0.0168, -0.0788,\n        -0.0275, -0.0587, -0.1167, -0.0439,  0.0112, -0.0965,  0.0606,  0.0367,\n        -0.0692,  0.0044,  0.1059, -0.1008,  0.0888,  0.0494,  0.0606,  0.0750,\n        -0.0343, -0.0691, -0.1188, -0.0574,  0.1104,  0.0109,  0.0590,  0.0371,\n        -0.0100, -0.0382,  0.0422, -0.0193, -0.1007,  0.0094,  0.1106,  0.0598,\n        -0.0910, -0.0907, -0.0817, -0.0393, -0.1104, -0.0184, -0.0115, -0.0582,\n        -0.0768, -0.0084, -0.0755,  0.0250, -0.0587,  0.0458, -0.0764, -0.0627,\n         0.0705,  0.0298,  0.0874,  0.0414,  0.0684, -0.0082,  0.0743,  0.1129,\n        -0.0857, -0.0872,  0.0460, -0.0286, -0.0894, -0.0585, -0.0875,  0.1006,\n         0.0251, -0.0039,  0.0013,  0.0647, -0.1260,  0.0333,  0.0066, -0.1037,\n        -0.1058,  0.0843, -0.0711,  0.0979,  0.0678,  0.0838, -0.1134, -0.0584,\n         0.1237,  0.0264,  0.0361, -0.0873,  0.0638, -0.1106,  0.1159, -0.0486,\n         0.0543, -0.0359, -0.0040, -0.1071,  0.0589, -0.1236, -0.0157,  0.0850,\n         0.0217, -0.0810,  0.0504,  0.0947, -0.0541, -0.0928,  0.0510,  0.0762,\n        -0.1089, -0.0698, -0.0116,  0.0860,  0.0701,  0.0295,  0.0099, -0.0805,\n        -0.0206,  0.0377,  0.0389,  0.1056,  0.0639,  0.0146,  0.0197, -0.1111]), 'meta_learner.transductive_net.feature_extractors.1.0.weight': tensor([[-0.0429, -0.0418, -0.0567,  ..., -0.0243,  0.0743, -0.0366],\n        [ 0.0476, -0.1088,  0.0236,  ..., -0.1109, -0.0218,  0.0064],\n        [-0.1218, -0.1013, -0.0936,  ..., -0.1132, -0.0058, -0.0148],\n        ...,\n        [ 0.0324,  0.0070,  0.0255,  ..., -0.0712,  0.0525,  0.0844],\n        [ 0.0521,  0.0042, -0.1223,  ..., -0.1057,  0.0033,  0.0364],\n        [ 0.0556, -0.0843, -0.0997,  ..., -0.0522, -0.0972, -0.0819]]), 'meta_learner.transductive_net.feature_extractors.1.0.bias': tensor([ 0.0547,  0.0688,  0.1062,  0.0412, -0.0279,  0.0101, -0.0561, -0.0684,\n        -0.0262,  0.0267,  0.0303,  0.1275,  0.0662, -0.1150, -0.1247, -0.0354,\n         0.1244,  0.0155, -0.0471,  0.1123, -0.0338, -0.1307, -0.0709,  0.0764,\n         0.0571,  0.0583, -0.0743,  0.1060, -0.0984,  0.0430,  0.0740, -0.0726,\n        -0.0129,  0.0929,  0.0684,  0.0663, -0.0540,  0.0614,  0.1143,  0.0804,\n         0.0161,  0.0210, -0.0657,  0.0958, -0.1368,  0.0756,  0.0003, -0.0700,\n        -0.1030, -0.0811, -0.0825,  0.0572, -0.0246,  0.0486, -0.0580, -0.0630,\n        -0.0626, -0.1099,  0.0172, -0.0943,  0.1103, -0.0226,  0.1098, -0.1037]), 'meta_learner.transductive_net.feature_extractors.2.0.weight': tensor([[-0.0761,  0.1300,  0.0841,  ...,  0.0069,  0.0200,  0.0295],\n        [ 0.0455,  0.0532,  0.0227,  ...,  0.0217,  0.0131,  0.0942],\n        [-0.1079, -0.0326, -0.1288,  ...,  0.0630,  0.0374, -0.1147],\n        ...,\n        [-0.0956, -0.0283, -0.0254,  ..., -0.0342,  0.0266,  0.0053],\n        [ 0.0300,  0.1142,  0.0283,  ..., -0.0794, -0.1363, -0.1060],\n        [ 0.0046, -0.0735, -0.0242,  ...,  0.0798,  0.0140, -0.0129]]), 'meta_learner.transductive_net.feature_extractors.2.0.bias': tensor([ 2.5571e-02,  1.8761e-02, -8.5268e-02, -1.1559e-01,  4.7784e-02,\n         4.4179e-02,  9.9557e-02, -8.9576e-02, -1.0601e-02, -2.1756e-02,\n        -3.1913e-02, -3.6043e-03,  1.0094e-02, -5.1944e-02,  1.0605e-01,\n        -2.6927e-02, -2.0452e-03, -1.3265e-01, -2.8387e-02,  7.9203e-02,\n         7.9090e-02,  8.9377e-02, -9.2493e-02,  2.8937e-02, -5.9347e-02,\n         4.5965e-02, -6.2510e-02, -1.0525e-02, -5.9657e-02,  2.0054e-02,\n         1.1314e-01, -6.6703e-02,  9.0684e-02,  2.1616e-02,  1.2015e-01,\n         1.6270e-02,  1.0212e-01,  6.1203e-03, -5.5843e-02,  5.8239e-02,\n        -1.0685e-01,  9.5406e-02,  2.5784e-02,  3.7879e-03,  1.2116e-01,\n         9.2227e-02, -2.3542e-02,  7.1868e-02, -1.0165e-02,  6.1754e-03,\n        -7.3511e-02,  2.3980e-02, -8.2940e-02,  8.3796e-02, -2.0029e-02,\n         1.2355e-01,  1.1522e-01,  7.1377e-02, -5.7357e-02,  7.7778e-02,\n         7.1140e-02, -8.5176e-02,  2.9238e-02,  1.2617e-01, -1.2195e-01,\n         3.7962e-02,  1.2066e-01, -9.0534e-02, -9.4365e-02,  1.0804e-01,\n         1.1184e-01,  3.7767e-02,  1.0474e-01, -8.6769e-02, -1.6454e-02,\n         6.8122e-02, -1.7982e-03, -1.9396e-02, -1.1012e-01,  4.1026e-02,\n         1.1880e-01,  7.9785e-02, -9.3539e-02, -1.3510e-02,  6.9315e-02,\n        -1.6294e-02,  2.2712e-02,  2.0967e-02,  4.7028e-02, -4.3475e-04,\n         5.5870e-02, -7.0186e-02,  1.0504e-01, -4.2433e-02,  1.2048e-01,\n         1.0620e-01,  3.1483e-02, -3.0627e-02,  8.3853e-02, -8.3802e-02,\n         9.4391e-02, -6.2703e-02,  1.1463e-01, -5.8583e-02, -3.6954e-02,\n         2.8439e-02, -5.4862e-02,  7.8848e-02, -2.1291e-02, -1.1086e-01,\n        -1.2104e-01, -4.4351e-02, -7.1570e-02,  1.0207e-01,  9.6604e-02,\n         5.3973e-02,  1.3085e-01, -5.2709e-02,  1.2681e-02, -1.1887e-01,\n         7.3581e-02,  7.2823e-02,  7.8662e-02,  4.3017e-04, -3.5576e-02,\n        -3.5234e-02, -1.1649e-01, -4.6313e-02,  2.9636e-02, -1.4539e-02,\n         5.2713e-02, -6.0987e-03, -4.6499e-02,  5.0809e-02,  6.0623e-02,\n        -1.2982e-01,  9.7878e-03, -1.2028e-02,  3.7793e-02, -3.9502e-02,\n         8.7917e-03, -1.1578e-01, -2.8044e-02, -7.1414e-03, -1.0266e-01,\n         3.9040e-03,  8.2369e-02, -1.6885e-02,  1.1925e-01,  1.1615e-01,\n         7.6983e-02,  1.2016e-02,  1.0578e-01,  8.2493e-02,  5.2142e-02,\n        -1.3081e-01,  1.1374e-01, -1.1023e-01, -2.1145e-02,  4.5418e-02,\n         1.8333e-02, -1.6159e-03, -1.3890e-01,  3.3814e-02,  9.9916e-02,\n        -1.1788e-01, -9.1717e-02, -5.8881e-02,  9.0839e-02,  3.8839e-02,\n        -7.5119e-02, -1.2984e-01,  6.7646e-02,  7.2990e-02,  3.5880e-02,\n        -2.1287e-03,  4.3196e-02,  5.8950e-02, -5.0029e-03,  9.3585e-02,\n         6.9148e-02, -8.0684e-02, -6.8739e-02,  1.0584e-01,  2.6139e-02,\n        -3.5627e-02,  9.2167e-02, -1.2098e-01, -8.5667e-02, -1.1619e-01,\n        -1.2802e-01,  3.6004e-03, -4.2791e-02,  7.8188e-02,  7.7903e-02,\n         7.3358e-02,  1.0584e-02,  1.1512e-01, -1.3375e-02, -7.1513e-02,\n        -3.1279e-02,  7.2613e-02, -4.7593e-02,  1.8887e-02,  5.6308e-02,\n        -3.7794e-02,  3.2584e-03, -8.5331e-02,  2.6697e-02,  1.2759e-01,\n         2.7402e-02, -4.2804e-02,  1.1463e-01, -1.1348e-01, -4.3063e-02,\n         6.4331e-02, -3.9343e-03, -1.2479e-01,  3.8317e-05,  7.2496e-03,\n         6.4932e-02,  1.0752e-01, -1.3361e-02,  5.5775e-03,  1.0687e-01,\n        -1.0654e-01,  1.0989e-01, -6.9402e-02, -9.8688e-02,  3.6652e-02,\n         5.8461e-04, -1.1306e-01, -3.4709e-02,  8.1979e-02,  1.0752e-01,\n        -9.3130e-02, -1.0133e-01,  1.2767e-01, -2.0966e-02, -1.4252e-02,\n         7.8156e-02, -1.0842e-01, -1.5853e-02, -9.5429e-02, -5.4344e-02,\n         1.1313e-01,  2.7977e-02,  3.4287e-02, -3.6412e-02, -9.5525e-02,\n        -1.0296e-01, -7.9427e-02,  1.0385e-01,  5.5083e-02,  1.5958e-02,\n         7.3447e-02]), 'meta_learner.transductive_net.feature_projection.0.weight': tensor([[ 0.0178,  0.0132,  0.0086,  ..., -0.0438,  0.0344, -0.0225],\n        [ 0.0365,  0.0518,  0.0120,  ..., -0.0057, -0.0352, -0.0293],\n        [-0.0067,  0.0075,  0.0240,  ...,  0.0190,  0.0397, -0.0294],\n        ...,\n        [ 0.0430, -0.0389, -0.0215,  ...,  0.0339,  0.0345,  0.0186],\n        [-0.0135, -0.0190, -0.0074,  ..., -0.0012, -0.0372, -0.0451],\n        [ 0.0254, -0.0438, -0.0059,  ...,  0.0316, -0.0241,  0.0110]]), 'meta_learner.transductive_net.feature_projection.0.bias': tensor([ 0.0132, -0.0320, -0.0135, -0.0129,  0.0017,  0.0073, -0.0495,  0.0005,\n        -0.0011,  0.0275, -0.0223, -0.0364,  0.0128, -0.0550,  0.0012,  0.0439,\n        -0.0278,  0.0443, -0.0021,  0.0176,  0.0103,  0.0075, -0.0360, -0.0057,\n        -0.0248, -0.0032,  0.0473, -0.0310,  0.0453, -0.0130, -0.0348,  0.0149,\n         0.0033, -0.0145, -0.0304,  0.0344, -0.0234,  0.0129,  0.0405,  0.0419,\n         0.0116, -0.0117,  0.0433, -0.0367,  0.0001, -0.0222, -0.0004, -0.0377,\n        -0.0182, -0.0278,  0.0055, -0.0565,  0.0217, -0.0068, -0.0155,  0.0344,\n         0.0117, -0.0138, -0.0193, -0.0557,  0.0096,  0.0497,  0.0044, -0.0462]), 'meta_learner.transductive_net.classifier.0.weight': tensor([[ 0.0717, -0.0804,  0.0465,  ..., -0.0225,  0.0733,  0.0837],\n        [-0.0651, -0.0565,  0.0410,  ..., -0.0781, -0.1016, -0.0100],\n        [-0.1076,  0.0647,  0.0747,  ...,  0.0049, -0.0335, -0.1130],\n        ...,\n        [-0.1147,  0.0261, -0.1212,  ..., -0.0713, -0.1189,  0.0434],\n        [ 0.0031, -0.0050,  0.0960,  ...,  0.0906, -0.0885,  0.0328],\n        [-0.0457, -0.0833, -0.1142,  ..., -0.0711, -0.1097,  0.0251]]), 'meta_learner.transductive_net.classifier.0.bias': tensor([ 0.0238, -0.0064,  0.1070, -0.0295,  0.0291, -0.0182,  0.0019,  0.0263,\n        -0.0815,  0.0424,  0.0183,  0.0328, -0.0971,  0.1128, -0.0815, -0.1221,\n         0.0405,  0.0482,  0.1096, -0.0868,  0.0017,  0.0079,  0.0842,  0.0309,\n        -0.0947,  0.1216, -0.0554, -0.0919, -0.0366,  0.0273,  0.0405, -0.0070,\n         0.1236, -0.0978, -0.0574,  0.0134, -0.1068, -0.0940,  0.0867,  0.0952,\n         0.0572, -0.0494,  0.0244, -0.1016,  0.0124, -0.1166, -0.0232, -0.1090,\n         0.0415,  0.0695,  0.0357,  0.0921,  0.0827, -0.0747, -0.0100,  0.0852,\n         0.0728,  0.1053,  0.0468,  0.0556,  0.0617,  0.0686, -0.0294, -0.0296]), 'meta_learner.transductive_net.classifier.3.weight': tensor([[-4.6429e-02,  1.0003e-01,  1.9178e-05,  ...,  6.1526e-02,\n          6.1236e-02,  6.9374e-02],\n        [ 3.8632e-02,  8.2375e-02,  3.3821e-02,  ...,  1.1482e-01,\n          9.9284e-03,  7.9468e-02],\n        [ 2.7745e-02, -9.0051e-03, -2.8994e-02,  ...,  8.7031e-02,\n         -4.2891e-02, -5.4357e-02],\n        ...,\n        [-3.1249e-02,  1.2378e-01, -5.0974e-02,  ..., -3.0723e-02,\n          8.4047e-02,  4.9875e-02],\n        [-3.8756e-02, -1.0168e-01,  1.8436e-02,  ...,  5.5887e-03,\n         -1.0875e-03, -9.9167e-05],\n        [ 1.1189e-01,  1.2428e-01,  4.1206e-02,  ...,  3.1893e-02,\n          3.3560e-02,  1.0983e-01]]), 'meta_learner.transductive_net.classifier.3.bias': tensor([-0.1046,  0.0883,  0.0814, -0.0237,  0.0236, -0.0928, -0.0143,  0.0730,\n         0.0767,  0.0694,  0.0180,  0.0803, -0.0463, -0.0667, -0.0257,  0.0963,\n         0.0669,  0.0086, -0.0753,  0.0643, -0.0542,  0.0117, -0.0064, -0.0365,\n        -0.0885,  0.0064,  0.0590, -0.0888, -0.0935,  0.0537, -0.0983,  0.0029]), 'meta_learner.transductive_net.classifier.6.weight': tensor([[-0.0446, -0.0506,  0.1760, -0.0712, -0.1167,  0.1742, -0.0514, -0.1187,\n          0.0647, -0.0336, -0.1118,  0.1458,  0.0586, -0.0199, -0.1588,  0.1473,\n         -0.1061,  0.1672, -0.1626, -0.0116,  0.0493,  0.1262,  0.1219,  0.0069,\n          0.1500, -0.0579, -0.0195, -0.1544,  0.1074, -0.1345,  0.0002, -0.1222],\n        [ 0.1432,  0.1606, -0.0237,  0.1192,  0.1584,  0.0441,  0.1487,  0.0045,\n          0.0715,  0.1482, -0.1194,  0.1631, -0.1762,  0.0043, -0.1497, -0.0594,\n         -0.1368,  0.1553,  0.0912,  0.0618, -0.0717, -0.1578,  0.1408,  0.0899,\n         -0.0392, -0.0742,  0.0106, -0.0593, -0.1116, -0.1296,  0.1618, -0.1333]]), 'meta_learner.transductive_net.classifier.6.bias': tensor([-0.1458,  0.0698]), 'meta_learner.transductive_net.self_attention.in_proj_weight': tensor([[ 0.1409, -0.1041, -0.0719,  ..., -0.1002,  0.0135, -0.0889],\n        [ 0.0454,  0.1147,  0.0807,  ..., -0.0238,  0.0545,  0.0320],\n        [-0.0530,  0.0238,  0.0221,  ..., -0.0033, -0.0277,  0.1484],\n        ...,\n        [ 0.1068,  0.0653, -0.0168,  ...,  0.0787, -0.0536,  0.1061],\n        [ 0.0449,  0.0885, -0.0273,  ...,  0.0502,  0.0094, -0.0257],\n        [-0.0310, -0.0911, -0.0017,  ..., -0.0935, -0.0935, -0.0819]]), 'meta_learner.transductive_net.self_attention.in_proj_bias': tensor([-1.7272e-03,  5.4210e-03, -6.0978e-03,  1.8490e-03,  2.4052e-03,\n         6.8082e-04,  4.9275e-03,  5.8308e-03, -6.4280e-04,  3.9026e-03,\n         9.0125e-03,  4.2045e-03, -8.1568e-03,  5.1112e-03,  8.0064e-03,\n        -4.4933e-03,  5.4407e-03,  7.9759e-03,  1.1014e-03,  2.9219e-03,\n        -1.0864e-03, -1.0041e-02,  5.5015e-03, -3.2257e-04, -3.9027e-03,\n        -3.7194e-03, -4.1887e-04,  1.9492e-03, -1.1532e-02,  6.0740e-03,\n         1.0468e-02, -4.9295e-03,  1.7172e-03, -7.9810e-03, -1.1080e-03,\n         4.7485e-03, -5.8108e-03,  4.9921e-03,  5.8819e-03,  1.2142e-03,\n         6.5470e-03, -6.5509e-03,  6.8529e-03, -3.9566e-03,  4.6494e-03,\n         6.4361e-03,  4.2742e-04,  2.5803e-03, -1.8622e-03,  5.0251e-03,\n        -9.6430e-03, -2.2401e-03,  8.1372e-03,  1.4705e-03, -3.3729e-03,\n         8.3920e-03, -5.3418e-04,  3.2123e-03, -2.2278e-03,  4.3775e-03,\n        -4.4083e-03, -2.2879e-03,  3.6172e-03,  5.1333e-03,  2.1824e-05,\n         5.5991e-05, -1.1406e-04,  4.0229e-05, -5.7957e-05, -6.2384e-05,\n        -1.7239e-04,  4.2761e-05, -8.1875e-05, -9.4569e-05,  3.8828e-05,\n        -4.0352e-05, -1.1834e-04, -6.6281e-05, -3.1266e-06, -1.2759e-04,\n         7.0869e-06, -5.2246e-05, -1.1307e-05,  6.0690e-05, -1.4687e-05,\n         1.2195e-04, -7.8181e-05,  1.6663e-05,  6.0792e-05, -2.5749e-05,\n        -9.7035e-05,  1.3763e-05,  1.1471e-05,  4.8751e-06, -4.3603e-05,\n         3.0937e-06, -2.2990e-05,  5.5825e-05, -1.3737e-05,  2.2222e-06,\n        -3.8882e-05,  3.9443e-05,  7.8088e-05, -6.1084e-05, -7.1690e-05,\n        -2.5201e-05,  2.6886e-05, -9.9808e-06, -4.6232e-05, -8.7123e-05,\n         6.2815e-05,  3.9341e-05, -4.0368e-05,  4.6259e-05, -7.3801e-05,\n        -7.4562e-05, -2.7646e-05, -4.0429e-05, -3.9225e-06, -6.8729e-05,\n         5.1958e-05,  3.8469e-05,  8.8291e-06,  2.4475e-05,  6.6471e-05,\n         1.5802e-05, -7.8701e-05,  8.9601e-05, -1.9049e-04,  2.6480e-04,\n        -2.9860e-04,  1.1794e-04,  5.4723e-04,  4.9255e-04, -4.4696e-04,\n         5.4509e-04, -3.3119e-04, -1.5181e-04, -8.8739e-05,  2.1072e-04,\n        -2.3313e-04, -5.0958e-04, -1.6873e-04, -3.5494e-04,  7.4543e-04,\n        -1.3719e-04, -2.8564e-04,  1.3583e-04, -1.2068e-04,  3.3839e-04,\n         9.0425e-04, -4.2593e-04,  7.1012e-04,  5.1854e-04,  1.9385e-05,\n         1.0700e-03, -2.8841e-04,  7.7539e-04, -4.0321e-04,  6.0796e-04,\n        -5.1620e-04,  1.7799e-04, -3.6407e-04, -2.0856e-04,  8.4267e-04,\n         2.2170e-04, -5.3849e-04, -1.1637e-04, -4.9082e-04,  4.2361e-04,\n        -2.7523e-04, -8.3360e-05, -2.2402e-04,  5.0964e-05, -1.7677e-04,\n         2.6891e-04, -2.6233e-04,  7.7315e-04, -9.7306e-04,  2.4784e-04,\n         8.2664e-04, -1.4190e-04, -8.9688e-04,  1.4240e-05,  2.0631e-04,\n        -1.0767e-04, -7.0910e-05, -1.8981e-04,  1.2213e-04,  3.8059e-05,\n         3.6551e-04, -2.1062e-04]), 'meta_learner.transductive_net.self_attention.out_proj.weight': tensor([[ 0.0141,  0.1057, -0.1250,  ..., -0.0205,  0.0274, -0.0336],\n        [ 0.1140, -0.0796,  0.0714,  ..., -0.0906, -0.0974, -0.0655],\n        [-0.0311, -0.1014, -0.0281,  ..., -0.0353, -0.0107, -0.0438],\n        ...,\n        [ 0.0738, -0.0895,  0.0232,  ..., -0.0839, -0.0095,  0.0866],\n        [ 0.1042,  0.0386,  0.0759,  ..., -0.0129,  0.0441,  0.0183],\n        [-0.0887, -0.0503, -0.1027,  ..., -0.0606, -0.1239, -0.1136]]), 'meta_learner.transductive_net.self_attention.out_proj.bias': tensor([-3.7996e-04, -1.6354e-04,  4.0432e-05,  3.8638e-04,  2.4304e-04,\n         1.6053e-04, -1.4670e-04,  5.8858e-04,  3.0452e-04, -2.3681e-04,\n        -1.0819e-04, -2.7069e-04,  2.5758e-04, -3.1039e-04,  4.7680e-04,\n         4.7831e-05,  3.9648e-04,  1.2968e-04,  5.2038e-05,  3.4761e-04,\n        -1.0808e-04, -9.2425e-04, -5.9772e-04,  6.6271e-04, -1.5410e-04,\n         3.9456e-05,  2.7572e-04, -1.0844e-03,  3.3303e-05,  8.9126e-05,\n        -1.3233e-04, -1.4244e-04,  2.2075e-05,  2.4203e-04, -9.3341e-04,\n        -6.0307e-05,  3.3991e-05, -2.0892e-04, -2.9031e-04, -1.4326e-04,\n         3.3713e-05, -6.0334e-04, -1.1943e-04, -1.3742e-04,  2.3269e-04,\n        -7.4048e-06,  1.9838e-04,  3.3283e-04, -6.5773e-05,  2.8508e-04,\n        -1.8565e-04, -2.5017e-04,  3.8693e-05,  6.6535e-04,  1.1136e-05,\n         8.3063e-04, -1.0057e-03,  3.5374e-04,  1.5970e-04,  6.0602e-04,\n         3.8070e-04,  2.2545e-05,  3.4049e-04, -5.0620e-04]), 'meta_learner.transductive_net.layer_norm.weight': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'meta_learner.transductive_net.layer_norm.bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}, sample_count=7034, training_loss=np.float64(0.12761220966640394), validation_accuracy=np.float64(0.720000011920929), validation_precision=0.0, validation_recall=0.0, validation_f1_score=0.0, timestamp=1760230545.6402886, model_hash='aba23f29d65ae8e224ae10df2f93acfbc0b5e5e86f1bd054c5c36c4061cc351f', ipfs_cid='QmTJYK8dMpkE4TxzRcy9CY5Tf1Wmgqy1j8kTch1KLHM4Nx', blockchain_tx_hash='71a06e529c3287dd1597f8d996da2463ffae0c43713e6b4760e20f2a1af3c403')"
      ],
      "aggregation_result": "AggregationResult(round_number=0, aggregated_parameters={}, client_contributions={'client_1': 0.3594914598861318, 'client_2': 0.5936145815277537, 'client_3': 0.04689395858611448}, aggregation_time=0.0010008811950683594, model_hash='model_round_0_1760230554', ipfs_cid='QmatD47MNGnTLTt9reUfzR8Z2FFbaZtRTHuZTKvMRcw6Sm', blockchain_tx_hash='208189d747157e5a81705f41293a11329969f81453a7db2ba75748d3f4a56b85')",
      "timestamp": 1760230558.1427915
    }
  ],
  "incentive_history": [
    {
      "round_number": 1,
      "total_rewards": 100.0,
      "individual_rewards": {
        "client_1": 33.8811101314246,
        "client_2": 32.413850772113065,
        "client_3": 33.70503909646232
      },
      "contribution_scores": {
        "client_1": 0.8082000068426132,
        "client_2": 0.7732000018358229,
        "client_3": 0.8040000083446504
      },
      "timestamp": 1760230558.1437912
    }
  ],
  "client_addresses": {},
  "config": {
    "data_path": "../DNN-EdgeIIoT-dataset.csv",
    "zero_day_attack": "SQL_injection",
    "available_attacks": [
      "DDoS_UDP",
      "DDoS_ICMP",
      "SQL_injection",
      "Password",
      "Vulnerability_scanner",
      "DDoS_TCP",
      "DDoS_HTTP",
      "Uploading",
      "Backdoor",
      "Port_Scanning",
      "XSS",
      "Ransomware",
      "MITM",
      "Fingerprinting"
    ],
    "input_dim": 62,
    "hidden_dim": 128,
    "embedding_dim": 64,
    "use_fully_decentralized": false,
    "support_weight": 0.3,
    "test_weight": 0.7,
    "n_way": 2,
    "k_shot": 5,
    "n_query": 15,
    "n_tasks": 10,
    "num_clients": 3,
    "num_rounds": 1,
    "learning_rate": 0.001,
    "ethereum_rpc_url": "http://localhost:8545",
    "contract_address": "0x1234567890123456789012345678901234567890",
    "ipfs_url": "http://localhost:5001",
    "enable_incentives": true,
    "incentive_contract_address": "0x1234567890123456789012345678901234567890",
    "private_key": "0x1234567890123456789012345678901234567890123456789012345678901234",
    "aggregator_address": "0x1234567890123456789012345678901234567890",
    "batch_size": 32,
    "ttt_steps": 200,
    "support_size": 50,
    "query_size": 450,
    "device": "cuda",
    "enable_blockchain": true,
    "max_samples_per_client": 50000,
    "use_data_sampling": true
  }
}