{
  "base_model": {
    "accuracy_mean": 0.5,
    "accuracy_std": 0.00012248673581272932,
    "macro_f1_mean": 0.33333334222400035,
    "macro_f1_std": 0.00013609637218145015,
    "mcc_mean": 0.0,
    "mcc_std": 0.0,
    "confusion_matrix": [
      [
        0,
        1667
      ],
      [
        0,
        1666
      ]
    ],
    "roc_curve": {
      "fpr": [
        0.0,
        0.0005998800239952009,
        0.17636472705458908,
        0.1775644871025795,
        0.19916016796640673,
        0.20035992801439712,
        0.2933413317336533,
        0.29454109178164367,
        0.3047390521895621,
        0.3059388122375525,
        0.370125974805039,
        0.3713257348530294,
        0.4289142171565687,
        0.4301139772045591,
        0.5350929814037193,
        0.5350929814037193,
        0.5356928614277144,
        0.5356928614277144,
        0.5392921415716857,
        0.5392921415716857,
        0.5518896220755849,
        0.5518896220755849,
        0.55248950209958,
        0.55248950209958,
        0.5530893821235753,
        0.5530893821235753,
        0.5548890221955609,
        0.5548890221955609,
        0.555488902219556,
        0.555488902219556,
        0.5560887822435513,
        0.5560887822435513,
        0.5566886622675465,
        0.5566886622675465,
        0.5578884223155369,
        0.5578884223155369,
        0.5584883023395321,
        0.5584883023395321,
        0.5590881823635273,
        0.5590881823635273,
        0.5596880623875224,
        0.5596880623875224,
        0.5602879424115177,
        0.5602879424115177,
        0.5608878224355129,
        0.5608878224355129,
        0.5614877024595081,
        0.5614877024595081,
        0.5614877024595081,
        0.5614877024595081,
        0.5620875824835033,
        0.5620875824835033,
        0.5626874625074985,
        0.5626874625074985,
        0.5626874625074985,
        0.5626874625074985,
        0.5626874625074985,
        0.5626874625074985,
        0.5626874625074985,
        0.5626874625074985,
        0.5626874625074985,
        0.5626874625074985,
        0.5626874625074985,
        0.5626874625074985,
        0.5626874625074985,
        0.5626874625074985,
        0.5626874625074985,
        0.5626874625074985,
        0.5626874625074985,
        0.5626874625074985,
        0.5626874625074985,
        0.5632873425314937,
        0.5632873425314937,
        0.5632873425314937,
        0.563887222555489,
        0.563887222555489,
        0.563887222555489,
        0.6496700659868027,
        0.650869826034793,
        0.7006598680263947,
        0.7018596280743852,
        0.7144571085782844,
        0.7156568686262748,
        0.8140371925614877,
        0.8152369526094781,
        0.8290341931613677,
        0.8314337132573485,
        0.904619076184763,
        0.904619076184763,
        0.9094181163767247,
        0.9094181163767247,
        0.9178164367126574,
        0.9178164367126574,
        0.9658068386322736,
        0.9658068386322736,
        0.9982003599280144,
        0.9982003599280144,
        0.9982003599280144,
        0.9982003599280144,
        0.9988002399520096,
        0.9988002399520096,
        0.9988002399520096,
        0.9988002399520096,
        0.9988002399520096,
        0.9988002399520096,
        0.9988002399520096,
        0.9988002399520096,
        0.9988002399520096,
        0.9988002399520096,
        0.9988002399520096,
        0.9988002399520096,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        0.9994001199760048,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0
      ],
      "tpr": [
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0006002400960384153,
        0.0006002400960384153,
        0.0012004801920768306,
        0.0012004801920768306,
        0.001800720288115246,
        0.001800720288115246,
        0.0024009603841536613,
        0.0024009603841536613,
        0.004801920768307323,
        0.004801920768307323,
        0.005402160864345739,
        0.005402160864345739,
        0.013805522208883553,
        0.013805522208883553,
        0.015006002400960384,
        0.015006002400960384,
        0.01800720288115246,
        0.01800720288115246,
        0.019807923169267706,
        0.019807923169267706,
        0.02040816326530612,
        0.02040816326530612,
        0.0234093637454982,
        0.0234093637454982,
        0.02460984393757503,
        0.02460984393757503,
        0.02701080432172869,
        0.02701080432172869,
        0.030012004801920768,
        0.030012004801920768,
        0.03361344537815126,
        0.03361344537815126,
        0.035414165666266505,
        0.036614645858343335,
        0.03721488595438175,
        0.037815126050420166,
        0.03961584633853541,
        0.03961584633853541,
        0.045018007202881155,
        0.046218487394957986,
        0.05702280912364946,
        0.058823529411764705,
        0.06182472989195678,
        0.06302521008403361,
        0.06422569027611044,
        0.06542617046818727,
        0.06782713085234093,
        0.0702280912364946,
        0.07142857142857142,
        0.07202881152460984,
        0.07382953181272509,
        0.07563025210084033,
        0.07683073229291716,
        0.07743097238895558,
        0.07923169267707082,
        0.07983193277310924,
        0.08043217286914765,
        0.0822328931572629,
        0.08283313325330131,
        0.08283313325330131,
        0.08403361344537816,
        0.08523409363745499,
        0.08523409363745499,
        0.08523409363745499,
        0.08523409363745499,
        0.08523409363745499,
        0.08523409363745499,
        0.08523409363745499,
        0.08523409363745499,
        0.08523409363745499,
        0.08523409363745499,
        0.08523409363745499,
        0.08523409363745499,
        0.08643457382953182,
        0.08643457382953182,
        0.08703481392557023,
        0.08703481392557023,
        0.08763505402160865,
        0.08763505402160865,
        0.08823529411764706,
        0.08823529411764706,
        0.0936374549819928,
        0.09483793517406963,
        0.10264105642256903,
        0.10264105642256903,
        0.10324129651860744,
        0.10444177671068428,
        0.10864345738295318,
        0.10984393757503001,
        0.11284513805522209,
        0.11404561824729892,
        0.11584633853541416,
        0.117046818727491,
        0.11884753901560624,
        0.12064825930372149,
        0.12364945978391356,
        0.12424969987995198,
        0.13025210084033614,
        0.1326530612244898,
        0.13445378151260504,
        0.1368547418967587,
        0.13865546218487396,
        0.13925570228091236,
        0.14645858343337334,
        0.1482593037214886,
        0.15066026410564226,
        0.1524609843937575,
        0.15366146458583432,
        0.15546218487394958,
        0.15786314525810324,
        0.15906362545018007,
        0.15966386554621848,
        0.16266506602641057,
        0.16326530612244897,
        0.16566626650660263,
        0.16806722689075632,
        0.16866746698679472,
        0.17046818727490998,
        0.1716686674669868,
        0.1752701080432173,
        0.17647058823529413,
        0.17827130852340936,
        0.18487394957983194,
        0.18667466986794717,
        0.187875150060024,
        0.1908763505402161,
        0.1914765906362545,
        0.19327731092436976,
        0.19387755102040816,
        0.1998799519807923,
        0.20048019207683074,
        0.2034813925570228,
        0.20588235294117646,
        0.20948379351740695,
        0.21248499399759904,
        0.2148859543817527,
        0.21788715486194477,
        0.2190876350540216,
        0.22268907563025211,
        0.22749099639855944,
        0.23109243697478993,
        0.234093637454982,
        0.23529411764705882,
        0.24009603841536614,
        0.2418967587034814,
        0.2503001200480192,
        0.25630252100840334,
        0.2635054021608643,
        0.2695078031212485,
        0.27310924369747897,
        0.2737094837935174,
        0.27611044417767105,
        0.28271308523409366,
        0.2851140456182473,
        0.2929171668667467,
        0.29591836734693877,
        0.3007202881152461,
        0.3037214885954382,
        0.3079231692677071,
        0.31452581032412963,
        0.31512605042016806,
        0.3199279711884754,
        0.3241296518607443,
        0.32713085234093636,
        0.33433373349339734,
        0.33613445378151263,
        0.34213685474189676,
        0.35114045618247297,
        0.3517406962785114,
        0.3577430972388956,
        0.3607442977190876,
        0.36494597839135656,
        0.37214885954381755,
        0.3787515006002401,
        0.3835534213685474,
        0.3895558223289316,
        0.3943577430972389,
        0.40036014405762305,
        0.4009603841536615,
        0.4057623049219688,
        0.4099639855942377,
        0.4255702280912365,
        0.43157262905162064,
        0.4399759903961585,
        0.44237695078031214,
        0.44837935174069626,
        0.453781512605042,
        0.4549819927971189,
        0.460984393757503,
        0.46278511404561823,
        0.468187274909964,
        0.4723889555822329,
        0.4843937575030012,
        0.48739495798319327,
        0.4909963985594238,
        0.4921968787515006,
        0.49879951980792314,
        0.5024009603841537,
        0.5048019207683073,
        0.5156062424969988,
        0.5162064825930373,
        0.5210084033613446,
        0.5252100840336135,
        0.5300120048019208,
        0.5330132052821128,
        0.5348139255702281,
        0.5402160864345739,
        0.5438175270108043,
        0.5480192076830732,
        0.5528211284513805,
        0.5540216086434574,
        0.5618247298919568,
        0.5630252100840336,
        0.5684273709483794,
        0.5714285714285714,
        0.578031212484994,
        0.5828331332533013,
        0.5882352941176471,
        0.5942376950780313,
        0.6008403361344538,
        0.6050420168067226,
        0.6116446578631453,
        0.6152460984393757,
        0.6158463385354142,
        0.6176470588235294,
        0.6206482593037215,
        0.6242496998799519,
        0.6302521008403361,
        0.6320528211284514,
        0.6398559423769508,
        0.6440576230492197,
        0.6500600240096038,
        0.6578631452581032,
        0.6608643457382953,
        0.6662665066026411,
        0.6698679471788715,
        0.6788715486194478,
        0.6824729891956782,
        0.6830732292917167,
        0.6974789915966386,
        0.7034813925570228,
        0.7040816326530612,
        0.7100840336134454,
        0.7130852340936374,
        0.7172869147659063,
        0.7184873949579832,
        0.7202881152460985,
        0.7226890756302521,
        0.7262905162064826,
        0.7304921968787516,
        0.7352941176470589,
        0.7388955582232893,
        0.7454981992797118,
        0.7472989195678271,
        0.7509003601440576,
        0.7545018007202882,
        0.7581032412965186,
        0.7611044417767107,
        0.7683073229291717,
        0.7713085234093637,
        0.7737094837935174,
        0.7779111644657863,
        0.7797118847539015,
        0.7821128451380552,
        0.7827130852340937,
        0.7845138055222088,
        0.7869147659063626,
        0.7893157262905162,
        0.790516206482593,
        0.7941176470588235,
        0.7947178871548619,
        0.7971188475390156,
        0.8001200480192077,
        0.8013205282112845,
        0.8025210084033614,
        0.8037214885954381,
        0.8085234093637454,
        0.8097238895558223,
        0.8127250900360145,
        0.8133253301320528,
        0.8181272509003601,
        0.8187274909963985,
        0.8217286914765907,
        0.8229291716686674,
        0.8235294117647058,
        0.8253301320528211,
        0.8277310924369747,
        0.8307322929171669,
        0.8319327731092437,
        0.8337334933973589,
        0.8367346938775511,
        0.8379351740696278,
        0.8391356542617047,
        0.84093637454982,
        0.8415366146458584,
        0.8451380552220888,
        0.8475390156062425,
        0.8481392557022809,
        0.8517406962785115,
        0.8523409363745498,
        0.8541416566626651,
        0.8559423769507803,
        0.8577430972388955,
        0.858343337334934,
        0.8607442977190877,
        0.8637454981992797,
        0.8649459783913566,
        0.865546218487395,
        0.8667466986794717,
        0.868547418967587,
        0.8709483793517407,
        0.8721488595438175,
        0.8733493397358943,
        0.8745498199279712,
        0.8763505402160864,
        0.8775510204081632,
        0.8793517406962785,
        0.882953181272509,
        0.8835534213685474,
        0.8853541416566627,
        0.885954381752701,
        0.8877551020408163,
        0.8925570228091236,
        0.8937575030012005,
        0.9087635054021609,
        0.9099639855942377,
        1.0
      ],
      "thresholds": [
        Infinity,
        0.5690987706184387,
        0.5646563172340393,
        0.5646476149559021,
        0.5645332336425781,
        0.5645321607589722,
        0.5641416311264038,
        0.564141571521759,
        0.564095139503479,
        0.5640884041786194,
        0.5637227296829224,
        0.5637174844741821,
        0.5633509159088135,
        0.5633497834205627,
        0.5628308057785034,
        0.562822699546814,
        0.562821090221405,
        0.5628193020820618,
        0.5627996325492859,
        0.5627983808517456,
        0.5627273917198181,
        0.5627232789993286,
        0.5627201199531555,
        0.5627135038375854,
        0.5627126097679138,
        0.5627084374427795,
        0.5627034306526184,
        0.5626620650291443,
        0.5626617670059204,
        0.5626609921455383,
        0.562658965587616,
        0.5626540184020996,
        0.5626538395881653,
        0.562651515007019,
        0.5626508593559265,
        0.5626504421234131,
        0.562648355960846,
        0.5626454949378967,
        0.5626451969146729,
        0.5626445412635803,
        0.5626441240310669,
        0.5626415014266968,
        0.5626411437988281,
        0.5626386404037476,
        0.562638521194458,
        0.562635600566864,
        0.5626355409622192,
        0.5626339912414551,
        0.5626334547996521,
        0.5626332759857178,
        0.5626327395439148,
        0.5626314282417297,
        0.5626312494277954,
        0.5626278519630432,
        0.5626274943351746,
        0.5626209378242493,
        0.5626207590103149,
        0.5626201629638672,
        0.5626201033592224,
        0.5626196265220642,
        0.562619149684906,
        0.5626183152198792,
        0.5626182556152344,
        0.5626177787780762,
        0.5626177191734314,
        0.5626175999641418,
        0.5626172423362732,
        0.5626171827316284,
        0.5626171231269836,
        0.5626170039176941,
        0.562616765499115,
        0.5626165270805359,
        0.5626164674758911,
        0.5626164078712463,
        0.5626158714294434,
        0.5626155734062195,
        0.5626150965690613,
        0.5620665550231934,
        0.5620653033256531,
        0.5615282654762268,
        0.5615260004997253,
        0.5614429712295532,
        0.5614399313926697,
        0.5610467195510864,
        0.5610464215278625,
        0.5609648823738098,
        0.5609604120254517,
        0.5599830150604248,
        0.559968113899231,
        0.5598430633544922,
        0.5598129630088806,
        0.5596088767051697,
        0.5596051216125488,
        0.5589106678962708,
        0.5589104890823364,
        0.5586113333702087,
        0.5585670471191406,
        0.5585669875144958,
        0.5585628151893616,
        0.5585625767707825,
        0.5585625171661377,
        0.5585624575614929,
        0.5585610866546631,
        0.5585609674453735,
        0.5585601925849915,
        0.5585599541664124,
        0.5585594773292542,
        0.5585594177246094,
        0.558559238910675,
        0.5585591793060303,
        0.5585588812828064,
        0.5585588216781616,
        0.558557391166687,
        0.5585572123527527,
        0.5585569143295288,
        0.5585567355155945,
        0.5585566163063049,
        0.5585565567016602,
        0.5585564374923706,
        0.558556318283081,
        0.5585561990737915,
        0.5585561394691467,
        0.5585560202598572,
        0.5585559606552124,
        0.5585559010505676,
        0.5585558414459229,
        0.5585557818412781,
        0.5585557222366333,
        0.5585556626319885,
        0.5585556030273438,
        0.5585554242134094,
        0.5585553646087646,
        0.5585553050041199,
        0.5585551857948303,
        0.5585551261901855,
        0.5585550665855408,
        0.558555006980896,
        0.5585549473762512,
        0.5585548877716064,
        0.5585548281669617,
        0.5585547685623169,
        0.5585547089576721,
        0.5585546493530273,
        0.5585545897483826,
        0.558554470539093,
        0.5585544109344482,
        0.5585543513298035,
        0.5585542917251587,
        0.5585542321205139,
        0.5585541725158691,
        0.5585541129112244,
        0.5585540533065796,
        0.5585539937019348,
        0.55855393409729,
        0.5585538744926453,
        0.5585538148880005,
        0.5585537552833557,
        0.5585536956787109,
        0.5585536360740662,
        0.5585535764694214,
        0.5585534572601318,
        0.5585533380508423,
        0.5585532784461975,
        0.5585532188415527,
        0.558553159236908,
        0.5585530996322632,
        0.5585530400276184,
        0.5585529804229736,
        0.5585529208183289,
        0.5585528612136841,
        0.5585528016090393,
        0.5585527420043945,
        0.5585526823997498,
        0.558552622795105,
        0.5585525631904602,
        0.5585525035858154,
        0.5585524439811707,
        0.5585523843765259,
        0.5585523247718811,
        0.5585522651672363,
        0.5585522055625916,
        0.5585521459579468,
        0.558552086353302,
        0.5585520267486572,
        0.5585519671440125,
        0.5585518479347229,
        0.5585517883300781,
        0.5585517287254333,
        0.5585516691207886,
        0.558551549911499,
        0.5585514903068542,
        0.5585514307022095,
        0.5585513710975647,
        0.5585513114929199,
        0.5585512518882751,
        0.5585511922836304,
        0.5585510730743408,
        0.5585509538650513,
        0.5585508942604065,
        0.5585508346557617,
        0.5585507750511169,
        0.5585507154464722,
        0.5585506558418274,
        0.5585505962371826,
        0.5585505366325378,
        0.5585504770278931,
        0.5585504174232483,
        0.558550238609314,
        0.5585501790046692,
        0.5585501194000244,
        0.5585500597953796,
        0.5585500001907349,
        0.5585499405860901,
        0.5585498809814453,
        0.5585498213768005,
        0.5585497617721558,
        0.558549702167511,
        0.5585496425628662,
        0.5585495829582214,
        0.5585495233535767,
        0.5585494637489319,
        0.5585494041442871,
        0.5585493445396423,
        0.5585492849349976,
        0.5585492253303528,
        0.558549165725708,
        0.5585491061210632,
        0.5585490465164185,
        0.5585489869117737,
        0.5585489273071289,
        0.5585488080978394,
        0.5585487484931946,
        0.5585486888885498,
        0.5585485696792603,
        0.5585485100746155,
        0.5585484504699707,
        0.5585483908653259,
        0.5585483312606812,
        0.5585482716560364,
        0.5585482120513916,
        0.5585481524467468,
        0.558548092842102,
        0.5585480332374573,
        0.5585479736328125,
        0.5585479140281677,
        0.558547854423523,
        0.5585477948188782,
        0.5585477352142334,
        0.5585476756095886,
        0.5585476160049438,
        0.5585475564002991,
        0.5585474967956543,
        0.5585474371910095,
        0.5585473775863647,
        0.5585471987724304,
        0.5585471391677856,
        0.5585470795631409,
        0.5585470199584961,
        0.5585469603538513,
        0.5585469007492065,
        0.5585468411445618,
        0.558546781539917,
        0.5585467219352722,
        0.5585466623306274,
        0.5585466027259827,
        0.5585465431213379,
        0.5585464239120483,
        0.5585463643074036,
        0.5585463047027588,
        0.558546245098114,
        0.5585461258888245,
        0.5585460662841797,
        0.5585460066795349,
        0.5585458278656006,
        0.5585457682609558,
        0.558545708656311,
        0.5585456490516663,
        0.5585455894470215,
        0.5585455298423767,
        0.5585454702377319,
        0.5585454106330872,
        0.5585452914237976,
        0.5585452318191528,
        0.5585451722145081,
        0.5585450530052185,
        0.5585449934005737,
        0.558544933795929,
        0.5585448741912842,
        0.5585448145866394,
        0.5585446953773499,
        0.5585446357727051,
        0.5585445165634155,
        0.5585444569587708,
        0.5585443377494812,
        0.5585442781448364,
        0.5585441589355469,
        0.5585440993309021,
        0.5585440397262573,
        0.5585439801216125,
        0.5585439205169678,
        0.558543860912323,
        0.5585437417030334,
        0.5585436820983887,
        0.5585435628890991,
        0.5585435032844543,
        0.5585433840751648,
        0.5585432648658752,
        0.5585430264472961,
        0.5585429668426514,
        0.5585429072380066,
        0.5585428476333618,
        0.5585426688194275,
        0.5585426092147827,
        0.5585424900054932,
        0.5585424304008484,
        0.5585423707962036,
        0.5585421919822693,
        0.5585421323776245,
        0.5585420727729797,
        0.5585418343544006,
        0.5585413575172424,
        0.5585411190986633,
        0.5585410594940186,
        0.5585409998893738,
        0.5585408806800842,
        0.5585405826568604,
        0.5585405230522156,
        0.5585402250289917,
        0.5585399866104126,
        0.5585399270057678,
        0.5585395097732544,
        0.5585391521453857,
        0.5585384964942932,
        0.5585381984710693,
        0.558538019657135,
        0.5585379004478455,
        0.5585373044013977,
        0.5585363507270813,
        0.5585362315177917,
        0.5585271120071411,
        0.558526337146759,
        0.5572740435600281
      ]
    },
    "roc_auc": 0.0379379106171563,
    "optimal_threshold": Infinity,
    "precision_mean": 0.49984998499849986,
    "recall_mean": 1.0
  },
  "ttt_model": {
    "accuracy_mean": 0.9994,
    "accuracy_std": 0.0004898979485566361,
    "macro_f1_mean": 0.9993999993999994,
    "macro_f1_std": 0.0004898984384550602,
    "mcc_mean": 0.998801197603593,
    "mcc_std": 0.000978818057874421,
    "confusion_matrix": [
      [
        500,
        0
      ],
      [
        0,
        500
      ]
    ],
    "roc_curve": {
      "fpr": [
        0.0,
        0.0,
        0.116,
        0.12,
        1.0
      ],
      "tpr": [
        0.0,
        1.0,
        1.0,
        1.0,
        1.0
      ],
      "thresholds": [
        Infinity,
        1.0,
        2.802596928649634e-45,
        1.401298464324817e-45,
        0.0
      ]
    },
    "roc_auc": 1.0,
    "optimal_threshold": 1.0,
    "ttt_adaptation_data": {
      "steps": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50,
        51,
        52,
        53,
        54,
        55,
        56,
        57,
        58,
        59,
        60,
        61,
        62,
        63,
        64,
        65,
        66,
        67,
        68,
        69,
        70,
        71,
        72,
        73,
        74,
        75,
        76,
        77,
        78,
        79,
        80,
        81,
        82,
        83,
        84,
        85,
        86,
        87,
        88,
        89,
        90,
        91,
        92,
        93,
        94,
        95,
        96,
        97,
        98,
        99,
        100,
        101,
        102,
        103,
        104,
        105,
        106,
        107,
        108,
        109,
        110,
        111,
        112,
        113,
        114,
        115,
        116,
        117,
        118,
        119,
        120,
        121,
        122,
        123,
        124,
        125,
        126,
        127,
        128,
        129,
        130,
        131,
        132,
        133,
        134,
        135,
        136,
        137,
        138,
        139,
        140,
        141,
        142,
        143,
        144,
        145,
        146,
        147,
        148,
        149,
        150,
        151,
        152,
        153,
        154,
        155,
        156,
        157,
        158,
        159,
        160,
        161,
        162,
        163,
        164,
        165,
        166,
        167,
        168,
        169,
        170,
        171,
        172,
        173,
        174,
        175,
        176,
        177,
        178,
        179,
        180,
        181,
        182,
        183,
        184,
        185,
        186,
        187,
        188,
        189,
        190,
        191,
        192,
        193,
        194,
        195,
        196,
        197,
        198,
        199
      ],
      "total_losses": [
        0.7680878639221191,
        0.7623279690742493,
        0.7626281976699829,
        0.7597626447677612,
        0.7572654485702515,
        0.748602569103241,
        0.7397432923316956,
        0.72040194272995,
        0.7039722204208374,
        0.683637261390686,
        0.6633911728858948,
        0.6452406048774719,
        0.6108325719833374,
        0.5802157521247864,
        0.5426815152168274,
        0.49640342593193054,
        0.4609280228614807,
        0.4192504584789276,
        0.3641217052936554,
        0.3140052556991577,
        0.27822476625442505,
        0.23758788406848907,
        0.19508418440818787,
        0.1561124175786972,
        0.13154639303684235,
        0.10877291858196259,
        0.08202625811100006,
        0.06921083480119705,
        0.053427014499902725,
        0.038945116102695465,
        0.02962019294500351,
        0.03703926503658295,
        0.024308128282427788,
        0.01806359738111496,
        0.017557362094521523,
        0.014879075810313225,
        0.015812471508979797,
        0.007232354953885078,
        0.010064772330224514,
        0.007228252477943897,
        0.005902882665395737,
        0.0065545313991606236,
        0.004599262960255146,
        0.003931113984435797,
        0.0032965983264148235,
        0.0034340238198637962,
        0.004229564685374498,
        0.002661840058863163,
        0.00424467958509922,
        0.000834139296784997,
        0.0011937179369851947,
        0.002521214075386524,
        0.0011217626743018627,
        0.0012905726907774806,
        0.0021887337788939476,
        0.001597277238033712,
        0.0018184639047831297,
        0.0010956807527691126,
        0.003154380014166236,
        0.0007869378896430135,
        0.0007225725566968322,
        0.0010488178813830018,
        0.0005844418192282319,
        0.0012762054102495313,
        0.0012867965269833803,
        0.0006895344704389572,
        0.0004389499663375318,
        0.0006800981354899704,
        0.001467263326048851,
        0.0019795584958046675,
        0.00237662298604846,
        0.0008071769261732697,
        0.000528648728504777,
        0.000874591467436403,
        0.0014891233295202255,
        0.0007186264847405255,
        0.0006944336928427219,
        0.0010618140222504735,
        0.001127154566347599,
        0.00035362859489396214,
        0.0002593784884084016,
        0.0008602588204666972,
        0.00036414095666259527,
        0.00040452968096360564,
        0.0007962246309034526,
        0.0014522569254040718,
        0.0006088735535740852,
        0.0002727473620325327,
        0.000985058257356286,
        0.00043136044405400753,
        0.00044358958257362247,
        0.0003659615176729858,
        0.0008576257387176156,
        0.0003731314209289849,
        0.001251265057362616,
        0.027844833210110664,
        0.000803152157459408,
        0.005869250278919935,
        0.00042505242163315415,
        0.000419726682594046,
        0.0008498542010784149,
        0.00045862200204283,
        0.0004225389566272497,
        0.00046803243458271027,
        0.00045809015864506364,
        0.00041609880281612277,
        0.0007927401456981897,
        0.0004946551634930074,
        0.0005284579237923026,
        0.000754836481064558,
        0.0006204118835739791,
        0.0006652360898442566,
        0.0009441557922400534,
        0.0002264968934468925,
        0.0007090704748407006,
        0.00044606259325519204,
        0.0011593764647841454,
        0.0013265509624034166,
        0.0006346022710204124,
        0.0009064865880645812,
        0.0002102849684888497,
        0.001255900482647121,
        0.0007039725314825773,
        0.0013679404510185122,
        0.0007806743960827589,
        0.010112529620528221,
        0.0005255287978798151,
        0.001068285433575511,
        0.00047727557830512524,
        0.0004165616410318762,
        0.000991404871456325,
        0.0012844940647482872,
        0.000810552854090929,
        0.0005942627904005349,
        0.0005246750079095364,
        0.0007105929544195533,
        0.001792202820070088,
        0.0008954801014624536,
        0.0004739279393106699,
        0.00043911527609452605,
        0.0007783768232911825,
        0.0009395786328241229,
        0.0008167632622644305,
        0.0013236618833616376,
        0.00036477757385000587,
        0.00030535494443029165,
        0.00037274265196174383,
        0.0006630144198425114,
        0.00042604352347552776,
        0.0016256642993539572,
        0.0005303797079250216,
        0.001042146934196353,
        0.000629563583061099,
        0.00047816670848987997,
        0.00039940510760061443,
        0.00029221788281574845,
        0.0008751275017857552,
        0.0011359782656654716,
        0.0004936123732477427,
        0.0003034878463950008,
        0.0004376565048005432,
        0.0005528522306121886,
        0.00022801323211751878,
        0.0010193223133683205,
        0.0005770071293227375,
        0.001289757783524692,
        0.0007081993389874697,
        0.0011284578358754516,
        0.00034380267607048154,
        0.00040280475514009595,
        0.0006341087282635272,
        0.0014311847044155002,
        0.0007563576800748706,
        0.00042188609950244427,
        0.00034109086846001446,
        0.0005847614374943078,
        0.0008757426403462887,
        0.00043968099635094404,
        0.00022119440836831927,
        0.0008172549423761666,
        0.0003246826818212867,
        0.005742017645388842,
        0.00038900598883628845,
        0.00038974324706941843,
        0.0005062306299805641,
        0.0003666186239570379,
        0.0005968480836600065,
        0.000519684748724103,
        0.0006982644554227591,
        0.001152765122242272,
        0.0005792059819214046,
        0.001031813444569707,
        0.0002651450631674379,
        0.0003914895933121443,
        0.0002998276031576097,
        0.0007781980093568563,
        0.00036701277713291347,
        0.00044893252197653055,
        0.00137584179174155,
        0.0009376595262438059
      ],
      "support_losses": [
        0.6994027495384216,
        0.6933788061141968,
        0.6935814023017883,
        0.6907064914703369,
        0.6882026195526123,
        0.6795569658279419,
        0.6707562208175659,
        0.6515073776245117,
        0.63519287109375,
        0.6151028871536255,
        0.5951558351516724,
        0.5774375200271606,
        0.5438246130943298,
        0.5142627954483032,
        0.47821176052093506,
        0.4340498149394989,
        0.40150323510169983,
        0.36260634660720825,
        0.31144699454307556,
        0.2657950520515442,
        0.23578564822673798,
        0.19874952733516693,
        0.16151122748851776,
        0.12859252095222473,
        0.10678799450397491,
        0.08838004618883133,
        0.06516439467668533,
        0.05555552989244461,
        0.04287112131714821,
        0.030667301267385483,
        0.02296522632241249,
        0.031760476529598236,
        0.019450144842267036,
        0.014087257906794548,
        0.014972019009292126,
        0.01200184691697359,
        0.013714497908949852,
        0.005578799173235893,
        0.008429977111518383,
        0.005569689441472292,
        0.004192478023469448,
        0.005269041284918785,
        0.0036548811476677656,
        0.002725060563534498,
        0.0024426172021776438,
        0.002818800276145339,
        0.003617979120463133,
        0.001990480115637183,
        0.003940184600651264,
        0.00029211066430434585,
        0.0009707598946988583,
        0.0021014900412410498,
        0.0008304049260914326,
        0.0009040595614351332,
        0.0018984084017574787,
        0.0012420609127730131,
        0.0015336325159296393,
        0.0007728390628471971,
        0.002876933431252837,
        0.0006296518840827048,
        0.00031864404445514083,
        0.0006806721794418991,
        0.0004017638857476413,
        0.0009768599411472678,
        0.0009106357465498149,
        0.0004822797200176865,
        0.0002668800007086247,
        0.0005340354982763529,
        0.0013279153499752283,
        0.0017041693208739161,
        0.0021119771990925074,
        0.0005015521310269833,
        0.00030262142536230385,
        0.0006997670279815793,
        0.0010908961994573474,
        0.0005655874847434461,
        0.00048183949547819793,
        0.0008159107528626919,
        0.000956577539909631,
        0.0001676254760241136,
        0.00015460506256204098,
        0.000519491673912853,
        0.00016690063057467341,
        0.0002590732474345714,
        0.0007120218360796571,
        0.0013821297325193882,
        0.00044256856199353933,
        8.742797945160419e-05,
        0.0006912719691172242,
        0.0002553923986852169,
        0.00040405706386081874,
        0.00014057969383429736,
        0.0007350596715696156,
        0.00020538126409519464,
        0.0010177684016525745,
        0.02761666104197502,
        0.0006017681444063783,
        0.00571118388324976,
        0.00025946644018404186,
        0.000306501257000491,
        0.0006481126765720546,
        0.0002536543761380017,
        0.00021474446111824363,
        0.00021872695651836693,
        0.00027218711329624057,
        0.00022075310698710382,
        0.0005929582403041422,
        0.0003655059263110161,
        0.00036456261295825243,
        0.0006355124642141163,
        0.00048794079339131713,
        0.00045987151679582894,
        0.0008687582449056208,
        0.00011473702033981681,
        0.00032858134363777936,
        0.0003674493927974254,
        0.000995940645225346,
        0.0010488562984392047,
        0.00026571733178570867,
        0.0007794459233991802,
        0.00014755579468328506,
        0.0010888035176321864,
        0.00048316255561076105,
        0.001234953640960157,
        0.0006890525110065937,
        0.010036090388894081,
        0.0003986916854046285,
        0.000954925490077585,
        0.0003080412861891091,
        0.00036970447399653494,
        0.000868722447194159,
        0.0011744546936824918,
        0.0007210911135189235,
        0.0003430545039009303,
        0.00030598114244639874,
        0.000417575502069667,
        0.0016277243848890066,
        0.0008108466863632202,
        0.00026562673156149685,
        0.00011977665417362005,
        0.0006758866948075593,
        0.0007481354405172169,
        0.0007640127441845834,
        0.001133336336351931,
        0.0001900518691400066,
        8.23326117824763e-05,
        9.969217353500426e-05,
        0.0005021864199079573,
        0.00029547428130172193,
        0.0012745545245707035,
        0.00038043232052586973,
        0.0008932160562835634,
        0.0005507267778739333,
        0.0002639736921992153,
        0.00028146582189947367,
        0.0001751486270222813,
        0.0007510684663429856,
        0.0010030113626271486,
        0.00035765269421972334,
        0.00023319323372561485,
        0.00024124527408275753,
        0.0003798549878410995,
        8.115918171824887e-05,
        0.0009088882943615317,
        0.00042326448601670563,
        0.001138577819801867,
        0.00046567933168262243,
        0.001023540273308754,
        0.00011877244105562568,
        0.00026649123174138367,
        0.0005316398455761373,
        0.0012063485337421298,
        0.0004340226296335459,
        0.000325550528941676,
        0.0002644774504005909,
        0.0004743585886899382,
        0.0006424959865398705,
        0.00023611298820469528,
        0.00013838420272804797,
        0.0006737297517247498,
        0.00019295074162073433,
        0.005646741017699242,
        0.00027358788065612316,
        0.00013055292947683483,
        0.0002445555874146521,
        0.00029334472492337227,
        0.0005434872000478208,
        0.0003377140674274415,
        0.00042444662540219724,
        0.0009514371049590409,
        0.00042858804226852953,
        0.0009307964937761426,
        0.00015543425979558378,
        0.0001739412546157837,
        8.704711217433214e-05,
        0.0006285076378844678,
        0.00025963273947127163,
        0.000392221991205588,
        0.0012525396887212992,
        0.0008260682225227356
      ],
      "consistency_losses": [
        0.6868509650230408,
        0.6894916296005249,
        0.6904679536819458,
        0.6905613541603088,
        0.6906282305717468,
        0.6904562711715698,
        0.6898708939552307,
        0.688945472240448,
        0.6877937316894531,
        0.6853436231613159,
        0.6823531985282898,
        0.6780306696891785,
        0.6700796484947205,
        0.6595298051834106,
        0.6446977853775024,
        0.6235361695289612,
        0.5942479968070984,
        0.5664410591125488,
        0.5267471671104431,
        0.4821019768714905,
        0.4243912696838379,
        0.38838356733322144,
        0.3357295095920563,
        0.27519890666007996,
        0.24758395552635193,
        0.20392869412899017,
        0.1686185896396637,
        0.1365530788898468,
        0.10555893182754517,
        0.08277814835309982,
        0.06654965877532959,
        0.05278787389397621,
        0.04857983812689781,
        0.03976338729262352,
        0.025853434577584267,
        0.02877228707075119,
        0.020979737862944603,
        0.016535559669137,
        0.01634795404970646,
        0.016585631296038628,
        0.017104046419262886,
        0.01285490207374096,
        0.009443818591535091,
        0.012060534209012985,
        0.00853981077671051,
        0.006152236368507147,
        0.006115856114774942,
        0.0067135985009372234,
        0.003044949611648917,
        0.00542028620839119,
        0.0022295804228633642,
        0.004197240341454744,
        0.002913577249273658,
        0.003865131177008152,
        0.002903254237025976,
        0.0035521630197763443,
        0.0028483138885349035,
        0.0032284173648804426,
        0.0027744655963033438,
        0.0015728599391877651,
        0.004039285238832235,
        0.003681456670165062,
        0.0018267789855599403,
        0.0029934546910226345,
        0.003761607687920332,
        0.0020725473295897245,
        0.0017206997144967318,
        0.001460626139305532,
        0.0013934801099821925,
        0.0027538910508155823,
        0.0026464578695595264,
        0.0030562474858015776,
        0.0022602728568017483,
        0.0017482441617175937,
        0.003982271067798138,
        0.0015303901163861156,
        0.002125941915437579,
        0.002459032228216529,
        0.001705769682303071,
        0.0018600310431793332,
        0.0010477342875674367,
        0.0034076711162924767,
        0.0019724031444638968,
        0.0014545641606673598,
        0.0008420280064456165,
        0.000701271346770227,
        0.001663049915805459,
        0.0018531938549131155,
        0.0029378633480519056,
        0.0017596804536879063,
        0.0003953252744395286,
        0.002253818092867732,
        0.0012256609043106437,
        0.0016775015974417329,
        0.0023349665571004152,
        0.00228171912021935,
        0.0020138402469456196,
        0.0015806637238711119,
        0.0016558599891141057,
        0.001132254139520228,
        0.002017415128648281,
        0.0020496761426329613,
        0.0020779448095709085,
        0.0024930546060204506,
        0.001859030220657587,
        0.0019534567836672068,
        0.001997819170355797,
        0.0012914922554045916,
        0.00163895299192518,
        0.001193240168504417,
        0.00132471090182662,
        0.002053645672276616,
        0.0007539756479673088,
        0.001117598614655435,
        0.0038048909045755863,
        0.0007861318299546838,
        0.0016343577299267054,
        0.002776946173980832,
        0.003688849275931716,
        0.0012704064138233662,
        0.0006272917380556464,
        0.0016709697665646672,
        0.0022080999333411455,
        0.0013298678677529097,
        0.000916218850761652,
        0.0007643934804946184,
        0.0012683713575825095,
        0.0011335990857332945,
        0.0016923430375754833,
        0.00046857172856107354,
        0.0012268241262063384,
        0.0011003935942426324,
        0.0008946174057200551,
        0.0025120829232037067,
        0.0021869384218007326,
        0.0029301748145371675,
        0.0016447848174721003,
        0.0008463342091999948,
        0.0020830119028687477,
        0.003193385899066925,
        0.0010249011684209108,
        0.001914431806653738,
        0.0005275052972137928,
        0.0019032553536817431,
        0.001747257192619145,
        0.002230223501101136,
        0.002730504609644413,
        0.001608279999345541,
        0.0013056922471150756,
        0.003511097515001893,
        0.0014994741650298238,
        0.0014893088955432177,
        0.0007883678190410137,
        0.0021419301629066467,
        0.0011793929152190685,
        0.0011706924997270107,
        0.0012405903544276953,
        0.0013296690303832293,
        0.0013595970813184977,
        0.0007029462140053511,
        0.001964112278074026,
        0.0017299724277108908,
        0.0014685404021292925,
        0.0011043399572372437,
        0.0015374264912679791,
        0.0015117994043976068,
        0.0024251998402178288,
        0.0010491752764210105,
        0.0022503023501485586,
        0.0013631354086101055,
        0.0010246889432892203,
        0.0022483612410724163,
        0.0032233502715826035,
        0.0009633558220230043,
        0.0007661340641789138,
        0.0011040285462513566,
        0.00233246642164886,
        0.002035679994150996,
        0.0008281019399873912,
        0.001435251790098846,
        0.0013173193437978625,
        0.0009527681395411491,
        0.001154181081801653,
        0.002591902855783701,
        0.002616750542074442,
        0.0007327389321289957,
        0.0005336086614988744,
        0.0018197069875895977,
        0.0027381780091673136,
        0.0020132805220782757,
        0.0015061795711517334,
        0.0010101695079356432,
        0.0010971081210300326,
        0.002175483386963606,
        0.0021278047934174538,
        0.001496903714723885,
        0.0010738003766164184,
        0.0005671054241247475,
        0.0012330205645412207,
        0.001115913037210703
      ]
    },
    "precision_mean": 1.0,
    "recall_mean": 1.0
  },
  "dataset_info": {
    "name": "Edge-IIoTset",
    "total_samples": 243134,
    "evaluated_samples": 10000,
    "features": 61,
    "attack_types": 15,
    "zero_day_attack": "DDoS_UDP",
    "zero_day_stats": {
      "zero_day_attack": "DDoS_UDP",
      "zero_day_samples": 121567,
      "zero_day_percentage": 20.168960900416927,
      "total_attack_samples": 602743,
      "normal_samples": 1615643,
      "total_samples": 2218386,
      "available_attacks": [
        "Normal",
        "DDoS_UDP",
        "DDoS_ICMP",
        "SQL_injection",
        "Password",
        "Vulnerability_scanner",
        "DDoS_TCP",
        "DDoS_HTTP",
        "Uploading",
        "Backdoor",
        "Port_Scanning",
        "XSS",
        "Ransomware",
        "Fingerprinting",
        "MITM"
      ]
    }
  },
  "final_global_model": {
    "accuracy": 0.5,
    "f1_score": 0.3333333333333333,
    "mcc": 0.0,
    "roc_auc": 0.043726319999999964,
    "optimal_threshold": "0.55746096",
    "roc_curve": {
      "fpr": [
        0.0,
        0.0004,
        0.0908,
        0.0916,
        0.0964,
        0.0972,
        0.1096,
        0.1104,
        0.1532,
        0.154,
        0.1792,
        0.18,
        0.1884,
        0.1892,
        0.1932,
        0.194,
        0.1996,
        0.2004,
        0.2096,
        0.2104,
        0.2136,
        0.2144,
        0.2416,
        0.2424,
        0.2768,
        0.2776,
        0.2832,
        0.284,
        0.3188,
        0.3196,
        0.3232,
        0.324,
        0.3968,
        0.3976,
        0.4276,
        0.4284,
        0.4304,
        0.432,
        0.4544,
        0.4552,
        0.502,
        0.5028,
        0.5304,
        0.5304,
        0.5324,
        0.5324,
        0.5336,
        0.5336,
        0.5348,
        0.5348,
        0.54,
        0.54,
        0.5424,
        0.5424,
        0.5448,
        0.5448,
        0.548,
        0.548,
        0.5488,
        0.5488,
        0.5492,
        0.5492,
        0.5508,
        0.5508,
        0.5528,
        0.5528,
        0.5544,
        0.5544,
        0.5556,
        0.5556,
        0.556,
        0.556,
        0.5564,
        0.5564,
        0.5568,
        0.5568,
        0.5572,
        0.5572,
        0.5576,
        0.5576,
        0.558,
        0.558,
        0.5596,
        0.5596,
        0.56,
        0.56,
        0.5604,
        0.5608,
        0.5608,
        0.5612,
        0.5612,
        0.5616,
        0.5616,
        0.5616,
        0.562,
        0.562,
        0.5628,
        0.5628,
        0.5632,
        0.5632,
        0.5636,
        0.5636,
        0.5636,
        0.5636,
        0.564,
        0.564,
        0.5644,
        0.5644,
        0.5648,
        0.5648,
        0.5648,
        0.5648,
        0.5648,
        0.5648,
        0.5652,
        0.5652,
        0.5652,
        0.5652,
        0.5652,
        0.5652,
        0.5652,
        0.5652,
        0.5656,
        0.5656,
        0.5656,
        0.5656,
        0.5656,
        0.5656,
        0.566,
        0.566,
        0.5664,
        0.5664,
        0.5664,
        0.5664,
        0.5664,
        0.5664,
        0.5664,
        0.5664,
        0.5664,
        0.5664,
        0.5664,
        0.5664,
        0.5664,
        0.5664,
        0.5664,
        0.5664,
        0.5664,
        0.5664,
        0.5664,
        0.5664,
        0.5664,
        0.5664,
        0.5664,
        0.5664,
        0.5664,
        0.5664,
        0.5664,
        0.5668,
        0.5668,
        0.5744,
        0.5752,
        0.6004,
        0.6012,
        0.62,
        0.6208,
        0.7124,
        0.7132,
        0.7348,
        0.7356,
        0.7448,
        0.7456,
        0.7516,
        0.7524,
        0.7612,
        0.762,
        0.7784,
        0.7792,
        0.7896,
        0.7904,
        0.8184,
        0.8184,
        0.82,
        0.8208,
        0.8256,
        0.8292,
        0.846,
        0.8472,
        0.8492,
        0.85,
        0.8712,
        0.8712,
        0.8816,
        0.8816,
        0.9268,
        0.9268,
        0.9364,
        0.9372,
        0.9652,
        0.9652,
        0.9664,
        0.9664,
        0.984,
        0.9848,
        0.9884,
        0.9884,
        0.9912,
        0.9912,
        0.998,
        0.998,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        1.0,
        1.0
      ],
      "tpr": [
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0004,
        0.0004,
        0.0008,
        0.0008,
        0.0012,
        0.0012,
        0.0016,
        0.0016,
        0.002,
        0.002,
        0.0024,
        0.0024,
        0.0028,
        0.0028,
        0.0032,
        0.0032,
        0.004,
        0.004,
        0.0044,
        0.0044,
        0.0052,
        0.0052,
        0.006,
        0.006,
        0.0064,
        0.0064,
        0.0068,
        0.0068,
        0.0072,
        0.0072,
        0.0076,
        0.0076,
        0.008,
        0.008,
        0.0084,
        0.0084,
        0.0088,
        0.0088,
        0.0092,
        0.0092,
        0.0108,
        0.0108,
        0.0116,
        0.0116,
        0.012,
        0.0136,
        0.0136,
        0.014,
        0.014,
        0.0148,
        0.016,
        0.016,
        0.02,
        0.02,
        0.0208,
        0.0208,
        0.0224,
        0.0224,
        0.024,
        0.0248,
        0.0256,
        0.0256,
        0.0276,
        0.0276,
        0.028,
        0.0284,
        0.0312,
        0.0328,
        0.034,
        0.0348,
        0.036,
        0.036,
        0.0364,
        0.038,
        0.0388,
        0.0404,
        0.0416,
        0.0424,
        0.0496,
        0.0496,
        0.0508,
        0.0516,
        0.0556,
        0.0564,
        0.0568,
        0.0572,
        0.058,
        0.058,
        0.0588,
        0.0656,
        0.0664,
        0.0672,
        0.068,
        0.0708,
        0.0716,
        0.0736,
        0.0744,
        0.076,
        0.0772,
        0.078,
        0.08,
        0.0804,
        0.0812,
        0.0816,
        0.0832,
        0.086,
        0.0872,
        0.088,
        0.0896,
        0.0908,
        0.0924,
        0.0956,
        0.0964,
        0.0976,
        0.0984,
        0.0988,
        0.0988,
        0.0988,
        0.0988,
        0.0988,
        0.0988,
        0.0988,
        0.0988,
        0.0988,
        0.0988,
        0.0988,
        0.0988,
        0.0988,
        0.0988,
        0.0988,
        0.0988,
        0.0988,
        0.0988,
        0.0988,
        0.0988,
        0.0988,
        0.0988,
        0.0992,
        0.0992,
        0.0992,
        0.0992,
        0.0992,
        0.0992,
        0.0992,
        0.0992,
        0.0992,
        0.0992,
        0.0996,
        0.0996,
        0.1,
        0.1,
        0.1004,
        0.1004,
        0.1004,
        0.1004,
        0.1008,
        0.1008,
        0.1016,
        0.1016,
        0.1016,
        0.1016,
        0.102,
        0.102,
        0.1024,
        0.1024,
        0.1028,
        0.1028,
        0.104,
        0.1048,
        0.1068,
        0.1076,
        0.1104,
        0.1112,
        0.1136,
        0.1148,
        0.1156,
        0.1164,
        0.1196,
        0.1212,
        0.1216,
        0.1224,
        0.1308,
        0.1316,
        0.1328,
        0.1344,
        0.1368,
        0.138,
        0.1388,
        0.1396,
        0.1404,
        0.1412,
        0.1416,
        0.1428,
        0.1436,
        0.1448,
        0.146,
        0.1468,
        0.148,
        0.1492,
        0.15,
        0.1504,
        0.1512,
        0.152,
        0.156,
        0.1584,
        0.1592,
        0.1604,
        0.164,
        0.1648,
        0.1652,
        0.1692,
        0.1716,
        0.1728,
        0.1752,
        0.1756,
        0.1764,
        0.1776,
        0.178,
        0.1792,
        0.1796,
        0.182,
        0.184,
        0.1844,
        0.1868,
        0.1904,
        0.1916,
        0.1932,
        0.1944,
        0.1988,
        0.2012,
        0.2052,
        0.2064,
        0.2088,
        0.2104,
        0.2112,
        0.214,
        0.2144,
        0.218,
        0.222,
        0.2236,
        0.2264,
        0.2272,
        0.2328,
        0.2384,
        0.2432,
        0.246,
        0.2492,
        0.2548,
        0.2576,
        0.2616,
        0.2632,
        0.2668,
        0.2708,
        0.2736,
        0.2772,
        0.2804,
        0.286,
        0.2896,
        0.294,
        0.2964,
        0.2972,
        0.2996,
        0.3036,
        0.3088,
        0.3116,
        0.3124,
        0.316,
        0.3212,
        0.3244,
        0.3272,
        0.3296,
        0.3356,
        0.3368,
        0.3384,
        0.3432,
        0.3488,
        0.3512,
        0.3532,
        0.3612,
        0.3628,
        0.3716,
        0.376,
        0.3812,
        0.388,
        0.3884,
        0.3928,
        0.4,
        0.4048,
        0.4116,
        0.4136,
        0.4184,
        0.424,
        0.4248,
        0.43,
        0.432,
        0.4404,
        0.4444,
        0.45,
        0.4568,
        0.4672,
        0.4736,
        0.4764,
        0.4784,
        0.4852,
        0.4876,
        0.4928,
        0.5004,
        0.502,
        0.5048,
        0.5124,
        0.518,
        0.5224,
        0.5232,
        0.5288,
        0.534,
        0.5352,
        0.5408,
        0.5416,
        0.5456,
        0.5528,
        0.5552,
        0.5656,
        0.5688,
        0.5732,
        0.5796,
        0.5856,
        0.592,
        0.5936,
        0.602,
        0.6064,
        0.6104,
        0.6156,
        0.6168,
        0.6264,
        0.6376,
        0.6428,
        0.6464,
        0.6524,
        0.6564,
        0.6576,
        0.6632,
        0.6664,
        0.6712,
        0.678,
        0.6816,
        0.6832,
        0.6904,
        0.6956,
        0.7012,
        0.7072,
        0.7092,
        0.7164,
        0.7192,
        0.7272,
        0.7336,
        0.7352,
        0.7396,
        0.7436,
        0.7468,
        0.7508,
        0.7548,
        0.7576,
        0.7656,
        0.7716,
        0.7728,
        0.7764,
        0.7784,
        0.784,
        0.7876,
        0.79,
        0.7916,
        0.7968,
        0.7984,
        0.8012,
        0.8044,
        0.8088,
        0.8108,
        0.8116,
        0.8128,
        0.8156,
        0.8176,
        0.8224,
        0.8236,
        0.8268,
        0.8272,
        0.8304,
        0.8336,
        0.836,
        0.8372,
        0.8392,
        0.8408,
        0.8416,
        0.842,
        0.8436,
        0.8456,
        0.848,
        0.8484,
        0.8496,
        0.8512,
        0.854,
        0.8552,
        0.856,
        0.8572,
        0.8596,
        0.86,
        0.8624,
        0.8648,
        0.8652,
        0.8668,
        0.8684,
        0.8704,
        0.872,
        0.8732,
        0.8744,
        0.8756,
        0.8772,
        0.8776,
        0.8788,
        0.8796,
        0.8804,
        0.8816,
        0.8824,
        0.8848,
        0.8856,
        0.8864,
        0.8872,
        0.89,
        0.8932,
        0.8948,
        0.8972,
        0.8976,
        0.8984,
        0.8988,
        0.9,
        0.9044,
        0.9052,
        0.9064,
        0.9068,
        0.9076,
        0.908,
        0.9088,
        0.9092,
        0.91,
        0.9116,
        0.9124,
        0.914,
        0.9148,
        0.9316,
        0.9324,
        0.9384,
        0.9392,
        0.9424,
        0.9432,
        0.944,
        0.9448,
        0.9504,
        0.9512,
        0.958,
        0.9588,
        0.984,
        0.9848,
        0.9924,
        0.9924,
        1.0
      ],
      "thresholds": [
        Infinity,
        0.5691646933555603,
        0.565545380115509,
        0.565534770488739,
        0.5654568076133728,
        0.5654555559158325,
        0.5653236508369446,
        0.5653217434883118,
        0.565014660358429,
        0.565010666847229,
        0.5648442506790161,
        0.5648433566093445,
        0.564807116985321,
        0.5648070573806763,
        0.5647915601730347,
        0.5647889971733093,
        0.5647501349449158,
        0.5647461414337158,
        0.5647051334381104,
        0.5647042989730835,
        0.5646912455558777,
        0.5646884441375732,
        0.5645578503608704,
        0.5645568370819092,
        0.5644010305404663,
        0.5643978714942932,
        0.5643731355667114,
        0.5643730759620667,
        0.564213752746582,
        0.5642110109329224,
        0.5641945600509644,
        0.5641888976097107,
        0.563728928565979,
        0.5637277960777283,
        0.5635890364646912,
        0.5635885000228882,
        0.5635616183280945,
        0.5635576844215393,
        0.563443660736084,
        0.5634414553642273,
        0.5631879568099976,
        0.5631858110427856,
        0.5629876852035522,
        0.5629857778549194,
        0.5629798769950867,
        0.5629798173904419,
        0.5629758238792419,
        0.5629737377166748,
        0.5629692673683167,
        0.562968909740448,
        0.5629337430000305,
        0.5629319548606873,
        0.5629119873046875,
        0.5629113912582397,
        0.5628932118415833,
        0.5628890991210938,
        0.5628712177276611,
        0.5628650784492493,
        0.5628633499145508,
        0.5628530979156494,
        0.5628511309623718,
        0.5628445744514465,
        0.5628290772438049,
        0.5628255605697632,
        0.5628188252449036,
        0.5628125071525574,
        0.5628076791763306,
        0.5628010034561157,
        0.562798798084259,
        0.5627973079681396,
        0.5627968907356262,
        0.562795877456665,
        0.562793493270874,
        0.5627933144569397,
        0.5627920627593994,
        0.5627920031547546,
        0.5627918839454651,
        0.5627915859222412,
        0.5627914071083069,
        0.5627899169921875,
        0.5627897381782532,
        0.5627880096435547,
        0.5627834796905518,
        0.562781035900116,
        0.5627799034118652,
        0.5627795457839966,
        0.5627793669700623,
        0.5627791881561279,
        0.5627780556678772,
        0.5627762079238892,
        0.5627741813659668,
        0.5627727508544922,
        0.5627722144126892,
        0.5627712607383728,
        0.5627705454826355,
        0.562762975692749,
        0.5627612471580505,
        0.562760055065155,
        0.5627596378326416,
        0.5627579092979431,
        0.5627574920654297,
        0.5627557039260864,
        0.5627555847167969,
        0.5627549290657043,
        0.5627548694610596,
        0.5627532601356506,
        0.5627524256706238,
        0.5627519488334656,
        0.5627517104148865,
        0.5627499222755432,
        0.5627492666244507,
        0.5627491474151611,
        0.5627490878105164,
        0.5627488493919373,
        0.5627487897872925,
        0.5627487301826477,
        0.5627486109733582,
        0.5627484917640686,
        0.5627482533454895,
        0.5627476572990417,
        0.5627474784851074,
        0.5627446174621582,
        0.5627443194389343,
        0.5627437829971313,
        0.5627437233924866,
        0.5627420544624329,
        0.5627419352531433,
        0.5627416372299194,
        0.5627413988113403,
        0.5627409219741821,
        0.5627408623695374,
        0.5627408027648926,
        0.5627386569976807,
        0.5627385973930359,
        0.5627384185791016,
        0.562738299369812,
        0.5627375245094299,
        0.5627374053001404,
        0.5627372860908508,
        0.5627371072769165,
        0.562736988067627,
        0.5627367496490479,
        0.5627366304397583,
        0.5627365708351135,
        0.5627365112304688,
        0.562736451625824,
        0.5627363920211792,
        0.5627362728118896,
        0.5627356767654419,
        0.5627356171607971,
        0.5627354979515076,
        0.5627354383468628,
        0.5627353191375732,
        0.5627351999282837,
        0.5627343654632568,
        0.5627343058586121,
        0.5627339482307434,
        0.5627337098121643,
        0.5627331733703613,
        0.5626720786094666,
        0.5626685619354248,
        0.5625109076499939,
        0.5625087022781372,
        0.5623933672904968,
        0.5623930096626282,
        0.5615672469139099,
        0.5615655779838562,
        0.561510443687439,
        0.5615094304084778,
        0.5614959597587585,
        0.5614902973175049,
        0.5614752769470215,
        0.5614744424819946,
        0.5614520311355591,
        0.5614516735076904,
        0.5613998174667358,
        0.5613988041877747,
        0.5613614320755005,
        0.5613598823547363,
        0.5612244009971619,
        0.56121826171875,
        0.561213493347168,
        0.5612132549285889,
        0.5611982345581055,
        0.56119704246521,
        0.5611162781715393,
        0.5611157417297363,
        0.5611100196838379,
        0.5611079931259155,
        0.5607617497444153,
        0.5607513189315796,
        0.5605254173278809,
        0.5605204105377197,
        0.5596638321876526,
        0.559660792350769,
        0.5594872832298279,
        0.5594844818115234,
        0.5591751933097839,
        0.5591737031936646,
        0.5591673851013184,
        0.5591647028923035,
        0.5590529441833496,
        0.5590527653694153,
        0.5590291619300842,
        0.5590230226516724,
        0.5590007901191711,
        0.5590004324913025,
        0.5589141845703125,
        0.5588970184326172,
        0.5588120818138123,
        0.5587842464447021,
        0.5587835311889648,
        0.5587796568870544,
        0.5587790012359619,
        0.5587772130966187,
        0.5587770342826843,
        0.5587761998176575,
        0.5587761402130127,
        0.5587755441665649,
        0.5587753057479858,
        0.5587726831436157,
        0.5587724447250366,
        0.5587723851203918,
        0.558772087097168,
        0.5587698817253113,
        0.5587698221206665,
        0.5587695240974426,
        0.5587692856788635,
        0.558768630027771,
        0.5587685704231262,
        0.5587684512138367,
        0.5587683916091919,
        0.5587682127952576,
        0.558768093585968,
        0.5587680339813232,
        0.5587679743766785,
        0.5587679147720337,
        0.5587676763534546,
        0.5587676167488098,
        0.5587674975395203,
        0.5587674379348755,
        0.5587672591209412,
        0.5587671995162964,
        0.5587671399116516,
        0.5587670803070068,
        0.5587669014930725,
        0.5587665438652039,
        0.5587664246559143,
        0.5587663054466248,
        0.55876624584198,
        0.5587661862373352,
        0.5587661266326904,
        0.5587660670280457,
        0.5587658882141113,
        0.5587657690048218,
        0.5587655901908875,
        0.5587655305862427,
        0.5587654113769531,
        0.5587653517723083,
        0.5587652325630188,
        0.558765172958374,
        0.5587651133537292,
        0.5587650537490845,
        0.5587649941444397,
        0.5587649345397949,
        0.5587648749351501,
        0.5587648153305054,
        0.5587647557258606,
        0.5587646961212158,
        0.558764636516571,
        0.5587645769119263,
        0.5587645173072815,
        0.5587644577026367,
        0.5587643384933472,
        0.5587642788887024,
        0.5587642192840576,
        0.5587641596794128,
        0.5587641000747681,
        0.5587640404701233,
        0.5587639808654785,
        0.5587639212608337,
        0.558763861656189,
        0.5587638020515442,
        0.5587637424468994,
        0.5587636828422546,
        0.5587635636329651,
        0.5587635040283203,
        0.5587634444236755,
        0.5587633848190308,
        0.558763325214386,
        0.5587632656097412,
        0.5587632060050964,
        0.5587631464004517,
        0.5587630867958069,
        0.5587630271911621,
        0.5587629675865173,
        0.5587629079818726,
        0.5587628483772278,
        0.558762788772583,
        0.5587627291679382,
        0.5587626695632935,
        0.5587626099586487,
        0.5587625503540039,
        0.5587624907493591,
        0.5587624311447144,
        0.5587623715400696,
        0.5587623119354248,
        0.55876225233078,
        0.5587621927261353,
        0.5587621331214905,
        0.5587620735168457,
        0.5587620139122009,
        0.5587619543075562,
        0.5587618947029114,
        0.5587618350982666,
        0.5587617754936218,
        0.558761715888977,
        0.5587616562843323,
        0.5587615370750427,
        0.558761477470398,
        0.5587614178657532,
        0.5587613582611084,
        0.5587612986564636,
        0.5587612390518188,
        0.5587611794471741,
        0.5587611198425293,
        0.5587610602378845,
        0.5587610006332397,
        0.558760941028595,
        0.5587608814239502,
        0.5587608218193054,
        0.5587607622146606,
        0.5587607026100159,
        0.5587606430053711,
        0.5587605834007263,
        0.5587605237960815,
        0.5587604641914368,
        0.558760404586792,
        0.5587603449821472,
        0.5587602853775024,
        0.5587602257728577,
        0.5587601661682129,
        0.5587599873542786,
        0.5587599277496338,
        0.558759868144989,
        0.5587598085403442,
        0.5587597489356995,
        0.5587596893310547,
        0.5587596297264099,
        0.5587595701217651,
        0.5587595105171204,
        0.5587594509124756,
        0.5587593913078308,
        0.558759331703186,
        0.5587592720985413,
        0.5587592124938965,
        0.5587591528892517,
        0.5587590932846069,
        0.5587590336799622,
        0.5587589740753174,
        0.5587589144706726,
        0.5587588548660278,
        0.5587587952613831,
        0.5587587356567383,
        0.5587586760520935,
        0.5587586164474487,
        0.558758556842804,
        0.5587584972381592,
        0.5587584376335144,
        0.5587583780288696,
        0.5587583184242249,
        0.5587582588195801,
        0.5587581992149353,
        0.5587581396102905,
        0.5587580800056458,
        0.558758020401001,
        0.5587579011917114,
        0.5587577819824219,
        0.5587576627731323,
        0.5587576031684875,
        0.5587575435638428,
        0.558757483959198,
        0.5587574243545532,
        0.5587573647499084,
        0.5587573051452637,
        0.5587572455406189,
        0.5587571859359741,
        0.5587571263313293,
        0.5587570667266846,
        0.5587570071220398,
        0.558756947517395,
        0.5587568879127502,
        0.5587568283081055,
        0.5587567687034607,
        0.5587567090988159,
        0.5587566494941711,
        0.5587565898895264,
        0.5587565302848816,
        0.5587564706802368,
        0.558756411075592,
        0.5587563514709473,
        0.5587562918663025,
        0.5587561726570129,
        0.5587561130523682,
        0.5587560534477234,
        0.5587559938430786,
        0.5587559342384338,
        0.5587558746337891,
        0.5587558150291443,
        0.5587557554244995,
        0.55875563621521,
        0.5587555170059204,
        0.5587554574012756,
        0.5587553977966309,
        0.5587553381919861,
        0.5587552785873413,
        0.5587552189826965,
        0.5587551593780518,
        0.558755099773407,
        0.5587550401687622,
        0.5587549209594727,
        0.5587548613548279,
        0.5587548017501831,
        0.5587547421455383,
        0.558754563331604,
        0.5587545037269592,
        0.5587544441223145,
        0.5587543845176697,
        0.5587543249130249,
        0.5587542057037354,
        0.5587541460990906,
        0.558754026889801,
        0.5587539672851562,
        0.5587539076805115,
        0.5587538480758667,
        0.5587537884712219,
        0.5587537288665771,
        0.5587536692619324,
        0.5587535500526428,
        0.558753490447998,
        0.5587534308433533,
        0.5587533712387085,
        0.5587533116340637,
        0.558753252029419,
        0.5587531924247742,
        0.5587531328201294,
        0.5587529540061951,
        0.5587528944015503,
        0.5587527751922607,
        0.558752715587616,
        0.5587526559829712,
        0.5587525963783264,
        0.5587524771690369,
        0.5587524175643921,
        0.5587522387504578,
        0.5587520599365234,
        0.5587518811225891,
        0.5587518215179443,
        0.55875164270401,
        0.5587515830993652,
        0.5587514638900757,
        0.5587513446807861,
        0.5587512850761414,
        0.5587510466575623,
        0.5587509870529175,
        0.5587504506111145,
        0.5587503910064697,
        0.5587501525878906,
        0.5587500929832458,
        0.5587496161460876,
        0.5587494373321533,
        0.5587487816810608,
        0.5587483048439026,
        0.5587480664253235,
        0.5587479472160339,
        0.5587478876113892,
        0.5587474703788757,
        0.5587447881698608,
        0.5587447285652161,
        0.5587443113327026,
        0.5587438941001892,
        0.5587437152862549,
        0.5587430000305176,
        0.5587422847747803,
        0.5587418079376221,
        0.5587417483329773,
        0.5587413907051086,
        0.5587407350540161,
        0.5587401390075684,
        0.5587394833564758,
        0.5587037801742554,
        0.5587025284767151,
        0.5586931705474854,
        0.5586908459663391,
        0.5586820840835571,
        0.5586808323860168,
        0.5586797595024109,
        0.5586791634559631,
        0.5586515069007874,
        0.558651328086853,
        0.5586087703704834,
        0.5586084723472595,
        0.5583893060684204,
        0.5583803057670593,
        0.5581640601158142,
        0.558107852935791,
        0.5574609637260437
      ]
    },
    "confusion_matrix": [
      [
        0,
        2500
      ],
      [
        0,
        2500
      ]
    ],
    "test_samples": 5000,
    "dataset_info": {
      "name": "Edge-IIoTset",
      "total_samples": 243134,
      "evaluated_samples": 5000,
      "features": 61,
      "attack_types": 15,
      "zero_day_attack": "DDoS_UDP"
    }
  },
  "training_history": [
    {
      "round_number": 0,
      "client_updates": [
        "ClientUpdate(client_id='client_1', model_parameters={'meta_learner.transductive_net.feature_extractors.0.0.weight': tensor([[-0.0728, -0.1192,  0.0666,  ...,  0.0392,  0.1139,  0.0098],\n        [-0.1273,  0.0905, -0.0760,  ...,  0.1232,  0.0897, -0.0332],\n        [-0.0563,  0.0648,  0.0410,  ..., -0.1229,  0.0033, -0.0893],\n        ...,\n        [-0.1226,  0.0151,  0.0932,  ...,  0.1192, -0.0963, -0.0748],\n        [ 0.1053,  0.1167,  0.0167,  ...,  0.0184,  0.0108, -0.0212],\n        [ 0.0852,  0.0733, -0.0984,  ..., -0.1171, -0.0329,  0.1151]]), 'meta_learner.transductive_net.feature_extractors.0.0.bias': tensor([ 0.1208,  0.0252,  0.0769,  0.0993, -0.1274,  0.0868, -0.0993, -0.0878,\n         0.0717,  0.1006,  0.0884,  0.0685,  0.1018, -0.0371,  0.0065,  0.0802,\n         0.1172, -0.0009, -0.0138,  0.0060,  0.0607,  0.0967, -0.1190,  0.0178,\n         0.0952,  0.0630, -0.0196,  0.1202, -0.0331, -0.1309,  0.0098,  0.1201,\n        -0.0536, -0.0816, -0.0326,  0.0306, -0.0790,  0.0703, -0.1227, -0.0132,\n        -0.0823,  0.0769,  0.0602, -0.0661, -0.1128,  0.0992, -0.1082, -0.0225,\n        -0.0134, -0.0413, -0.0438,  0.0934, -0.0009,  0.0551,  0.1091,  0.0857,\n         0.0810, -0.1010, -0.1288, -0.0295,  0.0837,  0.0179,  0.1117, -0.0924,\n         0.0265, -0.0174,  0.0991, -0.0580,  0.0860, -0.0104,  0.0967,  0.0376,\n         0.0603, -0.0617,  0.1095, -0.0733, -0.0993, -0.0471, -0.0911, -0.1034,\n        -0.1151,  0.1193,  0.1172,  0.1268,  0.0106, -0.0388, -0.0133, -0.0940,\n        -0.0798, -0.0331, -0.0960,  0.1289,  0.0182, -0.0136,  0.1199,  0.0517,\n        -0.1079,  0.0422, -0.0110,  0.1195,  0.0805, -0.0424,  0.0060, -0.0550,\n         0.0952,  0.0882,  0.0305,  0.0041, -0.0128, -0.1213, -0.1245, -0.0591,\n        -0.0560,  0.0290,  0.0541,  0.1249,  0.1072,  0.0815,  0.0768, -0.0918,\n        -0.0622, -0.0832,  0.0884, -0.0249, -0.0871,  0.1213,  0.0199, -0.0299]), 'meta_learner.transductive_net.feature_extractors.1.0.weight': tensor([[ 0.0976,  0.0977,  0.0918,  ...,  0.0939, -0.0671,  0.0524],\n        [-0.1246, -0.0779,  0.0029,  ...,  0.0405,  0.0055,  0.0963],\n        [-0.1143,  0.0957,  0.0731,  ...,  0.1333,  0.0944,  0.1192],\n        ...,\n        [ 0.0411,  0.0791, -0.0835,  ..., -0.1253, -0.0363, -0.0137],\n        [ 0.0974, -0.0097,  0.0960,  ..., -0.0409,  0.0544,  0.0728],\n        [ 0.0527, -0.0895, -0.0482,  ...,  0.0442, -0.0482,  0.1162]]), 'meta_learner.transductive_net.feature_extractors.1.0.bias': tensor([ 0.0918, -0.0372,  0.0950, -0.1249,  0.0638, -0.0135,  0.0103,  0.0093,\n        -0.0785, -0.0869,  0.0099,  0.0354, -0.0956, -0.0537, -0.0801, -0.1171,\n        -0.0667,  0.0896,  0.0282,  0.0564,  0.0729, -0.1133,  0.1281,  0.0216,\n         0.0512,  0.1075,  0.0326,  0.0738, -0.0080, -0.0375,  0.0092,  0.0690,\n         0.0644, -0.0180,  0.0116,  0.1015,  0.1107, -0.0559, -0.0484,  0.1146,\n        -0.0406, -0.0956,  0.0110, -0.0203, -0.1170,  0.1129, -0.1156, -0.0702,\n         0.0934,  0.0404,  0.0769, -0.0485,  0.0737,  0.0013,  0.0301,  0.1025,\n        -0.0448, -0.0468, -0.0181, -0.0448, -0.0549, -0.0328, -0.1230, -0.0485]), 'meta_learner.transductive_net.feature_extractors.2.0.weight': tensor([[ 0.0802, -0.0105, -0.0886,  ..., -0.0355,  0.0228,  0.0980],\n        [-0.0002, -0.0941,  0.0733,  ...,  0.0704,  0.0801, -0.0893],\n        [ 0.0793,  0.0790,  0.0086,  ...,  0.0042,  0.0836, -0.0132],\n        ...,\n        [ 0.0863, -0.0769, -0.0643,  ...,  0.0978, -0.0219, -0.0039],\n        [-0.0122, -0.0381, -0.0011,  ...,  0.1121,  0.0287,  0.1005],\n        [ 0.0732, -0.0963,  0.0513,  ..., -0.0526, -0.0850, -0.0507]]), 'meta_learner.transductive_net.feature_extractors.2.0.bias': tensor([-0.0018,  0.1247,  0.1184,  0.0454, -0.0901, -0.0625,  0.0877, -0.0429,\n         0.1052, -0.1070,  0.1056,  0.0766,  0.0514, -0.1104,  0.0380, -0.0976,\n         0.0181, -0.0689,  0.0407, -0.1019, -0.0949, -0.1356,  0.1043, -0.0408,\n         0.0635, -0.0796,  0.0010, -0.0026,  0.0069, -0.1119,  0.0991,  0.0918,\n         0.1006,  0.0823, -0.0336, -0.0953, -0.1255,  0.0888, -0.1118,  0.0313,\n        -0.1013,  0.0572,  0.0906,  0.0832,  0.0538,  0.0739,  0.0426, -0.0453,\n         0.0839, -0.0115, -0.1173, -0.0191,  0.0610, -0.1051,  0.1082,  0.0146,\n         0.0774,  0.0195, -0.0211,  0.0185,  0.0875, -0.0772,  0.0174, -0.0603,\n         0.0101, -0.0660, -0.1111, -0.1153, -0.0858,  0.1136,  0.0400,  0.0649,\n        -0.1069, -0.0126,  0.0384,  0.0533,  0.0535,  0.0347,  0.0537, -0.0776,\n         0.0334, -0.0066,  0.0189,  0.0987, -0.0386,  0.0160,  0.0652, -0.0871,\n        -0.0531,  0.0993, -0.0683, -0.0647,  0.0530, -0.0682,  0.0543,  0.0878,\n         0.0761, -0.1045,  0.1179,  0.0801, -0.0509, -0.0010, -0.0771, -0.0743,\n         0.0834,  0.1106, -0.0278, -0.0352, -0.0118, -0.0047,  0.0921, -0.0151,\n         0.0925, -0.0352,  0.0227,  0.1053,  0.1094, -0.0156,  0.0790,  0.0903,\n        -0.1214,  0.1099, -0.0523,  0.0382, -0.1370, -0.0329, -0.0383, -0.0540,\n        -0.1088,  0.0676,  0.0109,  0.0931, -0.1131,  0.0315,  0.0145, -0.0244,\n         0.0972, -0.0901, -0.0206,  0.0698, -0.0023,  0.0840, -0.0304, -0.0164,\n        -0.0343,  0.0646, -0.0161,  0.0688, -0.0729, -0.1084, -0.0391, -0.0062,\n         0.0273, -0.0896,  0.0540, -0.0598, -0.0656, -0.0267,  0.0790,  0.0954,\n         0.0791, -0.1090,  0.0924, -0.0419, -0.0491,  0.0157,  0.0937, -0.0361,\n        -0.0664, -0.0184, -0.0524, -0.0915, -0.0426, -0.0677, -0.0305,  0.0234,\n        -0.0225,  0.0376, -0.0686, -0.0994,  0.1185,  0.0810,  0.0427, -0.0155,\n        -0.0397, -0.0922, -0.0767,  0.1121,  0.0678,  0.0235, -0.1103,  0.0905,\n        -0.1255,  0.1090, -0.0844,  0.1150, -0.0514, -0.0452,  0.0364, -0.0490,\n         0.0729, -0.0355, -0.0750, -0.0651,  0.0146,  0.0640, -0.0832,  0.0317,\n        -0.0963,  0.0862,  0.0966,  0.0397,  0.0372, -0.0054, -0.1166,  0.1250,\n        -0.1239, -0.0398,  0.0713, -0.0125,  0.0429, -0.0454,  0.0103, -0.0180,\n         0.1008,  0.0495, -0.0909, -0.1206, -0.1115, -0.0269,  0.0917, -0.1061,\n        -0.0037,  0.0058,  0.0050, -0.1141, -0.0726, -0.1161, -0.0554,  0.0031,\n         0.0456,  0.0715,  0.0246,  0.0307,  0.0992, -0.0581,  0.0169, -0.0092,\n        -0.0413, -0.0443, -0.0841, -0.1228,  0.0428, -0.1301, -0.0183, -0.0799]), 'meta_learner.transductive_net.feature_projection.0.weight': tensor([[ 0.0199,  0.0475, -0.0463,  ...,  0.0425,  0.0098,  0.0365],\n        [-0.0165,  0.0492, -0.0214,  ..., -0.0060,  0.0380,  0.0229],\n        [-0.0425, -0.0383,  0.0013,  ...,  0.0487,  0.0038, -0.0378],\n        ...,\n        [ 0.0448,  0.0261, -0.0450,  ...,  0.0255, -0.0334,  0.0379],\n        [ 0.0386,  0.0069, -0.0423,  ...,  0.0256, -0.0026, -0.0309],\n        [ 0.0451, -0.0216, -0.0220,  ...,  0.0013,  0.0291,  0.0565]]), 'meta_learner.transductive_net.feature_projection.0.bias': tensor([-0.0197,  0.0291,  0.0496, -0.0237, -0.0289, -0.0010, -0.0194, -0.0131,\n         0.0465,  0.0063, -0.0028, -0.0542,  0.0384, -0.0474, -0.0064,  0.0493,\n         0.0275, -0.0026, -0.0058, -0.0263, -0.0211, -0.0471, -0.0011,  0.0153,\n         0.0319, -0.0072, -0.0316, -0.0352, -0.0306,  0.0078,  0.0164, -0.0113,\n        -0.0489, -0.0217,  0.0187, -0.0554,  0.0090, -0.0416, -0.0389,  0.0115,\n         0.0278,  0.0157, -0.0289,  0.0223,  0.0323,  0.0206,  0.0192, -0.0304,\n        -0.0334, -0.0541,  0.0095, -0.0344,  0.0286,  0.0240, -0.0070, -0.0266,\n         0.0418, -0.0543, -0.0285,  0.0309, -0.0060,  0.0383,  0.0344,  0.0417]), 'meta_learner.transductive_net.classifier.0.weight': tensor([[ 0.0051, -0.0112,  0.0192,  ...,  0.0407,  0.0607, -0.0949],\n        [ 0.0252,  0.0162,  0.1082,  ..., -0.0108, -0.0250, -0.0706],\n        [ 0.0432,  0.0561,  0.1026,  ..., -0.0191, -0.0788,  0.0856],\n        ...,\n        [ 0.0867, -0.1223,  0.0593,  ..., -0.0181, -0.0583, -0.0657],\n        [ 0.1093,  0.0565,  0.0225,  ..., -0.0046, -0.1021, -0.0510],\n        [-0.0933, -0.0657,  0.1249,  ...,  0.0609,  0.0331,  0.0366]]), 'meta_learner.transductive_net.classifier.0.bias': tensor([ 0.1169,  0.0622,  0.0889,  0.1161, -0.0191, -0.0096,  0.0619, -0.0249,\n         0.1246,  0.1176,  0.1121,  0.0282, -0.0158, -0.1027,  0.1211, -0.1031,\n         0.0155, -0.0126,  0.0486, -0.0181,  0.1052, -0.0548,  0.0045, -0.0386,\n         0.0207,  0.0968,  0.1072, -0.0685,  0.0338,  0.0571, -0.1104, -0.1028,\n        -0.0114,  0.0899,  0.0668, -0.0519, -0.0245, -0.1072,  0.0719, -0.0801,\n        -0.1063, -0.0494,  0.0147,  0.1189,  0.1141, -0.0975, -0.0604, -0.0414,\n         0.0212, -0.0246, -0.0547,  0.1006,  0.0464,  0.0453, -0.0769,  0.0528,\n        -0.0589, -0.0573, -0.1089,  0.0518, -0.0845,  0.0654,  0.0350,  0.0003]), 'meta_learner.transductive_net.classifier.3.weight': tensor([[-0.0365,  0.1013, -0.0063,  ..., -0.0144,  0.0821, -0.0447],\n        [ 0.1084, -0.1173, -0.1131,  ..., -0.0754, -0.0556, -0.0007],\n        [-0.1209,  0.0129,  0.1059,  ...,  0.0854, -0.1111, -0.1106],\n        ...,\n        [-0.0661,  0.0582,  0.0771,  ..., -0.0113, -0.0087, -0.0531],\n        [-0.0405, -0.0381,  0.0268,  ...,  0.0994, -0.1183, -0.0578],\n        [ 0.0076, -0.0720,  0.0225,  ...,  0.0174,  0.0055, -0.0634]]), 'meta_learner.transductive_net.classifier.3.bias': tensor([-0.0734,  0.0280,  0.0554, -0.0562, -0.0363, -0.0194,  0.1017,  0.0641,\n        -0.0622, -0.0509,  0.1020, -0.0943, -0.1001,  0.1124,  0.1190,  0.1113,\n        -0.0784, -0.1197, -0.1044, -0.0196, -0.1242, -0.0388,  0.0270, -0.0045,\n         0.0380,  0.1114, -0.0215,  0.0175,  0.0974, -0.0787,  0.0883, -0.0832]), 'meta_learner.transductive_net.classifier.6.weight': tensor([[ 1.5904e-01,  7.6864e-02,  1.1138e-01,  5.2648e-02,  4.2535e-02,\n         -9.4865e-02,  8.9347e-03,  1.0103e-01, -1.0132e-01,  7.4811e-02,\n         -7.2304e-02,  8.5068e-02,  1.7237e-02,  1.0891e-04,  1.4412e-01,\n          1.5096e-01,  1.2042e-01, -1.6878e-01, -1.8468e-02, -1.5219e-01,\n         -1.3890e-01, -1.2020e-01, -1.3267e-01, -7.8105e-02, -1.5360e-01,\n         -9.0991e-02,  1.5794e-01,  3.3720e-02, -8.4812e-02, -1.7459e-01,\n         -1.3194e-01, -1.4839e-01],\n        [ 1.7365e-01, -1.3064e-01,  4.8513e-02,  9.8107e-02, -1.1753e-02,\n          5.7517e-02, -1.6625e-02, -1.2490e-02,  3.9125e-02,  1.5576e-01,\n          6.0088e-02, -4.2600e-02,  1.2639e-01,  1.5851e-01, -1.5943e-01,\n         -5.4763e-02, -1.3172e-01,  1.3137e-01, -7.2371e-02, -6.7796e-03,\n         -1.0572e-01,  1.6881e-01,  8.1393e-02, -1.2042e-01,  6.5429e-02,\n          1.6687e-01,  1.5890e-01,  8.1704e-02,  4.4793e-02, -1.2313e-01,\n          1.4851e-01,  1.0242e-01]]), 'meta_learner.transductive_net.classifier.6.bias': tensor([-0.0061,  0.1342]), 'meta_learner.transductive_net.self_attention.in_proj_weight': tensor([[ 0.0226,  0.0822, -0.0243,  ...,  0.1423, -0.1279,  0.1075],\n        [ 0.1233,  0.0504, -0.0827,  ..., -0.0691, -0.0478, -0.0616],\n        [-0.0530,  0.1474, -0.1601,  ..., -0.1322, -0.0188, -0.0321],\n        ...,\n        [ 0.1199,  0.0278, -0.1575,  ...,  0.0452,  0.1082, -0.0889],\n        [ 0.0571,  0.0449,  0.1308,  ..., -0.1445, -0.0152, -0.1550],\n        [-0.0021, -0.0057, -0.0095,  ..., -0.0552, -0.0418,  0.1377]]), 'meta_learner.transductive_net.self_attention.in_proj_bias': tensor([ 1.3903e-03, -7.4718e-03,  2.7564e-03,  4.0084e-03, -2.5317e-03,\n         5.0803e-03,  6.6874e-04,  1.1124e-03,  6.6171e-03, -3.4483e-04,\n        -2.6699e-03,  6.8697e-03, -2.5756e-04, -1.0924e-02, -3.3598e-04,\n        -2.4608e-03,  8.1010e-04,  5.2565e-03, -8.3729e-03, -9.3869e-05,\n         7.5393e-04,  4.3617e-03, -8.1887e-04, -2.2693e-03,  5.2522e-03,\n        -3.7682e-03,  3.6006e-03, -8.5014e-04,  3.1164e-03,  2.3460e-03,\n        -5.9889e-03, -5.8310e-03,  5.4410e-04, -2.1865e-03,  4.0848e-03,\n        -6.2271e-03,  1.1060e-02, -2.7613e-03, -8.4924e-03,  5.1477e-03,\n         1.1736e-02, -5.4415e-03,  1.0877e-02,  4.3256e-03,  5.3305e-03,\n        -8.9271e-03,  1.0265e-02, -4.3106e-04,  1.8199e-03,  9.9648e-03,\n         8.1243e-03,  5.9921e-03, -5.3169e-03,  2.2957e-03, -7.6285e-05,\n         2.7764e-03, -7.0554e-03, -3.1296e-03,  5.8546e-03, -8.8517e-03,\n         5.8705e-03, -2.6827e-03,  5.2460e-03, -2.5242e-05,  1.0298e-04,\n         6.5218e-06,  5.4952e-05, -2.7467e-05, -5.2205e-05,  5.0202e-05,\n        -6.2716e-05, -7.8361e-05,  3.1041e-07, -1.8762e-04,  1.7869e-05,\n         2.0961e-05, -6.4669e-05,  3.3204e-05,  1.1258e-04,  3.2104e-05,\n        -7.5027e-06,  2.7729e-05, -2.6095e-06,  6.5071e-05,  9.5112e-05,\n        -2.7536e-05, -7.6568e-05,  1.0391e-04, -3.2001e-05, -5.9160e-05,\n         8.6108e-05, -2.8209e-05, -1.0154e-04,  2.1058e-05,  5.6160e-05,\n         2.7290e-05, -6.7972e-05,  8.1406e-05,  4.8545e-05,  1.1659e-04,\n         5.6139e-05, -2.2722e-05, -2.5743e-05, -8.3462e-06,  5.3044e-05,\n        -2.7136e-05,  4.4998e-05, -3.0038e-05,  2.2497e-06, -4.2286e-05,\n         2.1684e-05, -4.9862e-05, -2.8966e-06, -4.2016e-05,  8.0109e-05,\n         3.5969e-05, -1.3838e-04,  1.5382e-05,  1.5773e-04,  2.0780e-05,\n        -2.4415e-05,  1.4450e-05,  6.6374e-05, -2.0309e-05, -2.0710e-05,\n        -6.1720e-05, -1.1065e-04, -3.3138e-05,  9.6248e-04,  9.9101e-04,\n         1.0306e-04,  4.7657e-04, -2.3141e-04, -5.5536e-04,  2.4098e-04,\n         2.5214e-04, -1.3186e-04,  1.7801e-04, -1.1375e-04, -1.0620e-04,\n         1.5399e-04,  2.7113e-04, -4.9713e-04, -1.7681e-04,  9.6454e-04,\n         4.8702e-04,  2.9573e-05, -6.0653e-04,  7.2930e-04, -1.4739e-04,\n         2.7197e-04, -1.7567e-04,  6.0886e-05,  1.3693e-04, -3.6646e-04,\n        -2.3592e-04, -4.0287e-04, -6.7762e-04, -3.0434e-04,  3.8498e-04,\n         8.0037e-05, -1.4607e-04, -4.4059e-04,  2.6016e-04, -6.1942e-05,\n        -2.4664e-04,  9.0201e-04, -5.2772e-05,  4.5850e-04,  5.2067e-04,\n        -2.3254e-04, -8.8548e-05,  2.1774e-04,  7.0728e-04, -1.8750e-05,\n         3.4108e-04,  2.5112e-04,  1.7256e-04,  5.3854e-04, -2.3005e-04,\n        -3.7660e-05, -3.5188e-04,  8.1119e-05,  2.4361e-04, -2.6657e-04,\n        -7.9379e-05, -5.2914e-05, -4.2276e-04,  2.9908e-04,  7.3919e-04,\n        -4.2637e-04, -4.3373e-04]), 'meta_learner.transductive_net.self_attention.out_proj.weight': tensor([[ 0.1294,  0.0217,  0.0344,  ..., -0.0415, -0.0428,  0.0775],\n        [ 0.0940, -0.1337, -0.0400,  ...,  0.0358,  0.0701,  0.0889],\n        [ 0.0585, -0.0581, -0.0388,  ..., -0.1166, -0.0666,  0.0585],\n        ...,\n        [ 0.0408,  0.0779,  0.0802,  ..., -0.0178, -0.0618, -0.0010],\n        [ 0.0270, -0.0169,  0.0196,  ...,  0.0584,  0.1020,  0.1032],\n        [ 0.0912,  0.0878, -0.0023,  ...,  0.0715,  0.1036,  0.0224]]), 'meta_learner.transductive_net.self_attention.out_proj.bias': tensor([-2.0890e-04,  6.9941e-04,  1.2896e-04, -5.2213e-04,  6.3911e-04,\n        -3.7948e-04, -2.8459e-04,  2.0972e-04, -1.1408e-04, -5.1709e-04,\n         5.8403e-04,  1.2183e-04, -4.4037e-04,  3.2481e-05, -1.3408e-04,\n         1.4728e-04,  1.4082e-04,  2.1257e-04,  2.9482e-05,  3.6250e-04,\n         5.0924e-04, -1.3118e-04, -2.3790e-04,  2.9628e-04, -1.5664e-04,\n         3.2359e-04, -1.4664e-04,  1.8820e-05, -2.0531e-04,  8.0234e-05,\n        -2.3527e-04,  7.3884e-05,  5.7208e-04, -9.7938e-04, -1.3860e-04,\n         1.9072e-04, -2.7964e-04,  7.1833e-04,  4.1402e-05,  1.9689e-04,\n        -5.2881e-04, -3.4270e-04,  3.0510e-04, -9.2092e-05, -2.7546e-04,\n         3.3340e-04, -5.4267e-04, -4.9970e-04,  1.0323e-04, -1.3511e-04,\n        -1.3581e-04, -1.7853e-04,  2.0664e-04,  3.2982e-04,  2.4017e-04,\n         8.3318e-05, -9.8271e-04, -9.5008e-05, -5.4458e-04, -1.1015e-03,\n         9.1111e-06,  2.8321e-04, -4.7045e-04,  9.8630e-05]), 'meta_learner.transductive_net.layer_norm.weight': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'meta_learner.transductive_net.layer_norm.bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}, sample_count=55769, training_loss=np.float64(0.1515740606188774), validation_accuracy=np.float64(0.6640000069141389), validation_precision=0.0, validation_recall=0.0, validation_f1_score=0.0, timestamp=1760269297.4956524, model_hash='b6c3d2ba62c8f55717f8334aacffe723798d4f05b88d60a55f20f425a03f7739', ipfs_cid='QmWBskvvktTh84E73tBg9pvQcsJzEGEiW74k2rNBN6bYL2', blockchain_tx_hash='57670beff017525483d7ad2780eda3f3bd39a5db043a299dd83332afb08c4dc0')",
        "ClientUpdate(client_id='client_2', model_parameters={'meta_learner.transductive_net.feature_extractors.0.0.weight': tensor([[-0.0726, -0.1190,  0.0669,  ...,  0.0430,  0.1013,  0.0098],\n        [-0.1122,  0.1056, -0.0701,  ...,  0.1198,  0.0906, -0.0332],\n        [-0.0567,  0.0644,  0.0482,  ..., -0.1253,  0.0063, -0.0893],\n        ...,\n        [-0.1125,  0.0252,  0.0859,  ...,  0.1307, -0.0889, -0.0748],\n        [ 0.0844,  0.0960,  0.0292,  ...,  0.0254,  0.0095, -0.0212],\n        [ 0.0928,  0.0812, -0.0971,  ..., -0.1148, -0.0262,  0.1151]]), 'meta_learner.transductive_net.feature_extractors.0.0.bias': tensor([ 0.1205,  0.0142,  0.0760,  0.0970, -0.1221,  0.0739, -0.0864, -0.0862,\n         0.0761,  0.1073,  0.1042,  0.0672,  0.1143, -0.0442,  0.0058,  0.0787,\n         0.1235, -0.0133, -0.0145,  0.0114,  0.0477,  0.0985, -0.1254,  0.0106,\n         0.1086,  0.0602, -0.0119,  0.1150, -0.0278, -0.1134,  0.0119,  0.1331,\n        -0.0585, -0.0864, -0.0237,  0.0401, -0.0727,  0.0650, -0.1200, -0.0246,\n        -0.0910,  0.0673,  0.0650, -0.0597, -0.1171,  0.1048, -0.1057, -0.0057,\n        -0.0257, -0.0360, -0.0466,  0.0913, -0.0202,  0.0543,  0.1042,  0.0918,\n         0.0886, -0.1007, -0.1203, -0.0327,  0.0855,  0.0169,  0.1041, -0.0736,\n         0.0246, -0.0186,  0.1182, -0.0566,  0.0991, -0.0262,  0.0846,  0.0221,\n         0.0886, -0.0628,  0.1069, -0.0849, -0.1022, -0.0540, -0.0895, -0.1148,\n        -0.1169,  0.1331,  0.1269,  0.1165,  0.0089, -0.0302, -0.0147, -0.1009,\n        -0.0890, -0.0324, -0.0839,  0.1277,  0.0084,  0.0015,  0.1193,  0.0416,\n        -0.1045,  0.0392, -0.0135,  0.1315,  0.0773, -0.0339,  0.0088, -0.0439,\n         0.1074,  0.0739,  0.0240,  0.0044,  0.0003, -0.1191, -0.1111, -0.0601,\n        -0.0448,  0.0195,  0.0527,  0.1129,  0.0931,  0.0908,  0.0793, -0.0955,\n        -0.0520, -0.0887,  0.1057, -0.0312, -0.0964,  0.1112,  0.0360, -0.0290]), 'meta_learner.transductive_net.feature_extractors.1.0.weight': tensor([[ 0.1011,  0.1016,  0.0983,  ...,  0.0811, -0.0767,  0.0524],\n        [-0.1214, -0.0746,  0.0062,  ...,  0.0360,  0.0198,  0.0963],\n        [-0.1238,  0.0867,  0.0664,  ...,  0.1239,  0.0983,  0.1192],\n        ...,\n        [ 0.0605,  0.0985, -0.0669,  ..., -0.1070, -0.0351, -0.0137],\n        [ 0.0808, -0.0266,  0.0968,  ..., -0.0321,  0.0565,  0.0728],\n        [ 0.0605, -0.0817, -0.0480,  ...,  0.0545, -0.0420,  0.1162]]), 'meta_learner.transductive_net.feature_extractors.1.0.bias': tensor([ 0.0924, -0.0404,  0.1047, -0.1130,  0.0613, -0.0169,  0.0161,  0.0106,\n        -0.0769, -0.0845,  0.0133,  0.0398, -0.0972, -0.0653, -0.0753, -0.1091,\n        -0.0764,  0.0809,  0.0129,  0.0634,  0.0756, -0.1202,  0.1172,  0.0187,\n         0.0563,  0.1100,  0.0190,  0.0719, -0.0141, -0.0487,  0.0026,  0.0772,\n         0.0594, -0.0151,  0.0072,  0.0904,  0.1075, -0.0758, -0.0514,  0.1106,\n        -0.0333, -0.0994,  0.0078, -0.0207, -0.1109,  0.1256, -0.1132, -0.0931,\n         0.0949,  0.0322,  0.0900, -0.0523,  0.0889,  0.0117,  0.0166,  0.1019,\n        -0.0476, -0.0472, -0.0118, -0.0593, -0.0382, -0.0491, -0.1106, -0.0563]), 'meta_learner.transductive_net.feature_extractors.2.0.weight': tensor([[ 0.0875, -0.0030, -0.0872,  ..., -0.0347,  0.0114,  0.0980],\n        [ 0.0003, -0.0936,  0.0672,  ...,  0.0625,  0.0828, -0.0893],\n        [ 0.0874,  0.0869,  0.0100,  ..., -0.0030,  0.0855, -0.0132],\n        ...,\n        [ 0.0841, -0.0791, -0.0732,  ...,  0.0918, -0.0240, -0.0039],\n        [-0.0107, -0.0367,  0.0060,  ...,  0.1181,  0.0340,  0.1005],\n        [ 0.0700, -0.0995,  0.0481,  ..., -0.0493, -0.0784, -0.0507]]), 'meta_learner.transductive_net.feature_extractors.2.0.bias': tensor([-3.0664e-03,  1.2423e-01,  9.7942e-02,  3.6788e-02, -9.6353e-02,\n        -6.8643e-02,  1.0069e-01, -4.7904e-02,  1.0692e-01, -1.1305e-01,\n         9.4148e-02,  7.1017e-02,  4.3469e-02, -1.0945e-01,  4.1685e-02,\n        -9.6711e-02,  3.1698e-02, -7.0742e-02,  5.1192e-02, -1.1257e-01,\n        -8.4298e-02, -1.3646e-01,  1.0069e-01, -4.4112e-02,  7.2037e-02,\n        -8.2860e-02, -5.9327e-04, -6.6857e-05,  2.7752e-02, -1.0792e-01,\n         9.1653e-02,  6.9938e-02,  9.3201e-02,  8.0832e-02, -2.6562e-02,\n        -9.5363e-02, -1.3481e-01,  1.0509e-01, -9.9765e-02,  2.9142e-02,\n        -1.0715e-01,  5.4919e-02,  9.3710e-02,  7.7981e-02,  5.6019e-02,\n         8.0509e-02,  4.6486e-02, -4.7055e-02,  8.9686e-02, -7.8587e-03,\n        -1.0152e-01, -1.1531e-02,  6.5270e-02, -1.0723e-01,  1.2070e-01,\n         1.6906e-02,  9.4623e-02,  2.2036e-02, -1.1641e-02,  2.4710e-02,\n         9.5382e-02, -8.7625e-02,  6.3315e-03, -6.0857e-02,  1.0372e-02,\n        -7.5373e-02, -1.1412e-01, -1.1438e-01, -8.0687e-02,  1.0048e-01,\n         3.0401e-02,  8.5539e-02, -1.2000e-01, -1.8909e-03,  5.8080e-02,\n         5.8029e-02,  5.2995e-02,  2.5796e-02,  4.1175e-02, -7.6198e-02,\n         2.8324e-02, -2.8788e-03,  3.6286e-02,  9.5640e-02, -3.6946e-02,\n         1.4294e-02,  6.8913e-02, -9.4095e-02, -5.8039e-02,  1.2257e-01,\n        -5.1375e-02, -6.4791e-02,  4.9488e-02, -7.7075e-02,  4.3139e-02,\n         8.4767e-02,  8.8679e-02, -1.2328e-01,  1.2874e-01,  8.2405e-02,\n        -5.3049e-02, -1.1272e-02, -7.4112e-02, -8.2532e-02,  9.1776e-02,\n         1.1977e-01, -2.4365e-02, -4.0163e-02, -3.0514e-02, -8.8305e-03,\n         8.6545e-02, -6.8990e-03,  9.5919e-02, -3.9408e-02,  3.4548e-02,\n         1.0032e-01,  9.7082e-02, -1.1298e-02,  8.6843e-02,  9.2117e-02,\n        -1.1472e-01,  1.3071e-01, -4.3745e-02,  3.8798e-02, -1.1882e-01,\n        -3.3250e-02, -2.7073e-02, -4.5116e-02, -1.1597e-01,  8.6716e-02,\n         2.1515e-02,  1.0180e-01, -1.0923e-01,  3.0320e-02,  2.9391e-02,\n        -1.7601e-02,  9.6334e-02, -1.0903e-01, -2.1287e-02,  5.9422e-02,\n        -3.5974e-03,  6.9891e-02, -2.0075e-02, -1.9909e-02, -3.6298e-02,\n         5.8070e-02, -3.1633e-02,  5.2977e-02, -6.4947e-02, -1.0160e-01,\n        -4.5289e-02,  1.2788e-03,  1.8570e-02, -9.8745e-02,  6.4565e-02,\n        -6.7725e-02, -5.2204e-02, -1.5441e-02,  7.0468e-02,  9.8603e-02,\n         8.2962e-02, -1.1323e-01,  8.5485e-02, -4.8674e-02, -5.0941e-02,\n         9.2402e-03,  9.3285e-02, -3.2720e-02, -4.9597e-02, -2.5279e-02,\n        -5.9978e-02, -8.8348e-02, -4.3917e-02, -7.5147e-02, -1.8426e-02,\n         1.6348e-02, -1.4405e-02,  4.2291e-02, -7.2658e-02, -1.0612e-01,\n         1.1385e-01,  7.4430e-02,  3.9616e-02, -2.6624e-02, -4.1843e-02,\n        -9.9932e-02, -8.4265e-02,  1.0989e-01,  7.1507e-02,  3.2195e-02,\n        -1.0115e-01,  9.7562e-02, -1.3509e-01,  1.2062e-01, -7.3518e-02,\n         1.0033e-01, -5.1626e-02, -4.1670e-02,  3.1463e-02, -5.4950e-02,\n         6.3258e-02, -3.2086e-02, -8.9470e-02, -5.6706e-02,  2.9251e-02,\n         5.5845e-02, -8.4515e-02,  2.9811e-02, -9.2006e-02,  8.7804e-02,\n         1.0257e-01,  4.7399e-02,  2.5322e-02, -4.6270e-03, -1.1268e-01,\n         1.2501e-01, -1.0843e-01, -4.5018e-02,  8.2127e-02, -2.9415e-02,\n         3.2796e-02, -4.6689e-02,  7.4936e-03, -2.4533e-02,  1.1808e-01,\n         5.0990e-02, -8.1719e-02, -1.3076e-01, -1.1858e-01, -3.0011e-02,\n         8.1121e-02, -1.0992e-01,  1.7783e-02,  4.1025e-03, -1.2270e-02,\n        -1.2846e-01, -7.0187e-02, -1.0119e-01, -6.6919e-02,  1.0457e-02,\n         3.9433e-02,  8.0054e-02,  2.8181e-02,  3.1763e-02,  1.0558e-01,\n        -5.8196e-02,  1.4171e-02, -4.7256e-03, -3.7319e-02, -5.3567e-02,\n        -6.4870e-02, -1.2586e-01,  2.9060e-02, -1.2787e-01, -1.9795e-02,\n        -7.6725e-02]), 'meta_learner.transductive_net.feature_projection.0.weight': tensor([[ 0.0214,  0.0406, -0.0337,  ...,  0.0506,  0.0180,  0.0327],\n        [-0.0351,  0.0317, -0.0305,  ..., -0.0074,  0.0406,  0.0211],\n        [-0.0272, -0.0412, -0.0034,  ...,  0.0420, -0.0006, -0.0402],\n        ...,\n        [ 0.0413,  0.0236, -0.0437,  ...,  0.0155, -0.0197,  0.0493],\n        [ 0.0404,  0.0199, -0.0371,  ...,  0.0237, -0.0122, -0.0449],\n        [ 0.0395, -0.0259, -0.0297,  ..., -0.0018,  0.0276,  0.0454]]), 'meta_learner.transductive_net.feature_projection.0.bias': tensor([-0.0129,  0.0092,  0.0526, -0.0261, -0.0258,  0.0036, -0.0192, -0.0104,\n         0.0384,  0.0190, -0.0118, -0.0349,  0.0436, -0.0405, -0.0061,  0.0251,\n         0.0290, -0.0054, -0.0128, -0.0199, -0.0211, -0.0345,  0.0160,  0.0074,\n         0.0413, -0.0119, -0.0323, -0.0420, -0.0337,  0.0193,  0.0056, -0.0076,\n        -0.0516, -0.0106,  0.0153, -0.0414,  0.0051, -0.0472, -0.0407, -0.0069,\n         0.0293,  0.0126, -0.0348,  0.0179,  0.0328,  0.0192,  0.0168, -0.0278,\n        -0.0197, -0.0461,  0.0227, -0.0294,  0.0406,  0.0259, -0.0146, -0.0196,\n         0.0457, -0.0372, -0.0229,  0.0421, -0.0074,  0.0355,  0.0324,  0.0341]), 'meta_learner.transductive_net.classifier.0.weight': tensor([[ 0.0051, -0.0112,  0.0192,  ...,  0.0407,  0.0607, -0.0949],\n        [ 0.0252,  0.0162,  0.1082,  ..., -0.0108, -0.0250, -0.0706],\n        [ 0.0432,  0.0561,  0.1026,  ..., -0.0191, -0.0788,  0.0856],\n        ...,\n        [ 0.0867, -0.1223,  0.0593,  ..., -0.0181, -0.0583, -0.0657],\n        [ 0.1093,  0.0565,  0.0225,  ..., -0.0046, -0.1021, -0.0510],\n        [-0.0933, -0.0657,  0.1249,  ...,  0.0609,  0.0331,  0.0366]]), 'meta_learner.transductive_net.classifier.0.bias': tensor([ 0.1169,  0.0622,  0.0889,  0.1161, -0.0191, -0.0096,  0.0619, -0.0249,\n         0.1246,  0.1176,  0.1121,  0.0282, -0.0158, -0.1027,  0.1211, -0.1031,\n         0.0155, -0.0126,  0.0486, -0.0181,  0.1052, -0.0548,  0.0045, -0.0386,\n         0.0207,  0.0968,  0.1072, -0.0685,  0.0338,  0.0571, -0.1104, -0.1028,\n        -0.0114,  0.0899,  0.0668, -0.0519, -0.0245, -0.1072,  0.0719, -0.0801,\n        -0.1063, -0.0494,  0.0147,  0.1189,  0.1141, -0.0975, -0.0604, -0.0414,\n         0.0212, -0.0246, -0.0547,  0.1006,  0.0464,  0.0453, -0.0769,  0.0528,\n        -0.0589, -0.0573, -0.1089,  0.0518, -0.0845,  0.0654,  0.0350,  0.0003]), 'meta_learner.transductive_net.classifier.3.weight': tensor([[-0.0365,  0.1013, -0.0063,  ..., -0.0144,  0.0821, -0.0447],\n        [ 0.1084, -0.1173, -0.1131,  ..., -0.0754, -0.0556, -0.0007],\n        [-0.1209,  0.0129,  0.1059,  ...,  0.0854, -0.1111, -0.1106],\n        ...,\n        [-0.0661,  0.0582,  0.0771,  ..., -0.0113, -0.0087, -0.0531],\n        [-0.0405, -0.0381,  0.0268,  ...,  0.0994, -0.1183, -0.0578],\n        [ 0.0076, -0.0720,  0.0225,  ...,  0.0174,  0.0055, -0.0634]]), 'meta_learner.transductive_net.classifier.3.bias': tensor([-0.0734,  0.0280,  0.0554, -0.0562, -0.0363, -0.0194,  0.1017,  0.0641,\n        -0.0622, -0.0509,  0.1020, -0.0943, -0.1001,  0.1124,  0.1190,  0.1113,\n        -0.0784, -0.1197, -0.1044, -0.0196, -0.1242, -0.0388,  0.0270, -0.0045,\n         0.0380,  0.1114, -0.0215,  0.0175,  0.0974, -0.0787,  0.0883, -0.0832]), 'meta_learner.transductive_net.classifier.6.weight': tensor([[ 1.5904e-01,  7.6864e-02,  1.1138e-01,  5.2648e-02,  4.2535e-02,\n         -9.4865e-02,  8.9347e-03,  1.0103e-01, -1.0132e-01,  7.4811e-02,\n         -7.2304e-02,  8.5068e-02,  1.7237e-02,  1.0891e-04,  1.4412e-01,\n          1.5096e-01,  1.2042e-01, -1.6878e-01, -1.8468e-02, -1.5219e-01,\n         -1.3890e-01, -1.2020e-01, -1.3267e-01, -7.8105e-02, -1.5360e-01,\n         -9.0991e-02,  1.5794e-01,  3.3720e-02, -8.4812e-02, -1.7459e-01,\n         -1.3194e-01, -1.4839e-01],\n        [ 1.7365e-01, -1.3064e-01,  4.8513e-02,  9.8107e-02, -1.1753e-02,\n          5.7517e-02, -1.6625e-02, -1.2490e-02,  3.9125e-02,  1.5576e-01,\n          6.0088e-02, -4.2600e-02,  1.2639e-01,  1.5851e-01, -1.5943e-01,\n         -5.4763e-02, -1.3172e-01,  1.3137e-01, -7.2371e-02, -6.7796e-03,\n         -1.0572e-01,  1.6881e-01,  8.1393e-02, -1.2042e-01,  6.5429e-02,\n          1.6687e-01,  1.5890e-01,  8.1704e-02,  4.4793e-02, -1.2313e-01,\n          1.4851e-01,  1.0242e-01]]), 'meta_learner.transductive_net.classifier.6.bias': tensor([-0.0061,  0.1342]), 'meta_learner.transductive_net.self_attention.in_proj_weight': tensor([[ 0.0292,  0.0825, -0.0298,  ...,  0.1509, -0.1289,  0.0967],\n        [ 0.1208,  0.0321, -0.0718,  ..., -0.0644, -0.0574, -0.0397],\n        [-0.0536,  0.1289, -0.1390,  ..., -0.1286, -0.0200, -0.0300],\n        ...,\n        [ 0.1130,  0.0260, -0.1412,  ...,  0.0457,  0.0968, -0.0931],\n        [ 0.0409,  0.0351,  0.1436,  ..., -0.1515, -0.0227, -0.1640],\n        [ 0.0034,  0.0126, -0.0114,  ..., -0.0543, -0.0414,  0.1264]]), 'meta_learner.transductive_net.self_attention.in_proj_bias': tensor([ 5.6021e-03,  1.0791e-02, -4.5567e-03, -2.1695e-05, -4.4317e-03,\n        -5.1159e-03, -6.3563e-06,  7.4136e-03,  4.0833e-03,  8.2063e-03,\n        -4.3232e-04, -2.0232e-03,  6.7636e-03,  7.8604e-03,  5.9400e-03,\n        -6.4760e-04,  9.4332e-03,  2.0161e-03,  9.3564e-03,  2.0561e-03,\n        -8.6249e-03, -4.3912e-03,  3.1738e-03, -6.2668e-03,  9.3520e-03,\n        -2.3866e-03, -4.5099e-04, -2.4580e-03, -2.8718e-03, -1.0151e-02,\n        -2.2664e-03,  6.9246e-03,  3.2667e-03,  1.0720e-02,  8.7835e-03,\n        -1.1886e-02,  1.7708e-03, -8.2320e-03,  1.7907e-03,  6.3264e-03,\n         7.7543e-03, -4.8555e-03,  8.4575e-03, -5.3685e-03, -6.5763e-03,\n        -2.6809e-03,  6.4748e-03,  3.2467e-03, -4.7808e-03,  5.4333e-03,\n         5.8806e-03, -2.9496e-03,  1.6406e-04, -4.4783e-03,  3.8296e-04,\n         7.8984e-03,  6.7923e-03, -5.9164e-03, -1.1658e-02, -1.0313e-02,\n         5.6454e-03,  3.2274e-03,  4.6372e-03, -6.9303e-03, -6.1281e-06,\n         3.8715e-05,  8.0918e-06, -3.2258e-05, -9.6495e-06, -7.8497e-05,\n        -6.0983e-05,  1.0909e-04, -3.7154e-05,  1.7004e-04,  8.9127e-06,\n        -4.7993e-05,  6.8108e-05, -2.5426e-05,  2.5729e-05,  1.3480e-05,\n        -2.5351e-05,  9.0771e-05, -2.3760e-05, -2.9274e-05, -4.7200e-05,\n        -2.0267e-05,  1.9249e-05, -4.6002e-05, -9.2099e-05,  3.3952e-05,\n         8.0933e-06, -1.0963e-04,  1.9923e-05, -7.7024e-07,  2.3037e-06,\n        -1.2357e-04, -6.6675e-05, -1.0126e-05, -3.9480e-06, -6.3819e-05,\n         4.0803e-05, -4.2840e-05, -8.8379e-06, -7.3214e-06, -1.7818e-05,\n         1.9684e-05,  5.0251e-05, -4.2594e-06, -4.9409e-05,  6.9101e-05,\n         5.0440e-06, -3.6768e-05, -3.1480e-05, -1.7548e-06,  1.2970e-05,\n         5.1587e-05, -6.6801e-05,  1.1579e-04,  2.3591e-05, -1.7360e-05,\n         3.3744e-06,  3.1986e-05,  5.0965e-05, -3.4451e-05,  1.8631e-05,\n        -1.9966e-05, -2.0919e-05,  1.3213e-05, -2.2410e-04, -7.8479e-04,\n        -2.4040e-04,  3.3091e-04,  5.0065e-05, -3.4125e-04,  3.3274e-05,\n        -1.4421e-04,  3.6650e-04,  6.4563e-04,  2.2035e-04,  3.3979e-04,\n         7.3196e-04,  2.7543e-04, -7.0457e-05, -1.3995e-04,  1.2199e-04,\n        -4.2902e-04,  1.6661e-04,  6.8917e-04, -1.2646e-04, -1.7316e-04,\n        -6.4427e-05, -2.1344e-04, -1.8863e-04,  2.6193e-05,  9.4305e-05,\n        -6.3430e-04,  4.9646e-04, -1.3249e-05,  3.0601e-04,  4.7770e-04,\n        -4.9681e-04,  3.4742e-04,  2.5086e-04, -7.8466e-05, -3.8633e-04,\n         5.0343e-04, -5.7940e-05, -1.6251e-04,  9.9047e-05, -1.4437e-04,\n         6.3070e-04, -7.0516e-04, -1.4894e-05,  1.5501e-04, -1.5836e-04,\n         3.4039e-05, -2.9350e-05,  3.4746e-04,  2.4482e-05, -1.5143e-04,\n         7.9221e-07,  4.8524e-05, -2.1687e-05, -2.7271e-04, -7.4631e-04,\n         2.9423e-04, -1.7908e-04,  1.5506e-04, -6.4341e-05,  1.8176e-04,\n        -4.0694e-04, -6.4463e-05]), 'meta_learner.transductive_net.self_attention.out_proj.weight': tensor([[ 0.1245,  0.0025,  0.0552,  ..., -0.0444, -0.0314,  0.0776],\n        [ 0.1127, -0.1207, -0.0359,  ...,  0.0340,  0.0633,  0.0943],\n        [ 0.0568, -0.0506, -0.0423,  ..., -0.1061, -0.0618,  0.0555],\n        ...,\n        [ 0.0447,  0.0803,  0.0658,  ..., -0.0203, -0.0659,  0.0092],\n        [ 0.0320, -0.0036,  0.0246,  ...,  0.0794,  0.0906,  0.0964],\n        [ 0.0920,  0.0956, -0.0010,  ...,  0.0579,  0.1031,  0.0383]]), 'meta_learner.transductive_net.self_attention.out_proj.bias': tensor([-2.0198e-04,  2.9267e-04,  4.8254e-04,  5.8538e-04, -1.6921e-04,\n         1.2100e-04, -1.9408e-04, -6.6307e-05,  2.2220e-04, -3.1607e-04,\n         3.6675e-04,  1.0815e-03, -2.8070e-04, -1.0102e-04,  2.0026e-05,\n        -1.4954e-04, -1.0410e-06, -9.4092e-05,  1.3693e-04,  4.8627e-05,\n        -6.4157e-04,  1.2252e-04,  1.2232e-04,  1.1419e-04,  6.8614e-04,\n         5.1435e-05, -2.2244e-04, -2.6568e-04,  4.5063e-05,  3.2865e-04,\n        -2.1839e-04,  2.3960e-04,  9.4943e-05,  3.7249e-04, -2.5121e-04,\n         5.1986e-04,  3.7283e-04,  1.7234e-04, -2.6094e-04,  1.1935e-04,\n         1.8330e-04, -1.5142e-05, -3.3136e-04, -3.7439e-04,  1.1482e-04,\n        -1.3736e-04,  2.3672e-04,  7.4321e-04, -1.0510e-04,  1.6861e-05,\n         5.6082e-05,  2.1984e-04, -1.2563e-04, -5.3283e-04, -2.9707e-04,\n        -3.3153e-05, -6.6948e-05, -2.1476e-04, -1.6849e-04, -1.2079e-04,\n         6.2738e-04,  4.1091e-04, -2.1973e-04,  4.0330e-06]), 'meta_learner.transductive_net.layer_norm.weight': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'meta_learner.transductive_net.layer_norm.bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}, sample_count=40667, training_loss=np.float64(0.1631235685944557), validation_accuracy=np.float64(0.5940000092983245), validation_precision=0.0, validation_recall=0.0, validation_f1_score=0.0, timestamp=1760269300.7790048, model_hash='b9109f15d7e02e079694734fc73b95fb10434ed690e891847685ce99e9238518', ipfs_cid='QmSgVE5APbrviMoZgjt1pVEvGRPbrQtmRk8UEa2HFeQBsU', blockchain_tx_hash='00767bf4ed5a05e02d09501abf3979edcac6003419953110d37fd06fa0b8bfe0')",
        "ClientUpdate(client_id='client_3', model_parameters={'meta_learner.transductive_net.feature_extractors.0.0.weight': tensor([[-0.0849, -0.1313,  0.0546,  ...,  0.0399,  0.1052,  0.0098],\n        [-0.1170,  0.1008, -0.0787,  ...,  0.1243,  0.0907, -0.0332],\n        [-0.0519,  0.0690,  0.0440,  ..., -0.1223, -0.0012, -0.0893],\n        ...,\n        [-0.1222,  0.0156,  0.0935,  ...,  0.1248, -0.0873, -0.0748],\n        [ 0.0994,  0.1108,  0.0274,  ...,  0.0286,  0.0132, -0.0212],\n        [ 0.0860,  0.0741, -0.0961,  ..., -0.1243, -0.0361,  0.1151]]), 'meta_learner.transductive_net.feature_extractors.0.0.bias': tensor([ 0.1328,  0.0125,  0.0650,  0.0865, -0.1210,  0.0758, -0.1079, -0.0791,\n         0.0749,  0.1041,  0.0839,  0.0693,  0.0971, -0.0331, -0.0034,  0.0792,\n         0.1069, -0.0174, -0.0141, -0.0014,  0.0491,  0.0919, -0.1249,  0.0275,\n         0.1061,  0.0712, -0.0125,  0.1054, -0.0249, -0.1313,  0.0045,  0.1208,\n        -0.0444, -0.0783, -0.0379,  0.0375, -0.0791,  0.0652, -0.1174, -0.0124,\n        -0.0799,  0.0779,  0.0550, -0.0700, -0.1002,  0.0954, -0.1073, -0.0160,\n        -0.0157, -0.0444, -0.0342,  0.0984, -0.0110,  0.0557,  0.1081,  0.0958,\n         0.0836, -0.0965, -0.1213, -0.0414,  0.0927,  0.0154,  0.1178, -0.0959,\n         0.0285, -0.0412,  0.0991, -0.0486,  0.0901, -0.0224,  0.0968,  0.0357,\n         0.0688, -0.0626,  0.1148, -0.0790, -0.0928, -0.0429, -0.0845, -0.1050,\n        -0.1227,  0.1211,  0.1136,  0.1138,  0.0023, -0.0288, -0.0262, -0.0986,\n        -0.0825, -0.0278, -0.0911,  0.1271,  0.0078, -0.0118,  0.1107,  0.0461,\n        -0.1113,  0.0357, -0.0107,  0.1283,  0.0676, -0.0452,  0.0083, -0.0469,\n         0.1065,  0.0758,  0.0279,  0.0104,  0.0045, -0.1277, -0.1210, -0.0598,\n        -0.0534,  0.0213,  0.0365,  0.1199,  0.1008,  0.0850,  0.0682, -0.0966,\n        -0.0553, -0.0803,  0.1095, -0.0117, -0.0981,  0.1208,  0.0274, -0.0313]), 'meta_learner.transductive_net.feature_extractors.1.0.weight': tensor([[ 0.1079,  0.1077,  0.0977,  ...,  0.0868, -0.0793,  0.0524],\n        [-0.1074, -0.0607,  0.0150,  ...,  0.0339,  0.0066,  0.0963],\n        [-0.1212,  0.0887,  0.0820,  ...,  0.1276,  0.0872,  0.1192],\n        ...,\n        [ 0.0526,  0.0907, -0.0780,  ..., -0.1200, -0.0348, -0.0137],\n        [ 0.0867, -0.0204,  0.1104,  ..., -0.0420,  0.0422,  0.0728],\n        [ 0.0606, -0.0815, -0.0413,  ...,  0.0433, -0.0397,  0.1162]]), 'meta_learner.transductive_net.feature_extractors.1.0.bias': tensor([ 7.5543e-02, -5.4362e-02,  9.7967e-02, -1.2654e-01,  6.4607e-02,\n        -9.8402e-03,  8.0471e-03,  1.7482e-02, -7.4717e-02, -8.6522e-02,\n         4.6575e-03,  3.7240e-02, -1.0983e-01, -5.7323e-02, -7.3861e-02,\n        -1.2490e-01, -6.8742e-02,  7.8115e-02,  1.8209e-02,  5.9584e-02,\n         7.7156e-02, -1.2595e-01,  1.1115e-01,  1.5568e-02,  6.6233e-02,\n         1.1769e-01,  2.5429e-02,  7.8405e-02, -9.4438e-03, -5.1117e-02,\n         8.3567e-03,  7.7688e-02,  6.0721e-02, -1.5254e-02,  3.1529e-02,\n         1.0417e-01,  9.4268e-02, -5.6388e-02, -5.6393e-02,  1.1834e-01,\n        -2.5320e-02, -1.0974e-01,  7.0456e-03, -2.2559e-02, -1.2440e-01,\n         1.3001e-01, -1.1951e-01, -8.8961e-02,  9.0960e-02,  2.7413e-02,\n         8.3535e-02, -5.0925e-02,  8.2710e-02,  3.9382e-05,  2.7274e-02,\n         1.1035e-01, -3.9823e-02, -6.7932e-02, -8.3414e-03, -5.1059e-02,\n        -5.2638e-02, -3.8118e-02, -1.0996e-01, -5.6458e-02]), 'meta_learner.transductive_net.feature_extractors.2.0.weight': tensor([[ 0.0920,  0.0015, -0.0835,  ..., -0.0377,  0.0192,  0.0980],\n        [-0.0049, -0.0988,  0.0620,  ...,  0.0679,  0.0856, -0.0893],\n        [ 0.0938,  0.0938,  0.0123,  ...,  0.0078,  0.0867, -0.0132],\n        ...,\n        [ 0.0845, -0.0787, -0.0675,  ...,  0.0952, -0.0278, -0.0039],\n        [-0.0067, -0.0326,  0.0065,  ...,  0.1165,  0.0372,  0.1005],\n        [ 0.0800, -0.0895,  0.0581,  ..., -0.0383, -0.0653, -0.0507]]), 'meta_learner.transductive_net.feature_extractors.2.0.bias': tensor([-0.0069,  0.1295,  0.1123,  0.0494, -0.0827, -0.0550,  0.0882, -0.0521,\n         0.1061, -0.1001,  0.1044,  0.0662,  0.0616, -0.1109,  0.0296, -0.0983,\n         0.0301, -0.0752,  0.0451, -0.1030, -0.0977, -0.1200,  0.1071, -0.0391,\n         0.0526, -0.0775,  0.0018, -0.0051,  0.0191, -0.1103,  0.1033,  0.0856,\n         0.0874,  0.0792, -0.0322, -0.0905, -0.1201,  0.1063, -0.1087,  0.0325,\n        -0.0945,  0.0490,  0.0804,  0.0963,  0.0513,  0.0748,  0.0419, -0.0503,\n         0.0887, -0.0256, -0.1134, -0.0278,  0.0556, -0.1133,  0.1198,  0.0273,\n         0.0779,  0.0233, -0.0122,  0.0343,  0.0867, -0.0839,  0.0193, -0.0607,\n        -0.0006, -0.0769, -0.1133, -0.1220, -0.0877,  0.1195,  0.0346,  0.0753,\n        -0.1031, -0.0076,  0.0570,  0.0450,  0.0571,  0.0285,  0.0627, -0.0754,\n         0.0303,  0.0057,  0.0212,  0.0973, -0.0284,  0.0064,  0.0621, -0.0879,\n        -0.0479,  0.1044, -0.0570, -0.0546,  0.0484, -0.0709,  0.0645,  0.0917,\n         0.0854, -0.1178,  0.1218,  0.0645, -0.0439,  0.0006, -0.0737, -0.0722,\n         0.0929,  0.1044, -0.0321, -0.0269, -0.0121, -0.0163,  0.0933, -0.0110,\n         0.0862, -0.0392,  0.0361,  0.1115,  0.1086, -0.0204,  0.0791,  0.0832,\n        -0.1135,  0.1141, -0.0531,  0.0329, -0.1257, -0.0467, -0.0440, -0.0415,\n        -0.1137,  0.0785,  0.0252,  0.1017, -0.0988,  0.0242,  0.0150, -0.0214,\n         0.0844, -0.0937, -0.0224,  0.0596,  0.0066,  0.0833, -0.0206, -0.0178,\n        -0.0382,  0.0535, -0.0207,  0.0558, -0.0651, -0.1094, -0.0400,  0.0052,\n         0.0314, -0.0819,  0.0460, -0.0849, -0.0511, -0.0370,  0.0709,  0.0977,\n         0.0847, -0.1123,  0.0856, -0.0431, -0.0457, -0.0003,  0.0784, -0.0263,\n        -0.0564, -0.0168, -0.0455, -0.1042, -0.0455, -0.0750, -0.0367,  0.0086,\n        -0.0221,  0.0400, -0.0618, -0.1020,  0.1232,  0.0697,  0.0430, -0.0179,\n        -0.0393, -0.0932, -0.0738,  0.1171,  0.0730,  0.0126, -0.1002,  0.0944,\n        -0.1294,  0.1213, -0.0758,  0.1050, -0.0630, -0.0344,  0.0446, -0.0584,\n         0.0777, -0.0362, -0.0721, -0.0555,  0.0250,  0.0523, -0.0773,  0.0235,\n        -0.0961,  0.0973,  0.0998,  0.0570,  0.0337, -0.0140, -0.1113,  0.1290,\n        -0.1129, -0.0401,  0.0596, -0.0126,  0.0510, -0.0577,  0.0117, -0.0172,\n         0.1097,  0.0553, -0.0833, -0.1180, -0.1085, -0.0253,  0.0810, -0.1137,\n         0.0042,  0.0126,  0.0031, -0.1289, -0.0654, -0.1103, -0.0691,  0.0056,\n         0.0420,  0.0749,  0.0204,  0.0493,  0.0937, -0.0520,  0.0103, -0.0029,\n        -0.0436, -0.0460, -0.0869, -0.1202,  0.0382, -0.1282, -0.0238, -0.0867]), 'meta_learner.transductive_net.feature_projection.0.weight': tensor([[ 0.0152,  0.0470, -0.0365,  ...,  0.0409,  0.0100,  0.0394],\n        [-0.0352,  0.0309, -0.0203,  ..., -0.0149,  0.0416,  0.0160],\n        [-0.0301, -0.0447, -0.0057,  ...,  0.0371,  0.0017, -0.0348],\n        ...,\n        [ 0.0413,  0.0295, -0.0478,  ...,  0.0179, -0.0304,  0.0390],\n        [ 0.0385,  0.0257, -0.0400,  ...,  0.0293, -0.0108, -0.0395],\n        [ 0.0464, -0.0274, -0.0274,  ..., -0.0024,  0.0271,  0.0518]]), 'meta_learner.transductive_net.feature_projection.0.bias': tensor([-2.4288e-02,  2.0714e-02,  4.1490e-02, -8.9202e-03, -2.6523e-02,\n         6.4571e-05, -2.3570e-02, -1.7832e-02,  4.9071e-02,  2.4552e-02,\n         2.9138e-03, -3.9458e-02,  4.8809e-02, -4.5896e-02,  1.4599e-02,\n         3.9279e-02,  3.8149e-02, -6.2760e-03,  1.9991e-03, -1.4680e-02,\n        -1.7183e-02, -4.4660e-02, -4.9136e-05,  9.2379e-03,  3.3761e-02,\n        -1.4572e-02, -3.3902e-02, -3.8201e-02, -3.7658e-02,  9.5041e-03,\n         2.0047e-02, -1.1771e-02, -5.4354e-02, -2.2339e-02,  2.2242e-02,\n        -4.3894e-02,  1.4271e-02, -4.0043e-02, -3.3626e-02, -9.4286e-04,\n         2.3748e-02,  1.3247e-02, -4.5508e-02,  2.5661e-02,  2.4805e-02,\n         2.0106e-02,  1.7978e-02, -2.6529e-02, -3.5548e-02, -3.9640e-02,\n         1.6331e-02, -2.2494e-02,  3.3777e-02,  2.1351e-02,  8.5790e-03,\n        -3.1774e-02,  4.4171e-02, -4.2241e-02, -2.7143e-02,  4.0126e-02,\n         4.6985e-03,  3.5058e-02,  4.0118e-02,  4.2786e-02]), 'meta_learner.transductive_net.classifier.0.weight': tensor([[ 0.0051, -0.0112,  0.0192,  ...,  0.0407,  0.0607, -0.0949],\n        [ 0.0252,  0.0162,  0.1082,  ..., -0.0108, -0.0250, -0.0706],\n        [ 0.0432,  0.0561,  0.1026,  ..., -0.0191, -0.0788,  0.0856],\n        ...,\n        [ 0.0867, -0.1223,  0.0593,  ..., -0.0181, -0.0583, -0.0657],\n        [ 0.1093,  0.0565,  0.0225,  ..., -0.0046, -0.1021, -0.0510],\n        [-0.0933, -0.0657,  0.1249,  ...,  0.0609,  0.0331,  0.0366]]), 'meta_learner.transductive_net.classifier.0.bias': tensor([ 0.1169,  0.0622,  0.0889,  0.1161, -0.0191, -0.0096,  0.0619, -0.0249,\n         0.1246,  0.1176,  0.1121,  0.0282, -0.0158, -0.1027,  0.1211, -0.1031,\n         0.0155, -0.0126,  0.0486, -0.0181,  0.1052, -0.0548,  0.0045, -0.0386,\n         0.0207,  0.0968,  0.1072, -0.0685,  0.0338,  0.0571, -0.1104, -0.1028,\n        -0.0114,  0.0899,  0.0668, -0.0519, -0.0245, -0.1072,  0.0719, -0.0801,\n        -0.1063, -0.0494,  0.0147,  0.1189,  0.1141, -0.0975, -0.0604, -0.0414,\n         0.0212, -0.0246, -0.0547,  0.1006,  0.0464,  0.0453, -0.0769,  0.0528,\n        -0.0589, -0.0573, -0.1089,  0.0518, -0.0845,  0.0654,  0.0350,  0.0003]), 'meta_learner.transductive_net.classifier.3.weight': tensor([[-0.0365,  0.1013, -0.0063,  ..., -0.0144,  0.0821, -0.0447],\n        [ 0.1084, -0.1173, -0.1131,  ..., -0.0754, -0.0556, -0.0007],\n        [-0.1209,  0.0129,  0.1059,  ...,  0.0854, -0.1111, -0.1106],\n        ...,\n        [-0.0661,  0.0582,  0.0771,  ..., -0.0113, -0.0087, -0.0531],\n        [-0.0405, -0.0381,  0.0268,  ...,  0.0994, -0.1183, -0.0578],\n        [ 0.0076, -0.0720,  0.0225,  ...,  0.0174,  0.0055, -0.0634]]), 'meta_learner.transductive_net.classifier.3.bias': tensor([-0.0734,  0.0280,  0.0554, -0.0562, -0.0363, -0.0194,  0.1017,  0.0641,\n        -0.0622, -0.0509,  0.1020, -0.0943, -0.1001,  0.1124,  0.1190,  0.1113,\n        -0.0784, -0.1197, -0.1044, -0.0196, -0.1242, -0.0388,  0.0270, -0.0045,\n         0.0380,  0.1114, -0.0215,  0.0175,  0.0974, -0.0787,  0.0883, -0.0832]), 'meta_learner.transductive_net.classifier.6.weight': tensor([[ 1.5904e-01,  7.6864e-02,  1.1138e-01,  5.2648e-02,  4.2535e-02,\n         -9.4865e-02,  8.9347e-03,  1.0103e-01, -1.0132e-01,  7.4811e-02,\n         -7.2304e-02,  8.5068e-02,  1.7237e-02,  1.0891e-04,  1.4412e-01,\n          1.5096e-01,  1.2042e-01, -1.6878e-01, -1.8468e-02, -1.5219e-01,\n         -1.3890e-01, -1.2020e-01, -1.3267e-01, -7.8105e-02, -1.5360e-01,\n         -9.0991e-02,  1.5794e-01,  3.3720e-02, -8.4812e-02, -1.7459e-01,\n         -1.3194e-01, -1.4839e-01],\n        [ 1.7365e-01, -1.3064e-01,  4.8513e-02,  9.8107e-02, -1.1753e-02,\n          5.7517e-02, -1.6625e-02, -1.2490e-02,  3.9125e-02,  1.5576e-01,\n          6.0088e-02, -4.2600e-02,  1.2639e-01,  1.5851e-01, -1.5943e-01,\n         -5.4763e-02, -1.3172e-01,  1.3137e-01, -7.2371e-02, -6.7796e-03,\n         -1.0572e-01,  1.6881e-01,  8.1393e-02, -1.2042e-01,  6.5429e-02,\n          1.6687e-01,  1.5890e-01,  8.1704e-02,  4.4793e-02, -1.2313e-01,\n          1.4851e-01,  1.0242e-01]]), 'meta_learner.transductive_net.classifier.6.bias': tensor([-0.0061,  0.1342]), 'meta_learner.transductive_net.self_attention.in_proj_weight': tensor([[ 0.0244,  0.0870, -0.0394,  ...,  0.1415, -0.1226,  0.0976],\n        [ 0.1272,  0.0441, -0.0618,  ..., -0.0691, -0.0469, -0.0407],\n        [-0.0549,  0.1353, -0.1435,  ..., -0.1139, -0.0349, -0.0213],\n        ...,\n        [ 0.1219,  0.0195, -0.1342,  ...,  0.0569,  0.0971, -0.0860],\n        [ 0.0565,  0.0285,  0.1381,  ..., -0.1409, -0.0371, -0.1496],\n        [ 0.0074,  0.0036, -0.0162,  ..., -0.0563, -0.0323,  0.1303]]), 'meta_learner.transductive_net.self_attention.in_proj_bias': tensor([ 1.0284e-02, -5.8615e-03, -5.2693e-03,  1.1847e-02, -5.2795e-03,\n         4.7733e-04,  1.9147e-03,  6.6169e-03,  2.4120e-03,  6.1782e-03,\n        -4.6094e-03, -2.6137e-03,  7.7774e-03,  3.0503e-03, -1.9096e-03,\n        -5.2033e-03, -6.6334e-03, -2.2485e-03,  5.6833e-03, -1.0280e-03,\n        -6.8248e-03,  5.3554e-03,  1.5593e-03, -7.3029e-03,  4.9352e-03,\n         1.6058e-04,  8.1927e-03, -8.4076e-04, -4.5465e-03, -3.1269e-03,\n        -5.5317e-03,  1.4466e-03,  1.7331e-03,  8.7452e-03,  7.5850e-03,\n         6.5564e-03, -1.0499e-02, -5.5567e-03, -5.5366e-04, -5.5981e-03,\n        -7.2531e-03,  6.9415e-05, -1.0338e-02,  6.1532e-04,  6.7022e-04,\n         1.0072e-02,  3.5471e-03,  5.5532e-03, -2.5735e-03, -4.2350e-03,\n        -1.9676e-03, -4.9265e-03, -3.3663e-03, -6.2667e-03, -1.3167e-03,\n         2.8698e-03,  6.0301e-03,  1.6524e-03, -5.5156e-03, -5.2058e-04,\n         1.9369e-03, -5.9319e-03,  2.3508e-03,  3.3422e-03,  7.7970e-06,\n         2.4690e-05, -9.0708e-05, -3.0161e-07,  8.7217e-05, -4.0466e-05,\n         2.0665e-05,  1.8723e-05,  7.8365e-06, -5.7623e-05, -5.4608e-05,\n         1.6945e-04,  6.4574e-05, -3.8951e-05,  7.7977e-05,  2.8929e-05,\n         1.2041e-04,  7.4133e-05, -4.1938e-06, -1.7456e-04,  1.3369e-04,\n        -1.3210e-05,  5.0934e-05,  6.5107e-05,  1.3627e-04,  2.3905e-05,\n        -4.1323e-05,  2.9009e-05, -5.1800e-05, -4.5571e-06, -4.3668e-05,\n         1.7693e-05, -7.0065e-05,  3.3316e-05,  3.0489e-06, -9.7414e-05,\n        -4.0578e-05, -3.2737e-05, -8.2863e-05, -8.8093e-06, -9.0310e-05,\n        -5.8228e-06,  2.6200e-05, -1.2213e-04, -9.6039e-05, -7.9799e-06,\n         7.1659e-05, -2.3406e-05, -8.1829e-05, -3.4364e-06, -8.8667e-05,\n         3.1488e-05,  8.0482e-05, -4.9806e-06,  1.2782e-04, -1.2108e-04,\n        -7.9505e-05,  1.7567e-05,  7.0291e-05, -5.4656e-05,  4.7309e-05,\n        -9.8374e-06,  2.1926e-06, -3.4506e-06,  1.5438e-04, -7.4397e-05,\n         2.9323e-04, -3.0035e-04, -2.5983e-04, -3.5483e-04, -9.6846e-05,\n         2.2553e-04, -6.8377e-05,  2.1112e-04,  4.6149e-06,  8.1142e-04,\n        -4.4103e-04,  2.4565e-04,  4.2548e-04, -4.4394e-04, -1.4787e-05,\n        -3.8685e-04, -3.3151e-04,  1.1026e-04, -5.1697e-05,  6.9450e-04,\n         1.1928e-04,  4.7008e-04, -2.0979e-04, -1.4060e-04,  1.2414e-05,\n        -1.4795e-04, -1.7429e-04,  1.2509e-05, -1.8621e-04, -6.2954e-05,\n        -1.4706e-04, -5.4931e-04,  3.8050e-04, -2.3682e-04,  5.6655e-04,\n         5.0164e-05, -2.7840e-05,  3.7877e-04, -8.0825e-05,  1.8466e-04,\n         4.7299e-04,  3.2935e-04, -6.8339e-05, -6.8168e-04,  7.6875e-05,\n         3.6662e-04, -4.6062e-05,  1.0437e-05,  7.1800e-04, -6.7551e-04,\n        -2.7364e-05,  1.7120e-04,  1.2154e-04, -2.7196e-04,  2.7744e-05,\n        -1.4865e-04, -1.2877e-04,  7.6907e-05, -2.6665e-04,  1.1331e-04,\n         9.1697e-04,  8.4597e-05]), 'meta_learner.transductive_net.self_attention.out_proj.weight': tensor([[ 0.1173,  0.0072,  0.0430,  ..., -0.0559, -0.0386,  0.0852],\n        [ 0.1080, -0.1249, -0.0428,  ...,  0.0527,  0.0616,  0.0961],\n        [ 0.0591, -0.0676, -0.0444,  ..., -0.1032, -0.0708,  0.0552],\n        ...,\n        [ 0.0355,  0.0665,  0.0668,  ..., -0.0333, -0.0518,  0.0091],\n        [ 0.0333, -0.0026,  0.0224,  ...,  0.0797,  0.1043,  0.1055],\n        [ 0.0947,  0.0854, -0.0105,  ...,  0.0716,  0.1024,  0.0250]]), 'meta_learner.transductive_net.self_attention.out_proj.bias': tensor([ 3.7543e-04,  4.6544e-04, -3.6193e-04, -3.2153e-04, -5.1919e-04,\n         3.4499e-05,  2.9625e-04, -4.1153e-04,  1.3192e-04,  5.2743e-04,\n        -4.7986e-04,  6.4941e-04, -3.1778e-05, -7.1137e-04, -1.0375e-03,\n         2.6072e-04, -2.1207e-04, -3.8951e-05,  8.8072e-05, -7.5487e-05,\n        -4.9167e-05, -2.5762e-04,  1.1746e-04, -5.5594e-04,  1.1182e-04,\n        -3.7016e-04,  1.3095e-04,  4.6328e-04,  2.1919e-04, -3.6223e-04,\n        -5.9434e-05, -1.9858e-04,  2.0263e-04,  7.6343e-05,  6.0633e-04,\n         3.6499e-05, -3.1919e-04,  2.6029e-04, -4.4372e-04,  1.2332e-04,\n        -3.0934e-04, -1.3939e-04, -2.9429e-04,  4.7219e-04,  2.5124e-04,\n         1.6769e-04,  1.6923e-04,  1.9697e-04,  1.2263e-05, -4.5477e-04,\n         5.0654e-04, -2.2104e-04, -6.8211e-04,  2.1897e-04, -2.1828e-04,\n         1.4732e-04,  1.0925e-04,  1.1474e-04, -4.4388e-04,  6.3258e-05,\n         8.9362e-04, -2.5194e-04,  1.6614e-04,  2.9113e-04]), 'meta_learner.transductive_net.layer_norm.weight': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'meta_learner.transductive_net.layer_norm.bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}, sample_count=53562, training_loss=np.float64(0.17219316959381104), validation_accuracy=np.float64(0.5200000035762786), validation_precision=0.0, validation_recall=0.0, validation_f1_score=0.0, timestamp=1760269304.03187, model_hash='7f785d95aaa4c7df6410580385292900af13ffe720100cd359eef3f1944cab9b', ipfs_cid='QmfXba43JKcxXTcXVcgyjGWRruCgGLBEn4S69u8qPgfJnF', blockchain_tx_hash='0f040303a92f607fddb6ea4ffff3c1bad8929b08acdd2f3a0a3e21218ea64724')"
      ],
      "aggregation_result": "AggregationResult(round_number=0, aggregated_parameters={}, client_contributions={'client_1': 0.37179829064387526, 'client_2': 0.2711169482259764, 'client_3': 0.3570847611301484}, aggregation_time=0.0005195140838623047, model_hash='model_round_0_1760269313', ipfs_cid='QmZh6CKjdPxfybmeLhXn9GqnLGafdbCmybEGZu53Ph1Nuj', blockchain_tx_hash='5a94f2a07e387c693c4b6e6e3365341940a7156bca671c138befa97907d8f710')",
      "timestamp": 1760269316.2596307
    }
  ],
  "incentive_history": [
    {
      "round_number": 1,
      "total_rewards": 100.0,
      "individual_rewards": {
        "client_1": 35.661661843700514,
        "client_2": 33.3768535804078,
        "client_3": 30.961484575891696
      },
      "contribution_scores": {
        "client_1": 0.7648000048398971,
        "client_2": 0.7158000065088271,
        "client_3": 0.664000002503395
      },
      "timestamp": 1760269316.2596307
    }
  ],
  "client_addresses": {},
  "config": {
    "data_path": "../DNN-EdgeIIoT-dataset.csv",
    "zero_day_attack": "DDoS_UDP",
    "available_attacks": [
      "DDoS_UDP",
      "DDoS_ICMP",
      "SQL_injection",
      "Password",
      "Vulnerability_scanner",
      "DDoS_TCP",
      "DDoS_HTTP",
      "Uploading",
      "Backdoor",
      "Port_Scanning",
      "XSS",
      "Ransomware",
      "MITM",
      "Fingerprinting"
    ],
    "input_dim": 62,
    "hidden_dim": 128,
    "embedding_dim": 64,
    "use_fully_decentralized": false,
    "support_weight": 0.3,
    "test_weight": 0.7,
    "n_way": 2,
    "k_shot": 5,
    "n_query": 15,
    "n_tasks": 10,
    "num_clients": 3,
    "num_rounds": 1,
    "learning_rate": 0.001,
    "ethereum_rpc_url": "http://localhost:8545",
    "contract_address": "0x1234567890123456789012345678901234567890",
    "ipfs_url": "http://localhost:5001",
    "enable_incentives": true,
    "incentive_contract_address": "0x1234567890123456789012345678901234567890",
    "private_key": "0x1234567890123456789012345678901234567890123456789012345678901234",
    "aggregator_address": "0x1234567890123456789012345678901234567890",
    "batch_size": 32,
    "ttt_steps": 200,
    "support_size": 50,
    "query_size": 450,
    "device": "cuda",
    "enable_blockchain": true,
    "max_samples_per_client": 50000,
    "use_data_sampling": true
  }
}