{
  "base_model": {
    "accuracy_mean": 0.5,
    "accuracy_std": 0.00012248673581272932,
    "macro_f1_mean": 0.33333334222400035,
    "macro_f1_std": 0.00013609637218145015,
    "mcc_mean": 0.0,
    "mcc_std": 0.0,
    "confusion_matrix": [
      [
        0,
        1667
      ],
      [
        0,
        1666
      ]
    ],
    "roc_curve": {
      "fpr": [
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0005998800239952009,
        0.0005998800239952009,
        0.0005998800239952009,
        0.0005998800239952009,
        0.0005998800239952009,
        0.0005998800239952009,
        0.0005998800239952009,
        0.0005998800239952009,
        0.0005998800239952009,
        0.0005998800239952009,
        0.0005998800239952009,
        0.0005998800239952009,
        0.0005998800239952009,
        0.0005998800239952009,
        0.0005998800239952009,
        0.0005998800239952009,
        0.0005998800239952009,
        0.0005998800239952009,
        0.0005998800239952009,
        0.0005998800239952009,
        0.03239352129574085,
        0.033593281343731254,
        0.03419316136772645,
        0.03539292141571686,
        0.07318536292741452,
        0.07438512297540492,
        0.08158368326334733,
        0.08278344331133773,
        0.11577684463107378,
        0.11697660467906419,
        0.125374925014997,
        0.1265746850629874,
        0.13617276544691062,
        0.13737252549490103,
        0.14877024595080984,
        0.14997000599880023,
        0.15476904619076184,
        0.15596880623875226,
        0.16196760647870426,
        0.16316736652669467,
        0.1877624475104979,
        0.1889622075584883,
        0.1931613677264547,
        0.1943611277744451,
        0.20095980803839233,
        0.20215956808638272,
        0.20395920815836832,
        0.20935812837432513,
        0.20995800839832032,
        0.21175764847030593,
        0.21415716856628675,
        0.21535692861427713,
        0.22375524895020996,
        0.22495500899820037,
        0.22615476904619075,
        0.22735452909418116,
        0.23155368926214756,
        0.23275344931013797,
        0.23635272945410918,
        0.2375524895020996,
        0.2393521295740852,
        0.24055188962207558,
        0.2489502099580084,
        0.250749850029994,
        0.26094781043791243,
        0.2621475704859028,
        0.2633473305338932,
        0.26454709058188364,
        0.27534493101379726,
        0.27654469106178764,
        0.29634073185362925,
        0.2975404919016197,
        0.29934013197360526,
        0.3005398920215957,
        0.30353929214157166,
        0.3047390521895621,
        0.3101379724055189,
        0.3125374925014997,
        0.3131373725254949,
        0.3143371325734853,
        0.3173365326934613,
        0.31853629274145173,
        0.3215356928614277,
        0.32273545290941813,
        0.34013197360527897,
        0.34133173365326935,
        0.34313137372525493,
        0.34433113377324537,
        0.34493101379724056,
        0.34613077384523094,
        0.35332933413317336,
        0.35452909418116374,
        0.3587282543491302,
        0.36052789442111577,
        0.3677264547090582,
        0.36892621475704857,
        0.3827234553089382,
        0.38392321535692864,
        0.3857228554289142,
        0.38812237552489504,
        0.3893221355728854,
        0.39232153569286143,
        0.3935212957408518,
        0.39892021595680865,
        0.40011997600479904,
        0.40371925614877024,
        0.40491901619676063,
        0.4097180563887223,
        0.41091781643671266,
        0.41151769646070785,
        0.41151769646070785,
        0.41271745650869823,
        0.41571685662867425,
        0.41811637672465507,
        0.41931613677264545,
        0.4205158968206359,
        0.42231553689262147,
        0.42711457708458306,
        0.4289142171565687,
        0.4301139772045591,
        0.43431313737252547,
        0.4355128974205159,
        0.4373125374925015,
        0.4385122975404919,
        0.4511097780443911,
        0.4523095380923815,
        0.4553089382123575,
        0.45650869826034796,
        0.46130773845230955,
        0.46250749850029993,
        0.46970605878824234,
        0.4709058188362327,
        0.47750449910017995,
        0.4787042591481704,
        0.47990401919616077,
        0.48110377924415115,
        0.4829034193161368,
        0.48410317936412717,
        0.504499100179964,
        0.5062987402519497,
        0.5200959808038392,
        0.5212957408518296,
        0.5320935812837433,
        0.5332933413317337,
        0.5404919016196761,
        0.5416916616676665,
        0.5584883023395321,
        0.5596880623875224,
        0.5806838632273545,
        0.5818836232753449,
        0.590881823635273,
        0.5920815836832634,
        0.6022795440911818,
        0.6034793041391722,
        0.6106778644271146,
        0.611877624475105,
        0.6154769046190762,
        0.6166766646670666,
        0.6226754649070186,
        0.623875224955009,
        0.6244751049790042,
        0.626874625074985,
        0.641871625674865,
        0.6430713857228554,
        0.6484703059388123,
        0.6496700659868027,
        0.6562687462507498,
        0.6574685062987402,
        0.6652669466106779,
        0.6664667066586683,
        0.6754649070185963,
        0.6766646670665867,
        0.6826634673065387,
        0.6838632273545291,
        0.6844631073785243,
        0.6856628674265147,
        0.6916616676664668,
        0.6928614277144571,
        0.7030593881223756,
        0.704259148170366,
        0.713257348530294,
        0.7150569886022795,
        0.7270545890821836,
        0.728254349130174,
        0.7348530293941212,
        0.7360527894421116,
        0.7408518296340731,
        0.7420515896820636,
        0.7426514697060588,
        0.7438512297540492,
        0.74625074985003,
        0.7474505098980204,
        0.758248350329934,
        0.7594481103779244,
        0.7606478704259149,
        0.7618476304739052,
        0.7654469106178764,
        0.7666466706658668,
        0.7768446310737852,
        0.7786442711457708,
        0.7798440311937612,
        0.788242351529694,
        0.7894421115776845,
        0.7906418716256749,
        0.7918416316736653,
        0.7954409118176364,
        0.7966406718656269,
        0.7990401919616077,
        0.8002399520095981,
        0.8134373125374925,
        0.8158368326334733,
        0.8230353929214157,
        0.8254349130173965,
        0.8440311937612478,
        0.8452309538092382,
        0.9010197960407919,
        0.9022195560887822,
        0.9040191961607679,
        0.9064187162567486,
        0.9070185962807439,
        0.9082183563287343,
        0.9118176364727054,
        0.9130173965206959,
        0.9160167966406718,
        0.9178164367126574,
        0.9256148770245951,
        0.9268146370725855,
        1.0
      ],
      "tpr": [
        0.0,
        0.001800720288115246,
        0.006602641056422569,
        0.007202881152460984,
        0.01680672268907563,
        0.022809123649459785,
        0.03361344537815126,
        0.03481392557022809,
        0.04981992797118848,
        0.061224489795918366,
        0.07082833133253301,
        0.07382953181272509,
        0.08043217286914765,
        0.09003601440576231,
        0.10324129651860744,
        0.10444177671068428,
        0.11764705882352941,
        0.12484993997599039,
        0.12785114045618248,
        0.14105642256902762,
        0.14645858343337334,
        0.15486194477791115,
        0.1566626650660264,
        0.1608643457382953,
        0.16686674669867949,
        0.17466986794717887,
        0.17647058823529413,
        0.1872749099639856,
        0.19387755102040816,
        0.19867947178871548,
        0.20108043217286914,
        0.2070828331332533,
        0.2112845138055222,
        0.21308523409363744,
        0.21968787515006002,
        0.22509003601440578,
        0.226890756302521,
        0.234093637454982,
        0.24069627851140457,
        0.24909963985594238,
        0.24969987995198079,
        0.25990396158463386,
        0.2635054021608643,
        0.2695078031212485,
        0.2707082833133253,
        0.2755102040816326,
        0.2785114045618247,
        0.2809123649459784,
        0.2815126050420168,
        0.28691476590636256,
        0.2917166866746699,
        0.297719087635054,
        0.29891956782713086,
        0.30732292917166865,
        0.3085234093637455,
        0.31932773109243695,
        0.3199279711884754,
        0.32653061224489793,
        0.33733493397358943,
        0.3385354141656663,
        0.34633853541416565,
        0.35354141656662663,
        0.3547418967587035,
        0.3589435774309724,
        0.3637454981992797,
        0.36914765906362546,
        0.3709483793517407,
        0.37214885954381755,
        0.37695078031212487,
        0.382953181272509,
        0.3859543817527011,
        0.3877551020408163,
        0.39315726290516206,
        0.3943577430972389,
        0.3949579831932773,
        0.39615846338535415,
        0.3985594237695078,
        0.4057623049219688,
        0.40756302521008403,
        0.414765906362545,
        0.4177671068427371,
        0.42016806722689076,
        0.42136854741896757,
        0.42316926770708285,
        0.4255702280912365,
        0.42737094837935174,
        0.4327731092436975,
        0.4339735894357743,
        0.4381752701080432,
        0.43937575030012005,
        0.44417767106842737,
        0.4489795918367347,
        0.4495798319327731,
        0.4507803121248499,
        0.4531812725090036,
        0.45558223289315725,
        0.4579831932773109,
        0.46218487394957986,
        0.4657863145258103,
        0.46938775510204084,
        0.47418967587034816,
        0.4759903961584634,
        0.4819927971188475,
        0.48259303721488594,
        0.4849939975990396,
        0.48679471788715484,
        0.4891956782713085,
        0.4897959183673469,
        0.49339735894357745,
        0.4957983193277311,
        0.4963985594237695,
        0.49759903961584634,
        0.49939975990396157,
        0.5018007202881153,
        0.503001200480192,
        0.5054021608643458,
        0.5066026410564226,
        0.5096038415366146,
        0.5108043217286915,
        0.5126050420168067,
        0.517406962785114,
        0.5180072028811524,
        0.5192076830732293,
        0.5198079231692677,
        0.521608643457383,
        0.5228091236494598,
        0.5240096038415366,
        0.5264105642256903,
        0.5282112845138055,
        0.5306122448979592,
        0.5312124849939976,
        0.5366146458583433,
        0.5372148859543817,
        0.539015606242497,
        0.5402160864345739,
        0.5414165666266506,
        0.5438175270108043,
        0.5474189675870348,
        0.5480192076830732,
        0.5498199279711885,
        0.5522208883553421,
        0.5528211284513805,
        0.5540216086434574,
        0.556422569027611,
        0.5576230492196879,
        0.56062424969988,
        0.5642256902761105,
        0.5654261704681873,
        0.5672268907563025,
        0.5696278511404562,
        0.570828331332533,
        0.5720288115246098,
        0.5744297719087635,
        0.575030012004802,
        0.5804321728691476,
        0.5828331332533013,
        0.5852340936374549,
        0.5858343337334934,
        0.5882352941176471,
        0.5894357743097239,
        0.5912364945978391,
        0.5936374549819928,
        0.5960384153661464,
        0.5972388955582233,
        0.5978391356542617,
        0.6002400960384153,
        0.6014405762304922,
        0.6020408163265306,
        0.6044417767106842,
        0.6080432172869148,
        0.6086434573829532,
        0.6134453781512605,
        0.6158463385354142,
        0.617046818727491,
        0.620048019207683,
        0.6224489795918368,
        0.6260504201680672,
        0.6284513805522209,
        0.6296518607442977,
        0.631452581032413,
        0.634453781512605,
        0.6350540216086434,
        0.6374549819927972,
        0.6380552220888356,
        0.6398559423769508,
        0.6410564225690276,
        0.6422569027611045,
        0.6446578631452581,
        0.6458583433373349,
        0.6476590636254502,
        0.6482593037214885,
        0.6530612244897959,
        0.6542617046818727,
        0.6566626650660264,
        0.6578631452581032,
        0.6584633853541416,
        0.6608643457382953,
        0.6614645858343338,
        0.6632653061224489,
        0.6644657863145258,
        0.6656662665066027,
        0.6662665066026411,
        0.6680672268907563,
        0.6710684273709484,
        0.673469387755102,
        0.6752701080432173,
        0.6770708283313326,
        0.680672268907563,
        0.6818727490996399,
        0.6854741896758704,
        0.687875150060024,
        0.6920768307322929,
        0.6956782713085234,
        0.6974789915966386,
        0.698079231692677,
        0.6998799519807923,
        0.7004801920768308,
        0.7016806722689075,
        0.7022809123649459,
        0.7034813925570228,
        0.7040816326530612,
        0.7064825930372148,
        0.7070828331332533,
        0.7082833133253301,
        0.7166866746698679,
        0.7178871548619448,
        0.71968787515006,
        0.7208883553421368,
        0.7250900360144058,
        0.7274909963985594,
        0.7298919567827131,
        0.7310924369747899,
        0.7316926770708283,
        0.734093637454982,
        0.7352941176470589,
        0.737094837935174,
        0.7382953181272509,
        0.7460984393757503,
        0.7472989195678271,
        0.7478991596638656,
        0.7490996398559424,
        0.7509003601440576,
        0.7527010804321729,
        0.7539015606242497,
        0.7545018007202882,
        0.7557022809123649,
        0.7575030012004802,
        0.7593037214885955,
        0.7617046818727491,
        0.762905162064826,
        0.7635054021608644,
        0.7647058823529411,
        0.7665066026410564,
        0.7677070828331333,
        0.7821128451380552,
        0.7833133253301321,
        0.7965186074429772,
        0.7977190876350541,
        0.8067226890756303,
        0.8103241296518607,
        0.8175270108043218,
        0.8187274909963985,
        0.8253301320528211,
        0.826530612244898,
        0.8277310924369747,
        0.8289315726290516,
        0.8361344537815126,
        0.8373349339735895,
        0.8487394957983193,
        0.8499399759903962,
        0.8613445378151261,
        0.8625450180072028,
        0.8673469387755102,
        0.8673469387755102,
        0.8811524609843937,
        0.8823529411764706,
        0.8865546218487395,
        0.8937575030012005,
        0.9321728691476591,
        0.9597839135654261,
        0.9651860744297719,
        0.9717887154861945,
        0.9789915966386554,
        0.9837935174069627,
        0.985594237695078,
        0.9867947178871549,
        0.9903961584633854,
        0.9915966386554622,
        0.9933973589435774,
        0.9957983193277311,
        0.9963985594237695,
        0.9987995198079231,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        0.9993997599039616,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0
      ],
      "thresholds": [
        Infinity,
        0.5826796293258667,
        0.5826795697212219,
        0.5826795101165771,
        0.5826794505119324,
        0.5826793909072876,
        0.5826793313026428,
        0.582679271697998,
        0.5826792120933533,
        0.5826791524887085,
        0.5826790928840637,
        0.582679033279419,
        0.5826789736747742,
        0.5826789140701294,
        0.5826788544654846,
        0.5826787948608398,
        0.5826787352561951,
        0.5826786756515503,
        0.5826786160469055,
        0.5826785564422607,
        0.582678496837616,
        0.5826784372329712,
        0.5826783776283264,
        0.5826783180236816,
        0.5826782584190369,
        0.5826781988143921,
        0.5826781392097473,
        0.5826780796051025,
        0.5826780200004578,
        0.582677960395813,
        0.5826779007911682,
        0.5826777815818787,
        0.5826777219772339,
        0.5826776623725891,
        0.5826776027679443,
        0.5826775431632996,
        0.5826774835586548,
        0.58267742395401,
        0.5826773643493652,
        0.5826773047447205,
        0.5826772451400757,
        0.5826771855354309,
        0.5826771259307861,
        0.5826770663261414,
        0.5826770067214966,
        0.5826769471168518,
        0.582676887512207,
        0.5826768279075623,
        0.5826767683029175,
        0.5826767086982727,
        0.5826766490936279,
        0.5826765894889832,
        0.5826765298843384,
        0.5826764106750488,
        0.582676351070404,
        0.5826761722564697,
        0.582676112651825,
        0.5826760530471802,
        0.5826759338378906,
        0.5826758742332458,
        0.5826758146286011,
        0.5826756954193115,
        0.5826756358146667,
        0.582675576210022,
        0.5826754570007324,
        0.5826753377914429,
        0.5826752781867981,
        0.5826752185821533,
        0.5826751589775085,
        0.5826750993728638,
        0.582675039768219,
        0.5826749801635742,
        0.5826749205589294,
        0.5826748609542847,
        0.5826748013496399,
        0.5826747417449951,
        0.5826746821403503,
        0.5826746225357056,
        0.5826745629310608,
        0.5826744437217712,
        0.5826743841171265,
        0.5826743245124817,
        0.5826742649078369,
        0.5826742053031921,
        0.5826741456985474,
        0.5826740860939026,
        0.5826740264892578,
        0.582673966884613,
        0.5826739072799683,
        0.5826738476753235,
        0.5826737880706787,
        0.5826736688613892,
        0.5826736092567444,
        0.5826735496520996,
        0.5826734900474548,
        0.5826733708381653,
        0.5826733112335205,
        0.5826732516288757,
        0.5826731324195862,
        0.5826730132102966,
        0.5826727151870728,
        0.582672655582428,
        0.5826725363731384,
        0.5826724767684937,
        0.5826724171638489,
        0.5826723575592041,
        0.5826722979545593,
        0.5826722383499146,
        0.5826721787452698,
        0.582672119140625,
        0.5826720595359802,
        0.5826719999313354,
        0.5826719403266907,
        0.5826718807220459,
        0.5826718211174011,
        0.5826717615127563,
        0.5826717019081116,
        0.5826716423034668,
        0.5826715230941772,
        0.5826714634895325,
        0.5826714038848877,
        0.5826713442802429,
        0.5826712846755981,
        0.5826712250709534,
        0.5826711654663086,
        0.582671046257019,
        0.5826709270477295,
        0.5826708674430847,
        0.5826708078384399,
        0.5826707482337952,
        0.5826706886291504,
        0.5826705098152161,
        0.5826704502105713,
        0.5826703906059265,
        0.5826703310012817,
        0.5826702117919922,
        0.5826701521873474,
        0.5826699137687683,
        0.5826697945594788,
        0.582669734954834,
        0.5826695561408997,
        0.5826694965362549,
        0.5826694369316101,
        0.5826693773269653,
        0.5826693177223206,
        0.5826692581176758,
        0.5826691389083862,
        0.5826690793037415,
        0.5826690196990967,
        0.5826689600944519,
        0.5826689004898071,
        0.5826685428619385,
        0.5826684832572937,
        0.5826684236526489,
        0.5826682448387146,
        0.582668125629425,
        0.5826680064201355,
        0.5826679468154907,
        0.5826676487922668,
        0.5826675295829773,
        0.5826674699783325,
        0.582667350769043,
        0.5826672315597534,
        0.5826671123504639,
        0.5826669931411743,
        0.5826669335365295,
        0.5826668739318848,
        0.5826667547225952,
        0.5826666355133057,
        0.5826665163040161,
        0.5826664566993713,
        0.5826660394668579,
        0.5826659798622131,
        0.5826658010482788,
        0.582665741443634,
        0.5826656222343445,
        0.5826655626296997,
        0.5826654434204102,
        0.582665205001831,
        0.5826651453971863,
        0.5826650857925415,
        0.5826650261878967,
        0.582664966583252,
        0.5826649069786072,
        0.5826646685600281,
        0.5826646089553833,
        0.5826644897460938,
        0.5826641917228699,
        0.5826641321182251,
        0.5826640725135803,
        0.5826640129089355,
        0.5826634764671326,
        0.582663357257843,
        0.5826632976531982,
        0.5826632380485535,
        0.5826631784439087,
        0.5826631188392639,
        0.5826629400253296,
        0.58266282081604,
        0.5826624035835266,
        0.582662045955658,
        0.5826619863510132,
        0.5826616883277893,
        0.5826611518859863,
        0.5826610326766968,
        0.5826609134674072,
        0.5826606154441833,
        0.5826603174209595,
        0.5826601982116699,
        0.5826599597930908,
        0.5826595425605774,
        0.5826589465141296,
        0.5826586484909058,
        0.582658588886261,
        0.5826584100723267,
        0.5826582908630371,
        0.5826581716537476,
        0.5826581120491028,
        0.582658052444458,
        0.5826578736305237,
        0.5826577544212341,
        0.5826574563980103,
        0.5826572179794312,
        0.5826571583747864,
        0.5826552510261536,
        0.582655131816864,
        0.5826545357704163,
        0.5826544761657715,
        0.5826537609100342,
        0.5826534032821655,
        0.5826526284217834,
        0.5826525092124939,
        0.58265221118927,
        0.5826520919799805,
        0.5826520323753357,
        0.5826516151428223,
        0.5826515555381775,
        0.5826495289802551,
        0.5826494693756104,
        0.5826489925384521,
        0.5826489329338074,
        0.5826485753059387,
        0.5826483964920044,
        0.5826481580734253,
        0.5826480388641357,
        0.582647979259491,
        0.5826476216316223,
        0.5826469659805298,
        0.5826455354690552,
        0.5826454162597656,
        0.5826452970504761,
        0.5826445817947388,
        0.5826438069343567,
        0.5826436877250671,
        0.5826376676559448,
        0.5826376080513,
        0.5826306939125061,
        0.5826305747032166,
        0.582628071308136,
        0.5826272964477539,
        0.5826249718666077,
        0.5826247334480286,
        0.5826215147972107,
        0.5826212167739868,
        0.5826175808906555,
        0.5826174020767212,
        0.5826090574264526,
        0.5826072692871094,
        0.5825873017311096,
        0.5825870633125305,
        0.5825609564781189,
        0.5825531482696533,
        0.5825111269950867,
        0.5824961066246033,
        0.5824174284934998,
        0.5824129581451416,
        0.5823988318443298,
        0.5822769403457642,
        0.5822768807411194,
        0.5822768211364746,
        0.5822767615318298,
        0.5822767019271851,
        0.5822766423225403,
        0.5822765827178955,
        0.5822765231132507,
        0.582276463508606,
        0.5822763442993164,
        0.5822762846946716,
        0.5822762250900269,
        0.5822761654853821,
        0.5822761058807373,
        0.5822758078575134,
        0.5822755098342896,
        0.5820624828338623,
        0.5820623636245728,
        0.5820621848106384,
        0.5820621252059937,
        0.5820001363754272,
        0.5819990038871765,
        0.5819914937019348,
        0.5819911956787109,
        0.581950843334198,
        0.5819495916366577,
        0.581942617893219,
        0.5819418430328369,
        0.5819329619407654,
        0.5819324851036072,
        0.5819266438484192,
        0.5819252729415894,
        0.5819225311279297,
        0.5819220542907715,
        0.5819187164306641,
        0.5819186568260193,
        0.5819060206413269,
        0.5819056630134583,
        0.5819015502929688,
        0.5819011330604553,
        0.5818960666656494,
        0.5818958878517151,
        0.5818945169448853,
        0.5818933844566345,
        0.5818929076194763,
        0.5818922519683838,
        0.5818908214569092,
        0.5818906426429749,
        0.5818846225738525,
        0.5818843245506287,
        0.5818840265274048,
        0.5818832516670227,
        0.5818799138069153,
        0.5818793773651123,
        0.5818756222724915,
        0.5818745493888855,
        0.5818726420402527,
        0.5818725228309631,
        0.5818668603897095,
        0.581866443157196,
        0.5818564295768738,
        0.581855297088623,
        0.5818541646003723,
        0.5818539261817932,
        0.5818442702293396,
        0.58184415102005,
        0.5818228721618652,
        0.5818227529525757,
        0.5818210244178772,
        0.5818201303482056,
        0.5818173885345459,
        0.5818169116973877,
        0.5818123817443848,
        0.5818116664886475,
        0.5818116068840027,
        0.5818113088607788,
        0.5818099975585938,
        0.581809937953949,
        0.5818082094192505,
        0.5818080306053162,
        0.5817959308624268,
        0.5817948579788208,
        0.5817943215370178,
        0.5817941427230835,
        0.5817935466766357,
        0.581792950630188,
        0.5817879438400269,
        0.5817872881889343,
        0.5817854404449463,
        0.5817847847938538,
        0.5817821025848389,
        0.5817816853523254,
        0.581773042678833,
        0.5817728042602539,
        0.5817727446556091,
        0.5817710757255554,
        0.5817708373069763,
        0.5817693471908569,
        0.5817691087722778,
        0.5817675590515137,
        0.5817670822143555,
        0.5817661285400391,
        0.5817658305168152,
        0.5817638635635376,
        0.5817636251449585,
        0.5817634463310242,
        0.5817632675170898,
        0.581762969493866,
        0.5817621946334839,
        0.5817617774009705,
        0.5817610621452332,
        0.5817607045173645,
        0.5817601680755615,
        0.5817576050758362,
        0.581756591796875,
        0.5817563533782959,
        0.5817542672157288,
        0.5817540287971497,
        0.5817536115646362,
        0.5817535519599915,
        0.5817486047744751,
        0.5817483067512512,
        0.5817466974258423,
        0.5817457437515259,
        0.5817440152168274,
        0.5817421674728394,
        0.5817394256591797,
        0.5817393660545349,
        0.5817360281944275,
        0.5817356109619141,
        0.5817352533340454,
        0.5817351341247559,
        0.5817347168922424,
        0.5817343592643738,
        0.5817192792892456,
        0.581719160079956,
        0.5817095041275024,
        0.5817083716392517,
        0.5817002058029175,
        0.5816999077796936,
        0.5816948413848877,
        0.5816938281059265,
        0.5816781520843506,
        0.5816780924797058,
        0.5816619396209717,
        0.581661581993103,
        0.5816543102264404,
        0.5816540718078613,
        0.5816477537155151,
        0.5816476345062256,
        0.5816407203674316,
        0.5816404223442078,
        0.5816372036933899,
        0.5816369652748108,
        0.5816312432289124,
        0.581631064414978,
        0.581630527973175,
        0.5816301703453064,
        0.5816138982772827,
        0.5816137194633484,
        0.581609308719635,
        0.5816090106964111,
        0.5816031098365784,
        0.5816028714179993,
        0.5815967321395874,
        0.5815960168838501,
        0.5815891623497009,
        0.5815886855125427,
        0.5815853476524353,
        0.581584632396698,
        0.5815843939781189,
        0.5815834403038025,
        0.5815777778625488,
        0.5815774202346802,
        0.5815662145614624,
        0.5815658569335938,
        0.5815548300743103,
        0.5815547704696655,
        0.5815432071685791,
        0.5815429091453552,
        0.5815396308898926,
        0.5815393924713135,
        0.5815364718437195,
        0.5815364122390747,
        0.5815362334251404,
        0.5815359950065613,
        0.5815346837043762,
        0.5815344452857971,
        0.5815272331237793,
        0.5815268754959106,
        0.5815262198448181,
        0.5815251469612122,
        0.5815216302871704,
        0.5815215110778809,
        0.5815142393112183,
        0.5815139412879944,
        0.5815137624740601,
        0.5815086960792542,
        0.581508457660675,
        0.5815078020095825,
        0.5815074443817139,
        0.5815059542655945,
        0.5815050601959229,
        0.5815020799636841,
        0.581501841545105,
        0.5814931392669678,
        0.5814929604530334,
        0.5814852714538574,
        0.5814850926399231,
        0.581471860408783,
        0.5814717411994934,
        0.5813772678375244,
        0.5813772082328796,
        0.5813767313957214,
        0.5813760161399841,
        0.5813758373260498,
        0.5813755393028259,
        0.5813730955123901,
        0.5813723802566528,
        0.5813705325126648,
        0.5813702940940857,
        0.5813652276992798,
        0.5813644528388977,
        0.5810024738311768
      ]
    },
    "roc_auc": 0.9996737747288478,
    "optimal_threshold": 0.5822755098342896,
    "precision_mean": 0.49984998499849986,
    "recall_mean": 1.0
  },
  "ttt_model": {
    "accuracy_mean": 1.0,
    "accuracy_std": 0.0,
    "macro_f1_mean": 1.0,
    "macro_f1_std": 0.0,
    "mcc_mean": 1.0,
    "mcc_std": 0.0,
    "confusion_matrix": [
      [
        500,
        0
      ],
      [
        0,
        500
      ]
    ],
    "roc_curve": {
      "fpr": [
        0.0,
        0.0,
        0.266,
        0.272,
        0.274,
        1.0
      ],
      "tpr": [
        0.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0
      ],
      "thresholds": [
        Infinity,
        1.0,
        4.203895392974451e-45,
        2.802596928649634e-45,
        1.401298464324817e-45,
        0.0
      ]
    },
    "roc_auc": 1.0,
    "optimal_threshold": 1.0,
    "ttt_adaptation_data": {
      "steps": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50,
        51,
        52,
        53,
        54,
        55,
        56,
        57,
        58,
        59,
        60,
        61,
        62,
        63,
        64,
        65,
        66,
        67,
        68,
        69,
        70,
        71,
        72,
        73,
        74,
        75,
        76,
        77,
        78,
        79,
        80,
        81,
        82,
        83,
        84,
        85,
        86,
        87,
        88,
        89,
        90,
        91,
        92,
        93,
        94,
        95,
        96,
        97,
        98,
        99,
        100,
        101,
        102,
        103,
        104,
        105,
        106,
        107,
        108,
        109,
        110,
        111,
        112,
        113,
        114,
        115,
        116,
        117,
        118,
        119,
        120,
        121,
        122,
        123,
        124,
        125,
        126,
        127,
        128,
        129,
        130,
        131,
        132,
        133,
        134,
        135,
        136,
        137,
        138,
        139,
        140,
        141,
        142,
        143,
        144,
        145,
        146,
        147,
        148,
        149,
        150,
        151,
        152,
        153,
        154,
        155,
        156,
        157,
        158,
        159,
        160,
        161,
        162,
        163,
        164,
        165,
        166,
        167,
        168,
        169,
        170,
        171,
        172,
        173,
        174,
        175,
        176,
        177,
        178,
        179,
        180,
        181,
        182,
        183,
        184,
        185,
        186,
        187,
        188,
        189,
        190,
        191,
        192,
        193,
        194,
        195,
        196,
        197,
        198,
        199
      ],
      "total_losses": [
        0.7730451822280884,
        0.7695493698120117,
        0.7683411836624146,
        0.7669275999069214,
        0.7638387680053711,
        0.7602172493934631,
        0.7575559616088867,
        0.7445544004440308,
        0.7298066020011902,
        0.7077250480651855,
        0.6801154017448425,
        0.6512181758880615,
        0.6067085266113281,
        0.5768905282020569,
        0.5336256623268127,
        0.4834449291229248,
        0.44602322578430176,
        0.3965209126472473,
        0.3520728647708893,
        0.3140279948711395,
        0.2650109529495239,
        0.22795367240905762,
        0.18929550051689148,
        0.15452876687049866,
        0.12807844579219818,
        0.10544521361589432,
        0.09089154005050659,
        0.07438253611326218,
        0.06697984784841537,
        0.062496814876794815,
        0.04663251340389252,
        0.03904632106423378,
        0.036961060017347336,
        0.04466895014047623,
        0.03244718909263611,
        0.041082412004470825,
        0.019726837053894997,
        0.015233978629112244,
        0.013280121609568596,
        0.0075693996623158455,
        0.007622698321938515,
        0.007373469416052103,
        0.00578009570017457,
        0.020132046192884445,
        0.005026299972087145,
        0.005846102721989155,
        0.0035618487745523453,
        0.0027979358565062284,
        0.003146363189443946,
        0.0072835711762309074,
        0.0029839472845196724,
        0.004019258543848991,
        0.0016556850168853998,
        0.002492703963071108,
        0.0213167741894722,
        0.0011397727066650987,
        0.008195724338293076,
        0.0022736615501344204,
        0.0019911429844796658,
        0.001950848032720387,
        0.0019128136336803436,
        0.0013673233333975077,
        0.0013764100149273872,
        0.0010888590477406979,
        0.0013756697298958898,
        0.0011822523083537817,
        0.0010337203275412321,
        0.005908499471843243,
        0.0015656051691621542,
        0.001279359799809754,
        0.001308297272771597,
        0.0025786079932004213,
        0.0008103458676487207,
        0.0015357567463070154,
        0.0006282024551182985,
        0.0008373612072318792,
        0.0008786596008576453,
        0.0012619881890714169,
        0.0012078190920874476,
        0.0010839616879820824,
        0.001243564416654408,
        0.0011254909913986921,
        0.0015756008215248585,
        0.0015568159287795424,
        0.001854480942711234,
        0.0009572464623488486,
        0.0007011356065049767,
        0.0006022957386448979,
        0.0006811679340898991,
        0.0009139464818872511,
        0.0008233758853748441,
        0.0014272849075496197,
        0.0004893703735433519,
        0.0011269799433648586,
        0.0007451522978954017,
        0.0009323466802015901,
        0.0004311454831622541,
        0.0021346635185182095,
        0.0010233349166810513,
        0.006901797838509083,
        0.0010145234409719706,
        0.0010327998315915465,
        0.0008451956673525274,
        0.015512475743889809,
        0.0009425937896594405,
        0.0007425684598274529,
        0.0010335850529372692,
        0.0005561756552197039,
        0.0005883603589609265,
        0.0006131216650828719,
        0.000858758925460279,
        0.0008972501382231712,
        0.000532332924194634,
        0.0009647926199249923,
        0.0005590977380052209,
        0.0005491089541465044,
        0.0005243520135991275,
        0.0011562021682038903,
        0.0005831492017023265,
        0.0005605532787740231,
        0.0006369737675413489,
        0.0004845318617299199,
        0.0009975619614124298,
        0.0005191974341869354,
        0.0016882773488759995,
        0.0006536109140142798,
        0.000677762960549444,
        0.001275933114811778,
        0.0009341865661554039,
        0.000372344336938113,
        0.0005749266128987074,
        0.0006498495349660516,
        0.0008101623971015215,
        0.0007378425798378885,
        0.0004392692062538117,
        0.0006214441964402795,
        0.0006564968498423696,
        0.0031357828993350267,
        0.000816734042018652,
        0.00033407751470804214,
        0.0004205702571198344,
        0.0004823477065656334,
        0.0006000575376674533,
        0.0005380274378694594,
        0.0008615137776359916,
        0.0012774710776284337,
        0.0009174366714432836,
        0.0008823364041745663,
        0.0009525896748527884,
        0.0004013072466477752,
        0.0004121524398215115,
        0.0003318340750411153,
        0.0005716015584766865,
        0.0009748439188115299,
        0.00047334757982753217,
        0.0010564151452854276,
        0.000633448944427073,
        0.0009511696989648044,
        0.0014126608148217201,
        0.000308511866023764,
        0.0006826272583566606,
        0.00044328483636491,
        0.00044568622251972556,
        0.00040182791417464614,
        0.0003055199340451509,
        0.0004390465037431568,
        0.00043539481703191996,
        0.0006064831977710128,
        0.0003838660195469856,
        0.0014696395955979824,
        0.00030846981098875403,
        0.000535779632627964,
        0.000293998746201396,
        0.0007411869592033327,
        0.0005020666285417974,
        0.0005338327027857304,
        0.0006630674470216036,
        0.0013922625221312046,
        0.0012354593491181731,
        0.0005257335724309087,
        0.0005616900161840022,
        0.000724283920135349,
        0.0003649130230769515,
        0.0005218267324380577,
        0.0004866600502282381,
        0.0005146649200469255,
        0.020102484151721,
        0.0009772065095603466,
        0.0007142203394323587,
        0.00047426900709979236,
        0.0005963888252153993,
        0.00030423179850913584,
        0.000545147224329412,
        0.00028566073160618544,
        0.0008687893277965486,
        0.0012394743971526623,
        0.0015271009178832173,
        0.0004917456535622478,
        0.0003727608418557793,
        0.0006292458856478333
      ],
      "support_losses": [
        0.7049375772476196,
        0.7010517716407776,
        0.6997069120407104,
        0.6981440782546997,
        0.6950076818466187,
        0.6913004517555237,
        0.688611626625061,
        0.6756258606910706,
        0.6609682440757751,
        0.639002799987793,
        0.6117106676101685,
        0.5832334160804749,
        0.5394285321235657,
        0.5107195973396301,
        0.4688616096973419,
        0.4209676682949066,
        0.38665658235549927,
        0.34003230929374695,
        0.2993796467781067,
        0.26599979400634766,
        0.22268395125865936,
        0.1891353875398636,
        0.15581950545310974,
        0.12624746561050415,
        0.10511086881160736,
        0.08521658182144165,
        0.07405850291252136,
        0.06071612983942032,
        0.05599666386842728,
        0.05444304645061493,
        0.03930041566491127,
        0.03280285745859146,
        0.03178589418530464,
        0.04087543115019798,
        0.02871602214872837,
        0.03845050930976868,
        0.017347924411296844,
        0.012785032391548157,
        0.01095238234847784,
        0.0054434072226285934,
        0.005919529590755701,
        0.005705354269593954,
        0.004122747574001551,
        0.01897572912275791,
        0.00394411338493228,
        0.004593038000166416,
        0.0027107272762805223,
        0.002047112211585045,
        0.002413347130641341,
        0.006580676883459091,
        0.0020904315169900656,
        0.0031664404086768627,
        0.0010665670270100236,
        0.001778993522748351,
        0.020716508850455284,
        0.0007746913470327854,
        0.00771411694586277,
        0.0016314786626026034,
        0.0013782550813630223,
        0.0014570190105587244,
        0.0013531638542190194,
        0.0011396536137908697,
        0.0010306505719199777,
        0.0005506374291144311,
        0.001043476047925651,
        0.000804252689704299,
        0.0007578345248475671,
        0.005619795527309179,
        0.0012272398453205824,
        0.0009206014219671488,
        0.0009867476765066385,
        0.0020161077845841646,
        0.000567209383007139,
        0.0011251607211306691,
        0.00034971078275702894,
        0.0004200636758469045,
        0.0006465209880843759,
        0.0009354545618407428,
        0.0009325849823653698,
        0.0008516306988894939,
        0.0009791302727535367,
        0.0008538735564798117,
        0.0013664962025359273,
        0.0011419841321185231,
        0.00158958719111979,
        0.0007261326536536217,
        0.0003790202899836004,
        0.00038333164411596954,
        0.0005503065185621381,
        0.0007961606024764478,
        0.0005886054132133722,
        0.0011321468045935035,
        0.00023262180911842734,
        0.0009325062274001539,
        0.0004757236165460199,
        0.0007734356913715601,
        0.00028627176652662456,
        0.00193287234287709,
        0.0008451588219031692,
        0.006716208998113871,
        0.000843015150167048,
        0.0007040037307888269,
        0.0007131468737497926,
        0.015338004566729069,
        0.0007056556059978902,
        0.0004983081016689539,
        0.0008163691381923854,
        0.0003781421692110598,
        0.00047246547183021903,
        0.0003691798192448914,
        0.0007389584789052606,
        0.0006428163032978773,
        0.00037305199657566845,
        0.0008192532695829868,
        0.00032797909807413816,
        0.0002863744448404759,
        0.00024293614842463285,
        0.0010178423253819346,
        0.0004639801918528974,
        0.00034463198971934617,
        0.00036596169229596853,
        0.0002921184350270778,
        0.0007013931171968579,
        0.00039460413972847164,
        0.0015302457613870502,
        0.00037056952714920044,
        0.0005211873212829232,
        0.0011148008052259684,
        0.0007246671593748033,
        0.0002568030613474548,
        0.0004961425438523293,
        0.0003903811448253691,
        0.0005467173177748919,
        0.0005506700836122036,
        0.00025030801771208644,
        0.0004532760940492153,
        0.0005683297640644014,
        0.0030135572887957096,
        0.0005590501241385937,
        0.00011266361980233341,
        0.00026442157104611397,
        0.00041931646410375834,
        0.0004086057306267321,
        0.0003963828203268349,
        0.0005567714106291533,
        0.0011368010891601443,
        0.0005940224509686232,
        0.0006920478772372007,
        0.0008000970701687038,
        0.0002711627457756549,
        0.00014339124027173966,
        0.00021630221453960985,
        0.00039382220711559057,
        0.0007899753982201219,
        0.00021964497864246368,
        0.0009443681919947267,
        0.0004839407920371741,
        0.0007452951977029443,
        0.0012422095751389861,
        0.0002204034390160814,
        0.0003861321310978383,
        0.00029890896985307336,
        0.00034424461773596704,
        0.00026081668329425156,
        0.00014249479863792658,
        0.00033804276608861983,
        0.00025655110948719084,
        0.0003571774868760258,
        0.00026765192160382867,
        0.0013424995122477412,
        0.00015344757412094623,
        0.0003334403154440224,
        0.00020699799642898142,
        0.0006133298738859594,
        0.00040560640627518296,
        0.0003820148704107851,
        0.00041179050458595157,
        0.0011203321628272533,
        0.0011289314134046435,
        0.00042208959348499775,
        0.0003293790796305984,
        0.000574117642827332,
        0.0002796440094243735,
        0.0002780244976747781,
        0.0003888622741214931,
        0.0003568533284123987,
        0.019987044855952263,
        0.0008232600521296263,
        0.0002920093829743564,
        0.0003718685475178063,
        0.0004431904817465693,
        0.00018633117724675685,
        0.0004488678532652557,
        0.00012209151464048773,
        0.0006224113749340177,
        0.0011062135454267263,
        0.0013974999310448766,
        0.0003775281656999141,
        0.0002917504170909524,
        0.00041339820018038154
      ],
      "consistency_losses": [
        0.681076169013977,
        0.6849759221076965,
        0.686342716217041,
        0.6878352165222168,
        0.688310980796814,
        0.689167857170105,
        0.6894435286521912,
        0.6892856955528259,
        0.6883836984634399,
        0.6872223615646362,
        0.6840471625328064,
        0.6798478364944458,
        0.6727997064590454,
        0.6617094874382019,
        0.6476407051086426,
        0.6247727274894714,
        0.5936663746833801,
        0.5648860931396484,
        0.5269320607185364,
        0.4802820086479187,
        0.42326998710632324,
        0.3881829082965851,
        0.33475998044013977,
        0.28281307220458984,
        0.22967581450939178,
        0.20228633284568787,
        0.1683303266763687,
        0.13666407763957977,
        0.10983183979988098,
        0.08053767681121826,
        0.07332097738981247,
        0.06243463233113289,
        0.051751650869846344,
        0.03793517127633095,
        0.03731168434023857,
        0.026319019496440887,
        0.023789124563336372,
        0.02448945865035057,
        0.023277388885617256,
        0.02125992625951767,
        0.017031684517860413,
        0.01668114960193634,
        0.016573479399085045,
        0.011563172563910484,
        0.010821864008903503,
        0.012530644424259663,
        0.008511214517056942,
        0.007508235517889261,
        0.007330160588026047,
        0.007028942462056875,
        0.008935156278312206,
        0.008528182283043861,
        0.005891180131584406,
        0.007137103471904993,
        0.0060026515275239944,
        0.003650813829153776,
        0.0048160734586417675,
        0.0064218295738101006,
        0.006128878798335791,
        0.004938289988785982,
        0.005596498027443886,
        0.002276697661727667,
        0.003457594197243452,
        0.005382216535508633,
        0.003321936819702387,
        0.0037799954880028963,
        0.0027588584925979376,
        0.0028870408423244953,
        0.0033836537040770054,
        0.003587583312764764,
        0.0032154961954802275,
        0.005625002086162567,
        0.002431364730000496,
        0.004105960484594107,
        0.0027849168982356787,
        0.004172975663095713,
        0.0023213860113173723,
        0.003265336388722062,
        0.002752340864390135,
        0.0023233103565871716,
        0.0026443416718393564,
        0.0027161738835275173,
        0.0020910464227199554,
        0.004148317500948906,
        0.002648936817422509,
        0.002311138203367591,
        0.003221153514459729,
        0.0021896406542509794,
        0.0013086139224469662,
        0.0011778585612773895,
        0.002347704488784075,
        0.0029513807967305183,
        0.002567485673353076,
        0.0019447366939857602,
        0.002694286871701479,
        0.0015891095390543342,
        0.0014487371081486344,
        0.0020179119892418385,
        0.0017817610641941428,
        0.0018558894516900182,
        0.0017150826752185822,
        0.0032879605423659086,
        0.0013204880524426699,
        0.0017447140999138355,
        0.0023693819530308247,
        0.002442603465169668,
        0.002172159031033516,
        0.0017803347436711192,
        0.0011589491041377187,
        0.002439418574795127,
        0.0011980043491348624,
        0.0025443383492529392,
        0.0015928094508126378,
        0.0014553936198353767,
        0.002311186632141471,
        0.0026273448020219803,
        0.002814158797264099,
        0.0013835985446348786,
        0.0011916900984942913,
        0.002159212715923786,
        0.002710120752453804,
        0.001924134325236082,
        0.0029616879764944315,
        0.0012459326535463333,
        0.0015803163405507803,
        0.0028304136358201504,
        0.0015657565090805292,
        0.001611322513781488,
        0.0020951940678060055,
        0.0011554127559065819,
        0.0007878405158407986,
        0.00259468425065279,
        0.0026344507932662964,
        0.0018717250786721706,
        0.0018896118272095919,
        0.001681680791079998,
        0.0008816709159873426,
        0.0012222564546391368,
        0.0025768387131392956,
        0.002214138861745596,
        0.0015614868607372046,
        0.0006303124828264117,
        0.00191451795399189,
        0.001416446059010923,
        0.003047423902899027,
        0.0014066995354369283,
        0.003234142204746604,
        0.001902885502204299,
        0.0015249258140102029,
        0.0013014449505135417,
        0.002687611849978566,
        0.0011553185759112239,
        0.001777793513610959,
        0.0018486850894987583,
        0.002537026070058346,
        0.0011204695329070091,
        0.0014950815821066499,
        0.0020587448962032795,
        0.0017045126296579838,
        0.0008810843573883176,
        0.002964951330795884,
        0.0014437586069107056,
        0.0010144158732146025,
        0.0014101124834269285,
        0.001630251295864582,
        0.0010100372601300478,
        0.0017884369008243084,
        0.0024930573999881744,
        0.0011621409794315696,
        0.0012714006006717682,
        0.0015502225141972303,
        0.002023393288254738,
        0.0008700075559318066,
        0.0012785708531737328,
        0.0009646022808738053,
        0.0015181780327111483,
        0.0025127693079411983,
        0.0027193028945475817,
        0.0010652790078893304,
        0.0010364396730437875,
        0.0023231091909110546,
        0.0015016625402495265,
        0.0008526900201104581,
        0.0024380222894251347,
        0.0009779776446521282,
        0.0015781159745529294,
        0.0011543913278728724,
        0.0015394650399684906,
        0.0042221094481647015,
        0.0010240045376121998,
        0.0015319834928959608,
        0.0011790061835199594,
        0.000962793652433902,
        0.0016356923151761293,
        0.0024637794122099876,
        0.001332608750090003,
        0.0012960094027221203,
        0.0011421748204156756,
        0.0008101043058559299,
        0.0021584765054285526
      ]
    },
    "precision_mean": 1.0,
    "recall_mean": 1.0
  },
  "dataset_info": {
    "name": "Edge-IIoTset",
    "total_samples": 243134,
    "evaluated_samples": 10000,
    "features": 61,
    "attack_types": 15,
    "zero_day_attack": "DDoS_UDP",
    "zero_day_stats": {
      "zero_day_attack": "DDoS_UDP",
      "zero_day_samples": 121567,
      "zero_day_percentage": 20.168960900416927,
      "total_attack_samples": 602743,
      "normal_samples": 1615643,
      "total_samples": 2218386,
      "available_attacks": [
        "Normal",
        "DDoS_UDP",
        "DDoS_ICMP",
        "SQL_injection",
        "Password",
        "Vulnerability_scanner",
        "DDoS_TCP",
        "DDoS_HTTP",
        "Uploading",
        "Backdoor",
        "Port_Scanning",
        "XSS",
        "Ransomware",
        "Fingerprinting",
        "MITM"
      ]
    }
  },
  "final_global_model": {
    "accuracy": 0.5,
    "f1_score": 0.3333333333333333,
    "mcc": 0.0,
    "roc_auc": 0.9994071999999999,
    "optimal_threshold": "0.58231777",
    "roc_curve": {
      "fpr": [
        0.0,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0004,
        0.0008,
        0.0008,
        0.0008,
        0.0008,
        0.0008,
        0.0008,
        0.0008,
        0.0008,
        0.0008,
        0.0008,
        0.0008,
        0.0008,
        0.0012,
        0.0012,
        0.0012,
        0.0012,
        0.0016,
        0.0016,
        0.0016,
        0.0016,
        0.0016,
        0.0016,
        0.0016,
        0.0016,
        0.0016,
        0.0016,
        0.0016,
        0.0016,
        0.0016,
        0.0016,
        0.0016,
        0.0016,
        0.0016,
        0.0016,
        0.0016,
        0.0016,
        0.004,
        0.004,
        0.0048,
        0.0056,
        0.0264,
        0.0264,
        0.0468,
        0.0476,
        0.0492,
        0.05,
        0.0516,
        0.0524,
        0.054,
        0.0548,
        0.0552,
        0.056,
        0.0648,
        0.0656,
        0.0672,
        0.0684,
        0.0688,
        0.0696,
        0.0736,
        0.0744,
        0.0768,
        0.0784,
        0.0864,
        0.0864,
        0.0876,
        0.0884,
        0.0932,
        0.094,
        0.0968,
        0.0976,
        0.0984,
        0.0996,
        0.1004,
        0.1036,
        0.1044,
        0.1052,
        0.1064,
        0.108,
        0.1088,
        0.1116,
        0.1124,
        0.1296,
        0.1304,
        0.1324,
        0.1332,
        0.1352,
        0.136,
        0.1388,
        0.1396,
        0.1408,
        0.1416,
        0.1424,
        0.1432,
        0.1452,
        0.146,
        0.1476,
        0.1488,
        0.1512,
        0.152,
        0.156,
        0.1568,
        0.1572,
        0.158,
        0.1584,
        0.1592,
        0.1616,
        0.1624,
        0.166,
        0.1672,
        0.1684,
        0.1692,
        0.1708,
        0.1724,
        0.1772,
        0.178,
        0.1812,
        0.182,
        0.1836,
        0.1844,
        0.1848,
        0.1864,
        0.188,
        0.1888,
        0.19,
        0.1908,
        0.1948,
        0.1956,
        0.1968,
        0.1976,
        0.198,
        0.1996,
        0.2004,
        0.2036,
        0.2044,
        0.2064,
        0.2072,
        0.2088,
        0.2096,
        0.21,
        0.2108,
        0.2136,
        0.2168,
        0.2192,
        0.2204,
        0.2236,
        0.2248,
        0.2256,
        0.2272,
        0.2292,
        0.23,
        0.2324,
        0.2332,
        0.2372,
        0.238,
        0.2384,
        0.2392,
        0.24,
        0.2408,
        0.2448,
        0.2456,
        0.2496,
        0.2504,
        0.2532,
        0.254,
        0.2564,
        0.2572,
        0.2628,
        0.2636,
        0.2656,
        0.2664,
        0.2676,
        0.2684,
        0.2692,
        0.27,
        0.2712,
        0.272,
        0.2748,
        0.276,
        0.2768,
        0.2812,
        0.282,
        0.2828,
        0.2836,
        0.288,
        0.2888,
        0.2972,
        0.2988,
        0.2996,
        0.3004,
        0.3036,
        0.3044,
        0.3064,
        0.3072,
        0.308,
        0.3088,
        0.3092,
        0.31,
        0.316,
        0.3172,
        0.3176,
        0.3188,
        0.3224,
        0.324,
        0.3276,
        0.3284,
        0.33,
        0.3308,
        0.3364,
        0.338,
        0.3412,
        0.342,
        0.3432,
        0.3444,
        0.3468,
        0.3476,
        0.3492,
        0.35,
        0.3512,
        0.352,
        0.3656,
        0.3664,
        0.3668,
        0.3676,
        0.3784,
        0.3792,
        0.3804,
        0.3812,
        0.3816,
        0.3824,
        0.3856,
        0.3868,
        0.3936,
        0.3944,
        0.3948,
        0.3956,
        0.4016,
        0.4024,
        0.4048,
        0.4064,
        0.4088,
        0.4096,
        0.4116,
        0.4128,
        0.42,
        0.4208,
        0.4216,
        0.4224,
        0.4284,
        0.4292,
        0.4312,
        0.432,
        0.4416,
        0.4424,
        0.4432,
        0.444,
        0.4444,
        0.4452,
        0.4512,
        0.452,
        0.4528,
        0.4536,
        0.456,
        0.4568,
        0.4572,
        0.458,
        0.4608,
        0.4616,
        0.4644,
        0.466,
        0.4668,
        0.4676,
        0.47,
        0.4708,
        0.4716,
        0.4724,
        0.4748,
        0.4756,
        0.4772,
        0.478,
        0.4792,
        0.4808,
        0.482,
        0.4836,
        0.4884,
        0.4892,
        0.494,
        0.4948,
        0.496,
        0.4968,
        0.4984,
        0.4992,
        0.5008,
        0.5016,
        0.5024,
        0.5032,
        0.5036,
        0.5052,
        0.5056,
        0.5064,
        0.5096,
        0.5104,
        0.5108,
        0.5116,
        0.5184,
        0.5192,
        0.5208,
        0.5216,
        0.5232,
        0.524,
        0.5268,
        0.5276,
        0.5284,
        0.5292,
        0.5352,
        0.536,
        0.5396,
        0.5404,
        0.5424,
        0.5432,
        0.5444,
        0.5452,
        0.5468,
        0.548,
        0.5516,
        0.5524,
        0.5672,
        0.568,
        0.574,
        0.5748,
        0.5852,
        0.586,
        0.5904,
        0.5912,
        0.5916,
        0.5924,
        0.5992,
        0.6,
        0.61,
        0.6108,
        0.6116,
        0.6124,
        0.6176,
        0.6184,
        0.6248,
        0.6256,
        0.6296,
        0.6304,
        0.634,
        0.6348,
        0.64,
        0.6408,
        0.642,
        0.6428,
        0.644,
        0.6448,
        0.6464,
        0.648,
        0.6484,
        0.6492,
        0.654,
        0.6548,
        0.6576,
        0.66,
        0.6616,
        0.6624,
        0.668,
        0.6688,
        0.6696,
        0.6704,
        0.6716,
        0.6724,
        0.6804,
        0.6812,
        0.6852,
        0.686,
        0.7008,
        0.7016,
        0.7064,
        0.7072,
        0.7096,
        0.7104,
        0.7128,
        0.7136,
        0.7148,
        0.7212,
        0.7228,
        0.7256,
        0.7264,
        0.7312,
        0.732,
        0.7328,
        0.7336,
        0.7344,
        0.7352,
        0.7436,
        0.7444,
        0.7476,
        0.7484,
        0.7488,
        0.7496,
        0.7532,
        0.754,
        0.7544,
        0.756,
        0.758,
        0.7588,
        0.7592,
        0.76,
        0.768,
        0.7688,
        0.7732,
        0.774,
        0.776,
        0.7772,
        0.7804,
        0.7812,
        0.7816,
        0.7828,
        0.7836,
        0.7848,
        0.7864,
        0.7892,
        0.79,
        0.7904,
        0.7936,
        0.794,
        0.7948,
        0.796,
        0.7968,
        0.7992,
        0.8004,
        0.8008,
        0.8016,
        0.8064,
        0.8072,
        0.8132,
        0.814,
        0.8188,
        0.8196,
        0.8248,
        0.8264,
        0.8344,
        0.836,
        0.8408,
        0.8416,
        0.842,
        0.8428,
        0.8444,
        0.8452,
        0.8656,
        0.8664,
        0.8876,
        0.8884,
        0.89,
        0.8908,
        0.8912,
        0.892,
        0.8924,
        0.8932,
        0.9004,
        0.9012,
        0.9092,
        0.91,
        0.9116,
        0.9124,
        0.9132,
        0.9144,
        0.9152,
        0.916,
        0.9176,
        0.9184,
        0.9188,
        0.9196,
        0.9224,
        0.9232,
        0.924,
        0.9248,
        0.9252,
        0.926,
        0.9268,
        0.9276,
        0.9304,
        0.9312,
        0.9316,
        0.9324,
        0.9328,
        0.9336,
        0.9372,
        0.938,
        0.9384,
        0.9392,
        0.9416,
        0.9424,
        0.9452,
        0.946,
        0.9488,
        0.9496,
        0.9508,
        0.9516,
        0.9588,
        0.9596,
        0.964,
        0.9648,
        0.966,
        0.9672,
        1.0
      ],
      "tpr": [
        0.0,
        0.0,
        0.0004,
        0.0012,
        0.0048,
        0.0104,
        0.0124,
        0.0188,
        0.0264,
        0.0368,
        0.0376,
        0.0512,
        0.064,
        0.0656,
        0.08,
        0.0896,
        0.0996,
        0.1004,
        0.1112,
        0.1256,
        0.1368,
        0.14,
        0.148,
        0.1548,
        0.168,
        0.1772,
        0.1824,
        0.1896,
        0.1904,
        0.1972,
        0.2016,
        0.2036,
        0.2148,
        0.2184,
        0.2244,
        0.2276,
        0.234,
        0.2376,
        0.2464,
        0.2488,
        0.2572,
        0.2684,
        0.2688,
        0.278,
        0.2816,
        0.282,
        0.2864,
        0.2896,
        0.2952,
        0.298,
        0.3024,
        0.3064,
        0.3108,
        0.3132,
        0.3204,
        0.3252,
        0.332,
        0.34,
        0.3408,
        0.3456,
        0.3488,
        0.3492,
        0.3536,
        0.356,
        0.3608,
        0.3612,
        0.3656,
        0.368,
        0.3712,
        0.3728,
        0.3756,
        0.3828,
        0.3832,
        0.386,
        0.388,
        0.394,
        0.3956,
        0.4,
        0.4032,
        0.4044,
        0.406,
        0.4084,
        0.4096,
        0.4124,
        0.4144,
        0.4188,
        0.4192,
        0.4232,
        0.424,
        0.4272,
        0.4284,
        0.4316,
        0.432,
        0.4348,
        0.4352,
        0.4376,
        0.4416,
        0.442,
        0.448,
        0.4532,
        0.4548,
        0.4552,
        0.458,
        0.46,
        0.4624,
        0.4628,
        0.4668,
        0.4716,
        0.4724,
        0.4756,
        0.4784,
        0.4808,
        0.4824,
        0.4844,
        0.4856,
        0.49,
        0.4948,
        0.4952,
        0.496,
        0.4984,
        0.4992,
        0.5008,
        0.5028,
        0.5052,
        0.5096,
        0.5116,
        0.5124,
        0.5152,
        0.5172,
        0.52,
        0.5216,
        0.5228,
        0.5248,
        0.5296,
        0.53,
        0.5324,
        0.5336,
        0.5344,
        0.5348,
        0.5356,
        0.5372,
        0.5396,
        0.54,
        0.5424,
        0.5436,
        0.5452,
        0.5484,
        0.55,
        0.552,
        0.556,
        0.5596,
        0.5604,
        0.562,
        0.5628,
        0.5644,
        0.5648,
        0.568,
        0.5684,
        0.572,
        0.574,
        0.5764,
        0.5812,
        0.582,
        0.5852,
        0.5872,
        0.588,
        0.59,
        0.5924,
        0.5932,
        0.5948,
        0.5956,
        0.5968,
        0.5996,
        0.6012,
        0.6024,
        0.6048,
        0.6056,
        0.6088,
        0.61,
        0.612,
        0.6136,
        0.6156,
        0.6168,
        0.6176,
        0.62,
        0.6208,
        0.6232,
        0.6252,
        0.626,
        0.6272,
        0.6276,
        0.6288,
        0.6304,
        0.6328,
        0.6344,
        0.6356,
        0.6372,
        0.6384,
        0.6412,
        0.642,
        0.6444,
        0.6448,
        0.6464,
        0.6472,
        0.6484,
        0.6492,
        0.6508,
        0.6544,
        0.6552,
        0.6556,
        0.6568,
        0.6576,
        0.6596,
        0.6604,
        0.6624,
        0.6636,
        0.6644,
        0.6648,
        0.6676,
        0.668,
        0.6704,
        0.672,
        0.6728,
        0.6732,
        0.6744,
        0.6748,
        0.6756,
        0.6772,
        0.678,
        0.6784,
        0.6796,
        0.68,
        0.6808,
        0.6816,
        0.6828,
        0.6832,
        0.6848,
        0.6856,
        0.6864,
        0.6868,
        0.688,
        0.6884,
        0.6892,
        0.6908,
        0.692,
        0.6924,
        0.6944,
        0.6976,
        0.6984,
        0.6988,
        0.6996,
        0.7,
        0.7008,
        0.702,
        0.7028,
        0.7044,
        0.7048,
        0.706,
        0.7064,
        0.7072,
        0.7076,
        0.7084,
        0.7096,
        0.7112,
        0.7116,
        0.7136,
        0.7148,
        0.7152,
        0.716,
        0.7164,
        0.7172,
        0.7176,
        0.7184,
        0.7196,
        0.7212,
        0.7232,
        0.7236,
        0.7244,
        0.726,
        0.7264,
        0.728,
        0.7284,
        0.7292,
        0.7304,
        0.7312,
        0.7316,
        0.7332,
        0.7344,
        0.7352,
        0.7364,
        0.738,
        0.7396,
        0.74,
        0.7408,
        0.7412,
        0.7428,
        0.7436,
        0.7444,
        0.7456,
        0.7464,
        0.7472,
        0.7496,
        0.7504,
        0.7508,
        0.7532,
        0.7536,
        0.7544,
        0.7556,
        0.7564,
        0.7576,
        0.7584,
        0.7588,
        0.7596,
        0.7612,
        0.762,
        0.7632,
        0.7644,
        0.7656,
        0.7672,
        0.7684,
        0.7688,
        0.7696,
        0.7712,
        0.772,
        0.7736,
        0.7752,
        0.7772,
        0.778,
        0.7796,
        0.7804,
        0.7828,
        0.7836,
        0.784,
        0.7852,
        0.7856,
        0.7864,
        0.7868,
        0.7876,
        0.7896,
        0.7912,
        0.792,
        0.7928,
        0.7932,
        0.7956,
        0.7972,
        0.7984,
        0.7992,
        0.8008,
        0.8064,
        0.8076,
        0.8084,
        0.8092,
        0.8128,
        0.8144,
        0.8152,
        0.816,
        0.8172,
        0.818,
        0.8212,
        0.822,
        0.8228,
        0.8236,
        0.8304,
        0.8312,
        0.8316,
        0.8324,
        0.8328,
        0.834,
        0.8348,
        0.8356,
        0.8404,
        0.8412,
        0.842,
        0.8428,
        0.8468,
        0.8468,
        0.852,
        0.8528,
        0.8556,
        0.8564,
        0.8596,
        0.8604,
        0.8652,
        0.866,
        0.8768,
        0.8776,
        0.8828,
        0.8828,
        0.8904,
        0.8912,
        0.9004,
        0.9004,
        0.9008,
        0.9016,
        0.9132,
        0.9484,
        0.9616,
        0.9756,
        0.978,
        0.982,
        0.9852,
        0.9864,
        0.9884,
        0.99,
        0.9912,
        0.992,
        0.994,
        0.9948,
        0.9968,
        0.9976,
        0.9988,
        0.9988,
        0.9992,
        0.9992,
        0.9992,
        0.9992,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        0.9996,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0
      ],
      "thresholds": [
        Infinity,
        0.5830540657043457,
        0.5826944708824158,
        0.5826943516731262,
        0.5826942920684814,
        0.5826942324638367,
        0.5826941728591919,
        0.5826941132545471,
        0.5826940536499023,
        0.5826939940452576,
        0.5826939344406128,
        0.582693874835968,
        0.5826938152313232,
        0.5826937556266785,
        0.5826936960220337,
        0.5826936364173889,
        0.5826935768127441,
        0.5826935172080994,
        0.5826934576034546,
        0.5826933979988098,
        0.582693338394165,
        0.5826932787895203,
        0.5826932191848755,
        0.5826931595802307,
        0.5826930999755859,
        0.5826929807662964,
        0.5826929211616516,
        0.5826928615570068,
        0.5826928019523621,
        0.5826927423477173,
        0.5826926827430725,
        0.5826926231384277,
        0.582692563533783,
        0.5826925039291382,
        0.5826924443244934,
        0.5826923847198486,
        0.5826923251152039,
        0.5826922655105591,
        0.5826922059059143,
        0.5826921463012695,
        0.5826920866966248,
        0.5826919674873352,
        0.5826919078826904,
        0.5826918482780457,
        0.5826917886734009,
        0.5826917290687561,
        0.5826916694641113,
        0.5826916098594666,
        0.5826915502548218,
        0.582691490650177,
        0.5826914310455322,
        0.5826913714408875,
        0.5826913118362427,
        0.5826911926269531,
        0.5826910734176636,
        0.582690954208374,
        0.5826908946037292,
        0.5826908349990845,
        0.5826907753944397,
        0.5826907157897949,
        0.5826906561851501,
        0.5826905965805054,
        0.5826905369758606,
        0.5826904773712158,
        0.582690417766571,
        0.5826903581619263,
        0.5826902985572815,
        0.5826902389526367,
        0.5826901793479919,
        0.5826901197433472,
        0.5826900601387024,
        0.5826899409294128,
        0.5826898813247681,
        0.5826898217201233,
        0.5826897621154785,
        0.5826897025108337,
        0.582689642906189,
        0.5826895833015442,
        0.5826895236968994,
        0.5826894640922546,
        0.5826893448829651,
        0.5826892852783203,
        0.5826892256736755,
        0.5826891660690308,
        0.582689106464386,
        0.5826890468597412,
        0.5826889872550964,
        0.5826889276504517,
        0.5826888680458069,
        0.5826888084411621,
        0.5826887488365173,
        0.5826886892318726,
        0.5826886296272278,
        0.582688570022583,
        0.5826885104179382,
        0.5826884508132935,
        0.5826883912086487,
        0.5826883316040039,
        0.5826882719993591,
        0.5826882123947144,
        0.5826881527900696,
        0.5826880931854248,
        0.58268803358078,
        0.5826879739761353,
        0.5826879143714905,
        0.5826878547668457,
        0.5826877951622009,
        0.5826876759529114,
        0.5826876163482666,
        0.5826875567436218,
        0.582687497138977,
        0.5826874375343323,
        0.5826873183250427,
        0.582687258720398,
        0.5826871991157532,
        0.5826871395111084,
        0.5826870203018188,
        0.5826869606971741,
        0.5826869010925293,
        0.5826867818832397,
        0.582686722278595,
        0.5826866626739502,
        0.5826866030693054,
        0.5826864838600159,
        0.5826864242553711,
        0.5826863646507263,
        0.5826863050460815,
        0.5826862454414368,
        0.582686185836792,
        0.5826861262321472,
        0.5826860070228577,
        0.5826859474182129,
        0.5826858878135681,
        0.582685649394989,
        0.5826855897903442,
        0.5826855301856995,
        0.5826854705810547,
        0.5826854109764099,
        0.5826853513717651,
        0.5826852917671204,
        0.5826852321624756,
        0.582685112953186,
        0.5826850533485413,
        0.5826849937438965,
        0.5826848745346069,
        0.5826848149299622,
        0.5826847553253174,
        0.5826846957206726,
        0.5826846361160278,
        0.5826845765113831,
        0.5826845169067383,
        0.5826844573020935,
        0.5826843976974487,
        0.582684338092804,
        0.5826842784881592,
        0.5826842188835144,
        0.5826840996742249,
        0.5826840400695801,
        0.5826839804649353,
        0.5826839208602905,
        0.5826838612556458,
        0.5826836824417114,
        0.5826836228370667,
        0.5826835036277771,
        0.5826834440231323,
        0.5826833844184875,
        0.582683265209198,
        0.5826831459999084,
        0.5826830863952637,
        0.5826830267906189,
        0.5826829671859741,
        0.5826829075813293,
        0.5826828479766846,
        0.5826827883720398,
        0.582682728767395,
        0.5826826095581055,
        0.5826825499534607,
        0.5826824903488159,
        0.5826823711395264,
        0.5826823115348816,
        0.5826822519302368,
        0.5826821327209473,
        0.5826820731163025,
        0.5826820135116577,
        0.5826818943023682,
        0.5826818346977234,
        0.5826817154884338,
        0.5826816558837891,
        0.5826815366744995,
        0.5826814770698547,
        0.58268141746521,
        0.5826813578605652,
        0.5826812386512756,
        0.5826811790466309,
        0.5826811194419861,
        0.5826809406280518,
        0.582680881023407,
        0.5826807022094727,
        0.5826805830001831,
        0.5826805233955383,
        0.5826804637908936,
        0.5826804041862488,
        0.5826802253723145,
        0.5826801061630249,
        0.5826799869537354,
        0.5826798677444458,
        0.582679808139801,
        0.5826795697212219,
        0.5826794505119324,
        0.5826793909072876,
        0.5826793313026428,
        0.582679271697998,
        0.5826792120933533,
        0.5826791524887085,
        0.5826790928840637,
        0.582679033279419,
        0.5826789736747742,
        0.5826789140701294,
        0.5826788544654846,
        0.5826787948608398,
        0.5826785564422607,
        0.582678496837616,
        0.5826784372329712,
        0.5826783776283264,
        0.5826783180236816,
        0.5826782584190369,
        0.5826781988143921,
        0.5826780796051025,
        0.5826780200004578,
        0.5826779007911682,
        0.5826778411865234,
        0.5826777815818787,
        0.5826777219772339,
        0.5826775431632996,
        0.58267742395401,
        0.5826773643493652,
        0.5826773047447205,
        0.5826770663261414,
        0.5826769471168518,
        0.582676887512207,
        0.5826768279075623,
        0.5826767683029175,
        0.5826767086982727,
        0.5826766490936279,
        0.5826765298843384,
        0.5826764702796936,
        0.5826764106750488,
        0.5826762318611145,
        0.5826761722564697,
        0.582676112651825,
        0.5826760530471802,
        0.5826759934425354,
        0.5826759338378906,
        0.5826758742332458,
        0.5826757550239563,
        0.582675576210022,
        0.5826755166053772,
        0.5826754570007324,
        0.5826753377914429,
        0.5826752781867981,
        0.5826751589775085,
        0.582675039768219,
        0.5826748013496399,
        0.5826746821403503,
        0.5826746225357056,
        0.5826745629310608,
        0.5826744437217712,
        0.5826743841171265,
        0.5826743245124817,
        0.5826742053031921,
        0.5826741456985474,
        0.5826737880706787,
        0.5826736688613892,
        0.5826735496520996,
        0.5826733708381653,
        0.5826733112335205,
        0.582673192024231,
        0.5826731324195862,
        0.5826730132102966,
        0.5826728940010071,
        0.5826727747917175,
        0.5826727151870728,
        0.582672655582428,
        0.5826723575592041,
        0.5826722979545593,
        0.5826721787452698,
        0.5826717615127563,
        0.5826717019081116,
        0.582671582698822,
        0.5826715230941772,
        0.5826712250709534,
        0.5826711058616638,
        0.5826708078384399,
        0.5826707482337952,
        0.5826705694198608,
        0.5826703906059265,
        0.5826700925827026,
        0.5826698541641235,
        0.5826696157455444,
        0.5826694965362549,
        0.5826689004898071,
        0.5826687216758728,
        0.582668662071228,
        0.5826686024665833,
        0.5826683640480042,
        0.5826683044433594,
        0.5826682448387146,
        0.582668125629425,
        0.5826680064201355,
        0.582667887210846,
        0.5826678276062012,
        0.5826677680015564,
        0.5826676487922668,
        0.5826671123504639,
        0.5826669335365295,
        0.5826666355133057,
        0.5826665759086609,
        0.5826658010482788,
        0.5826654434204102,
        0.5826653242111206,
        0.5826650857925415,
        0.5826650261878967,
        0.5826646685600281,
        0.5826646089553833,
        0.5826641917228699,
        0.5826639533042908,
        0.582663357257843,
        0.5826632976531982,
        0.58266282081604,
        0.5826627016067505,
        0.5826622247695923,
        0.5826621651649475,
        0.5826619863510132,
        0.5826615691184998,
        0.582661509513855,
        0.5826614499092102,
        0.5826613306999207,
        0.5826612710952759,
        0.5826603770256042,
        0.5826601386070251,
        0.5826598405838013,
        0.5826596617698669,
        0.5826595425605774,
        0.5826590061187744,
        0.5826582908630371,
        0.5826581716537476,
        0.582658052444458,
        0.5826574563980103,
        0.5826547145843506,
        0.5826546549797058,
        0.5826544761657715,
        0.5826539993286133,
        0.5826517939567566,
        0.5826517343521118,
        0.5826511979103088,
        0.5826509594917297,
        0.5826507210731506,
        0.582650363445282,
        0.5826488733291626,
        0.5826486945152283,
        0.5826480388641357,
        0.5826479196548462,
        0.5826447606086731,
        0.582644522190094,
        0.5826443433761597,
        0.5826440453529358,
        0.5826439261436462,
        0.5826438665390015,
        0.5826432704925537,
        0.5826427936553955,
        0.582639217376709,
        0.5826379656791687,
        0.5826355814933777,
        0.5826355218887329,
        0.5826308727264404,
        0.5826307535171509,
        0.5826260447502136,
        0.5826256275177002,
        0.5826188325881958,
        0.5826185941696167,
        0.5826150178909302,
        0.5826136469841003,
        0.5826089978218079,
        0.5826084017753601,
        0.5825690031051636,
        0.5825688242912292,
        0.5825464129447937,
        0.5825463533401489,
        0.5824683308601379,
        0.5824635624885559,
        0.582404375076294,
        0.5823841691017151,
        0.5823296904563904,
        0.5823201537132263,
        0.5823200941085815,
        0.5823200345039368,
        0.582319974899292,
        0.5823199152946472,
        0.5823198556900024,
        0.5823197960853577,
        0.5823197364807129,
        0.5823196768760681,
        0.5823196172714233,
        0.5823195576667786,
        0.5823194980621338,
        0.582319438457489,
        0.5823193788528442,
        0.5823193192481995,
        0.582318902015686,
        0.5823186635971069,
        0.5823177695274353,
        0.5822331309318542,
        0.582232654094696,
        0.582219660282135,
        0.5822120308876038,
        0.5821471810340881,
        0.5821464657783508,
        0.5821089744567871,
        0.5821083188056946,
        0.5821024775505066,
        0.5821017026901245,
        0.5820973515510559,
        0.5820969343185425,
        0.5820935964584351,
        0.5820935368537903,
        0.5820932984352112,
        0.5820922255516052,
        0.5820815563201904,
        0.5820813775062561,
        0.582080602645874,
        0.5820800065994263,
        0.5820798873901367,
        0.5820796489715576,
        0.5820738673210144,
        0.582072377204895,
        0.5820685029029846,
        0.5820677280426025,
        0.582055926322937,
        0.582054853439331,
        0.5820530652999878,
        0.5820527076721191,
        0.5820485353469849,
        0.5820481181144714,
        0.5820459723472595,
        0.582045316696167,
        0.5820435881614685,
        0.5820430517196655,
        0.582042932510376,
        0.582040011882782,
        0.5820396542549133,
        0.5820388793945312,
        0.5820376873016357,
        0.582036554813385,
        0.5820364356040955,
        0.5820326805114746,
        0.5820324420928955,
        0.582019031047821,
        0.5820186734199524,
        0.5820174217224121,
        0.5820168852806091,
        0.5820155739784241,
        0.5820151567459106,
        0.5820130705833435,
        0.5820125341415405,
        0.5820122957229614,
        0.5820119380950928,
        0.5820115208625793,
        0.5820112824440002,
        0.5820099115371704,
        0.5820098519325256,
        0.5820091962814331,
        0.5820087790489197,
        0.5820077061653137,
        0.582007646560669,
        0.5820053219795227,
        0.5820047855377197,
        0.582004725933075,
        0.5820046067237854,
        0.5820045471191406,
        0.5820041298866272,
        0.5820021033287048,
        0.5820015072822571,
        0.5819998383522034,
        0.581999659538269,
        0.581998884677887,
        0.5819987654685974,
        0.5819975733757019,
        0.5819970965385437,
        0.5819929838180542,
        0.5819928646087646,
        0.5819916725158691,
        0.5819913744926453,
        0.5819901823997498,
        0.5819894671440125,
        0.5819894075393677,
        0.5819891691207886,
        0.5819888710975647,
        0.5819882750511169,
        0.5819873809814453,
        0.5819872617721558,
        0.5819856524467468,
        0.5819854736328125,
        0.5819847583770752,
        0.5819843411445618,
        0.5819841623306274,
        0.5819839835166931,
        0.5819834470748901,
        0.5819816589355469,
        0.5819807052612305,
        0.5819788575172424,
        0.5819784998893738,
        0.5819779634475708,
        0.5819778442382812,
        0.5819773077964783,
        0.5819770693778992,
        0.5819752812385559,
        0.5819747447967529,
        0.5819728970527649,
        0.581972599029541,
        0.5819714069366455,
        0.581970751285553,
        0.5819702744483948,
        0.5819698572158813,
        0.5819686651229858,
        0.5819686055183411,
        0.5819668769836426,
        0.5819668173789978,
        0.581964910030365,
        0.5819646120071411,
        0.5819645524024963,
        0.5819644331932068,
        0.5819641351699829,
        0.5819638967514038,
        0.5819604396820068,
        0.5819603204727173,
        0.5819580554962158,
        0.5819578170776367,
        0.5819552540779114,
        0.5819551944732666,
        0.5819543600082397,
        0.5819539427757263,
        0.5819480419158936,
        0.581947922706604,
        0.581946849822998,
        0.5819467902183533,
        0.5819459557533264,
        0.5819457173347473,
        0.581945538520813,
        0.5819449424743652,
        0.581943929195404,
        0.5819436311721802,
        0.5819422006607056,
        0.581942081451416,
        0.5819419622421265,
        0.5819383263587952,
        0.5819382667541504,
        0.5819377303123474,
        0.5819373726844788,
        0.5819355249404907,
        0.5819348096847534,
        0.5819298028945923,
        0.5819291472434998,
        0.5819277763366699,
        0.5819275379180908,
        0.5819236040115356,
        0.5819231867790222,
        0.5819215178489685,
        0.581921398639679,
        0.5819208025932312,
        0.5819202065467834,
        0.5819196701049805,
        0.5819195508956909,
        0.5819156169891357,
        0.581915020942688,
        0.5819149613380432,
        0.5819147825241089,
        0.5819112658500671,
        0.5819108486175537,
        0.5819087624549866,
        0.5819085240364075,
        0.5819075107574463,
        0.5819074511528015,
        0.5819048881530762,
        0.5819036364555359,
        0.5819019079208374,
        0.5819010734558105,
        0.5819003582000732,
        0.5819001197814941,
        0.5818983316421509,
        0.5818977952003479,
        0.5818954110145569,
        0.5818952918052673,
        0.5818950533866882,
        0.5818948745727539,
        0.581885576248169,
        0.5818853974342346,
        0.5818853378295898,
        0.5818852782249451,
        0.5818784832954407,
        0.5818783044815063,
        0.5818779468536377,
        0.5818778276443481,
        0.5818777084350586,
        0.5818773508071899,
        0.5818756222724915,
        0.5818752646446228,
        0.5818704962730408,
        0.5818703770637512,
        0.5818693041801453,
        0.5818691253662109,
        0.5818659663200378,
        0.5818659067153931,
        0.5818643569946289,
        0.5818641781806946,
        0.581863284111023,
        0.5818632245063782,
        0.581862211227417,
        0.5818614959716797,
        0.5818575620651245,
        0.5818575024604797,
        0.5818572640419006,
        0.5818571448326111,
        0.581854522228241,
        0.5818542838096619,
        0.5818527340888977,
        0.5818526744842529,
        0.581848680973053,
        0.5818485021591187,
        0.5818479657173157,
        0.5818479061126709,
        0.5818477869033813,
        0.5818474888801575,
        0.5818446278572083,
        0.5818438529968262,
        0.5818436145782471,
        0.581843376159668,
        0.5818426609039307,
        0.5818421244621277,
        0.5818420648574829,
        0.5818416476249695,
        0.581839919090271,
        0.5818396210670471,
        0.5818383693695068,
        0.5818382501602173,
        0.58183753490448,
        0.5818374752998352,
        0.5818356871604919,
        0.5818356275558472,
        0.5818352103233337,
        0.5818350315093994,
        0.5818332433700562,
        0.581832766532898,
        0.5818312764167786,
        0.5818309187889099,
        0.5818300843238831,
        0.5818297266960144,
        0.5818286538124084,
        0.58182692527771,
        0.5818251371383667,
        0.5818250179290771,
        0.5818222761154175,
        0.5818219184875488,
        0.5818207859992981,
        0.5818203091621399,
        0.5818189978599548,
        0.5818188786506653,
        0.5818178057670593,
        0.5818169116973877,
        0.5818161368370056,
        0.5818158388137817,
        0.5818153619766235,
        0.5818145275115967,
        0.5818144083023071,
        0.5818133354187012,
        0.5818119645118713,
        0.581811249256134,
        0.5818101763725281,
        0.5818096399307251,
        0.5818033218383789,
        0.5818031430244446,
        0.5818016529083252,
        0.5818014144897461,
        0.5817984342575073,
        0.5817983150482178,
        0.5817965269088745,
        0.5817960500717163,
        0.5817950367927551,
        0.5817948579788208,
        0.5817897915840149,
        0.5817895531654358,
        0.5817869305610657,
        0.5817863941192627,
        0.5817856192588806,
        0.5817850828170776,
        0.5817838311195374,
        0.5817835330963135,
        0.5817821621894836,
        0.5817820429801941,
        0.581778347492218,
        0.5817781090736389,
        0.581764817237854,
        0.5817647576332092,
        0.5817582607269287,
        0.5817582011222839,
        0.5817465782165527,
        0.5817463397979736,
        0.5817417502403259,
        0.581741213798523,
        0.5817406177520752,
        0.5817402005195618,
        0.5817333459854126,
        0.5817322134971619,
        0.5817240476608276,
        0.5817237496376038,
        0.5817230343818665,
        0.5817223787307739,
        0.5817173719406128,
        0.581716775894165,
        0.5817091464996338,
        0.5817071795463562,
        0.5817033648490906,
        0.5817031264305115,
        0.5816999077796936,
        0.581699788570404,
        0.5816929340362549,
        0.581692636013031,
        0.581691563129425,
        0.5816914439201355,
        0.5816883444786072,
        0.5816881060600281,
        0.5816876888275146,
        0.5816864967346191,
        0.5816860795021057,
        0.5816857814788818,
        0.581681489944458,
        0.5816810131072998,
        0.5816788077354431,
        0.5816776752471924,
        0.58167564868927,
        0.5816755890846252,
        0.5816720724105835,
        0.581671953201294,
        0.5816717147827148,
        0.5816714763641357,
        0.5816691517829895,
        0.5816689729690552,
        0.581663191318512,
        0.5816630125045776,
        0.5816588997840881,
        0.5816588401794434,
        0.5816484093666077,
        0.5816478729248047,
        0.5816442966461182,
        0.5816442370414734,
        0.5816417932510376,
        0.581641674041748,
        0.5816399455070496,
        0.5816397666931152,
        0.5816395282745361,
        0.5816343426704407,
        0.5816341638565063,
        0.5816320776939392,
        0.5816318392753601,
        0.5816296935081482,
        0.5816293358802795,
        0.5816290974617004,
        0.5816285014152527,
        0.5816283226013184,
        0.5816282033920288,
        0.5816248059272766,
        0.5816246271133423,
        0.581622302532196,
        0.5816217064857483,
        0.581621527671814,
        0.5816214680671692,
        0.5816181898117065,
        0.5816178321838379,
        0.5816172361373901,
        0.5816164612770081,
        0.581615686416626,
        0.5816155076026917,
        0.5816147327423096,
        0.58161461353302,
        0.5816086530685425,
        0.5816085934638977,
        0.5816060900688171,
        0.581605851650238,
        0.5816053152084351,
        0.5816050171852112,
        0.581603467464447,
        0.5816034078598022,
        0.5816026926040649,
        0.581602156162262,
        0.5816017389297485,
        0.5816015005111694,
        0.5816007852554321,
        0.5815994143486023,
        0.5815992951393127,
        0.5815990567207336,
        0.5815987586975098,
        0.5815986394882202,
        0.5815985798835754,
        0.581598162651062,
        0.5815980434417725,
        0.5815972685813904,
        0.5815970301628113,
        0.581596851348877,
        0.5815967917442322,
        0.5815905332565308,
        0.5815904140472412,
        0.5815849304199219,
        0.5815848112106323,
        0.5815805792808533,
        0.5815803408622742,
        0.5815733075141907,
        0.581572949886322,
        0.5815656781196594,
        0.5815649628639221,
        0.5815585255622864,
        0.5815579891204834,
        0.5815578699111938,
        0.5815563797950745,
        0.5815553665161133,
        0.581554651260376,
        0.5815176963806152,
        0.5815165638923645,
        0.5814175605773926,
        0.5814172625541687,
        0.5814155340194702,
        0.5814142227172852,
        0.581413209438324,
        0.5814123153686523,
        0.5814120769500732,
        0.5814120173454285,
        0.5813978910446167,
        0.5813976526260376,
        0.5813902020454407,
        0.5813900828361511,
        0.5813893675804138,
        0.5813886523246765,
        0.5813878178596497,
        0.5813873410224915,
        0.5813870429992676,
        0.5813867449760437,
        0.5813860297203064,
        0.5813859105110168,
        0.5813856720924377,
        0.5813853740692139,
        0.5813837647438049,
        0.5813833475112915,
        0.5813828706741333,
        0.5813827514648438,
        0.5813822150230408,
        0.5813807845115662,
        0.5813806056976318,
        0.5813801884651184,
        0.5813785791397095,
        0.5813785195350647,
        0.5813784003257751,
        0.5813775062561035,
        0.5813767910003662,
        0.5813766717910767,
        0.5813748836517334,
        0.5813746452331543,
        0.5813745260238647,
        0.5813736319541931,
        0.5813724398612976,
        0.5813723206520081,
        0.5813692212104797,
        0.5813683271408081,
        0.5813649296760559,
        0.5813627243041992,
        0.5813571810722351,
        0.5813565850257874,
        0.5813274383544922,
        0.5813265442848206,
        0.5813112854957581,
        0.5813094973564148,
        0.5813084244728088,
        0.5813056826591492,
        0.5811624526977539
      ]
    },
    "confusion_matrix": [
      [
        0,
        2500
      ],
      [
        0,
        2500
      ]
    ],
    "test_samples": 5000,
    "dataset_info": {
      "name": "Edge-IIoTset",
      "total_samples": 243134,
      "evaluated_samples": 5000,
      "features": 61,
      "attack_types": 15,
      "zero_day_attack": "DDoS_UDP"
    }
  },
  "training_history": [
    {
      "round_number": 0,
      "client_updates": [
        "ClientUpdate(client_id='client_1', model_parameters={'meta_learner.transductive_net.feature_extractors.0.0.weight': tensor([[ 0.0759,  0.0722, -0.1249,  ..., -0.0593, -0.0790,  0.0453],\n        [-0.0053,  0.0139, -0.0044,  ..., -0.0018,  0.0688,  0.0662],\n        [ 0.0159, -0.1003, -0.0384,  ...,  0.0144,  0.1223, -0.0814],\n        ...,\n        [ 0.0851,  0.0197, -0.0046,  ..., -0.1040, -0.0015, -0.0133],\n        [ 0.0102, -0.0872,  0.0637,  ..., -0.0905, -0.0787, -0.1131],\n        [ 0.0435, -0.0223,  0.0321,  ..., -0.0146,  0.0846, -0.1236]]), 'meta_learner.transductive_net.feature_extractors.0.0.bias': tensor([ 0.0170, -0.1292, -0.0852, -0.0797, -0.1139,  0.0461,  0.0571,  0.1151,\n         0.0555, -0.0392, -0.0220,  0.0363,  0.0775, -0.0858,  0.1240, -0.0625,\n         0.0861,  0.0784,  0.0692, -0.0074, -0.0865, -0.0832, -0.0365,  0.0469,\n        -0.1179,  0.0101, -0.1074, -0.0673,  0.0758, -0.0490,  0.0653,  0.0183,\n        -0.0238,  0.1116,  0.0830,  0.0419, -0.0042,  0.0661,  0.0413,  0.0120,\n         0.1014, -0.1175,  0.0742, -0.0698,  0.0627,  0.0230,  0.0136, -0.1004,\n        -0.0254, -0.0879, -0.1158,  0.0032,  0.0817,  0.0119,  0.0388,  0.0419,\n        -0.0850,  0.1185,  0.0378, -0.1237,  0.0502, -0.1282, -0.1174, -0.0869,\n         0.1209,  0.0295,  0.0390, -0.0820,  0.0601,  0.0733, -0.0508, -0.1169,\n         0.0707, -0.0434, -0.1174, -0.0111,  0.0617,  0.0915, -0.0729, -0.0063,\n         0.0858, -0.0708, -0.0870,  0.1300, -0.0325,  0.0387,  0.0374,  0.0073,\n         0.0094, -0.0258,  0.0232, -0.0591, -0.0766,  0.0656, -0.0196,  0.1105,\n         0.0924,  0.0041,  0.0413,  0.1125,  0.0610, -0.1159, -0.0786,  0.0354,\n        -0.0319, -0.0819, -0.0467, -0.0048, -0.0101, -0.1068, -0.0054,  0.0357,\n        -0.0329, -0.0181,  0.0367, -0.0567, -0.0329, -0.0722,  0.0790, -0.0553,\n        -0.0080,  0.1010,  0.1150, -0.0197,  0.1157,  0.0798,  0.0701, -0.0817]), 'meta_learner.transductive_net.feature_extractors.1.0.weight': tensor([[-0.0658, -0.0682,  0.1038,  ..., -0.0576, -0.0526, -0.0871],\n        [-0.0734,  0.1146, -0.1068,  ..., -0.0996,  0.0583, -0.0666],\n        [-0.0468, -0.0363,  0.1194,  ..., -0.0614, -0.0255, -0.0785],\n        ...,\n        [ 0.0969,  0.1134, -0.1040,  ..., -0.1043,  0.0739, -0.0996],\n        [ 0.1014, -0.0678,  0.0178,  ...,  0.0302, -0.0884,  0.0076],\n        [-0.0652, -0.0557,  0.0250,  ...,  0.0959, -0.0249, -0.0156]]), 'meta_learner.transductive_net.feature_extractors.1.0.bias': tensor([-0.0582,  0.0897,  0.0336, -0.0521,  0.0600, -0.1023,  0.0842,  0.0762,\n         0.0484,  0.0352,  0.0753,  0.0756,  0.0769, -0.1210,  0.0133,  0.0644,\n        -0.0171, -0.0581, -0.1110,  0.0540,  0.1096,  0.0284, -0.0772,  0.0373,\n        -0.0723, -0.0990,  0.0449,  0.0191,  0.0460,  0.0202, -0.0067, -0.0303,\n         0.0182, -0.0209,  0.0973, -0.0658, -0.0314,  0.0269, -0.0039,  0.0221,\n         0.0438,  0.0660,  0.0037,  0.0769,  0.0084, -0.1057,  0.0635,  0.0174,\n         0.1251,  0.0696, -0.0916,  0.0516, -0.0910, -0.0388, -0.0818,  0.0680,\n         0.0171,  0.0322, -0.0319,  0.0440, -0.0670, -0.0553, -0.0563,  0.1140]), 'meta_learner.transductive_net.feature_extractors.2.0.weight': tensor([[ 0.0553, -0.0873, -0.1182,  ..., -0.1179, -0.0834,  0.1147],\n        [-0.0409, -0.1110, -0.1276,  ...,  0.0256,  0.1159,  0.1176],\n        [-0.0362,  0.0531, -0.1238,  ...,  0.0661,  0.0585, -0.0278],\n        ...,\n        [-0.0814, -0.0618, -0.0720,  ...,  0.0318,  0.0157,  0.0239],\n        [-0.0825,  0.0135,  0.0598,  ..., -0.0081,  0.0592, -0.0943],\n        [-0.0820,  0.0048,  0.0386,  ...,  0.0019,  0.0523, -0.0590]]), 'meta_learner.transductive_net.feature_extractors.2.0.bias': tensor([-3.5618e-02, -3.2270e-02, -5.1560e-02, -8.3366e-02,  1.4103e-02,\n         9.4862e-02, -6.4566e-02, -3.9818e-02, -7.4441e-02,  4.6281e-02,\n        -1.0600e-01, -6.7296e-02, -5.2357e-02, -4.1619e-02,  6.6163e-02,\n        -1.1199e-01,  5.7534e-02, -2.9857e-02, -6.7074e-02, -2.5783e-02,\n        -9.6257e-02,  6.0951e-02,  1.2055e-01,  2.8048e-02,  4.4665e-02,\n        -2.9483e-02, -4.1042e-02,  5.0103e-02,  8.9441e-02,  1.1179e-02,\n        -8.2043e-02,  1.1503e-01, -2.4862e-02, -1.3519e-01,  6.7730e-02,\n         1.3344e-01,  1.5926e-02,  1.1701e-01,  7.8930e-03,  3.5021e-02,\n        -4.2247e-02, -4.7060e-02,  3.9851e-02, -4.4562e-02, -1.7887e-03,\n        -7.8421e-02,  3.4529e-02,  6.5953e-02,  5.4089e-02,  7.8384e-03,\n        -4.8861e-02,  9.2540e-03,  2.2529e-02, -7.7000e-03, -7.1982e-02,\n        -2.9047e-02,  9.6508e-03,  1.2268e-01, -4.2842e-02, -1.1889e-02,\n         1.0473e-01,  1.8248e-02,  2.2321e-02,  4.1270e-02, -1.0278e-01,\n         5.1998e-02,  4.9214e-02,  1.4625e-05, -6.1590e-02, -1.5984e-02,\n         9.2220e-02,  8.5318e-02, -5.4703e-02, -5.3152e-02,  6.1731e-02,\n         4.3111e-02, -1.7948e-02,  3.5675e-02,  6.3270e-02,  9.0134e-02,\n         4.4669e-02,  4.9771e-02, -1.1914e-02, -7.2850e-02, -9.6026e-02,\n         7.4754e-02,  8.2978e-02,  5.3057e-02, -3.2518e-02, -6.3529e-02,\n        -9.0587e-03,  3.3983e-02, -1.0302e-01,  8.5905e-02, -1.0628e-01,\n        -1.0048e-01,  9.8890e-02,  8.8766e-02,  6.9061e-02, -1.1218e-01,\n         2.3135e-02, -8.9817e-02,  3.2511e-02,  5.4572e-02, -5.9079e-02,\n         1.0826e-01, -1.0573e-01,  6.3031e-02, -3.4516e-02,  2.2958e-02,\n         3.0274e-02, -8.0176e-02,  5.7995e-02,  1.1192e-01,  8.0117e-02,\n        -5.4931e-02, -5.6652e-02,  1.1921e-01, -3.5298e-02, -6.2853e-02,\n         9.8535e-02,  1.6005e-02,  2.2043e-02,  5.4290e-02,  4.3110e-02,\n        -8.7194e-02, -3.2772e-02, -9.6702e-02, -1.2949e-01, -1.3796e-02,\n         6.9591e-02,  6.7776e-02,  6.4555e-02,  1.1841e-01, -8.4140e-02,\n         2.5614e-02,  1.0868e-01, -3.6169e-02,  2.9323e-02, -2.2457e-02,\n        -6.0141e-02, -6.2436e-02,  3.8819e-02, -8.0959e-02,  1.0613e-01,\n        -1.1201e-01,  1.2206e-01,  7.0550e-02, -1.1209e-02,  9.9544e-02,\n         2.0504e-02,  3.7861e-02, -1.0173e-01,  3.3409e-02, -3.2202e-02,\n         7.0779e-02,  9.4194e-02,  8.1958e-02, -6.2208e-02,  7.4154e-02,\n         7.6098e-02, -1.0317e-01,  3.4737e-02, -9.7766e-02,  4.9733e-02,\n         4.5177e-02,  6.4855e-02,  2.0919e-02,  4.5012e-02, -3.8906e-02,\n         5.9641e-02,  4.8142e-02, -1.0972e-01,  7.6441e-02,  3.7172e-02,\n        -4.2523e-02,  3.9462e-02, -9.4059e-02, -6.4719e-02,  5.9501e-02,\n         9.5995e-02, -7.2913e-02, -1.2196e-01,  5.3952e-02,  6.3648e-03,\n        -4.2267e-02, -3.6638e-03, -3.1252e-02,  8.4723e-02,  5.7701e-02,\n         8.6634e-02, -5.1779e-02, -5.2601e-02,  4.7296e-02, -7.1212e-03,\n        -3.7982e-02, -4.1396e-02, -5.4990e-03, -7.7114e-02,  1.2921e-01,\n        -3.4859e-02, -1.0965e-01,  1.2229e-02,  3.1760e-02, -2.5246e-02,\n        -7.9750e-02,  9.1687e-02,  2.7116e-02, -3.4850e-02, -1.1986e-01,\n         5.1905e-02, -6.0908e-02, -4.4303e-02, -1.2073e-01, -5.3522e-02,\n        -1.1114e-01, -9.0004e-02,  2.7013e-02, -9.8468e-02, -6.4787e-02,\n        -5.5279e-02, -6.0252e-02, -6.2420e-02,  1.0917e-01,  2.1570e-02,\n         3.4515e-02,  1.2392e-01, -1.3273e-01, -7.6949e-02, -3.0345e-03,\n         9.7967e-03, -2.7630e-02, -1.0084e-01,  1.1864e-01,  1.1199e-01,\n         2.3398e-02,  9.6770e-02,  1.2558e-01, -1.0274e-01,  7.0094e-02,\n        -1.0130e-01,  4.4344e-03,  2.8326e-02,  3.8042e-02,  1.0370e-01,\n         1.2796e-01,  3.4220e-02,  1.2222e-01, -1.1177e-01,  1.1523e-02,\n        -3.2096e-02, -8.7222e-02, -1.0660e-01,  2.9869e-02,  6.6536e-02,\n         2.7703e-02]), 'meta_learner.transductive_net.feature_projection.0.weight': tensor([[ 0.0067, -0.0249,  0.0214,  ..., -0.0184, -0.0354,  0.0325],\n        [ 0.0289,  0.0320, -0.0349,  ..., -0.0242,  0.0408,  0.0085],\n        [-0.0154, -0.0273, -0.0211,  ..., -0.0373, -0.0088,  0.0280],\n        ...,\n        [ 0.0037,  0.0409, -0.0220,  ...,  0.0239,  0.0275, -0.0012],\n        [-0.0364, -0.0134,  0.0325,  ...,  0.0509,  0.0391, -0.0366],\n        [-0.0069, -0.0228, -0.0020,  ...,  0.0184, -0.0148,  0.0352]]), 'meta_learner.transductive_net.feature_projection.0.bias': tensor([ 0.0149,  0.0422,  0.0115, -0.0361, -0.0223, -0.0209, -0.0191,  0.0460,\n         0.0138, -0.0235, -0.0112, -0.0241,  0.0295,  0.0501,  0.0025, -0.0296,\n         0.0334, -0.0313, -0.0245,  0.0260,  0.0391, -0.0073, -0.0489, -0.0454,\n        -0.0407, -0.0136, -0.0172, -0.0102,  0.0317, -0.0097,  0.0203, -0.0117,\n        -0.0414, -0.0294,  0.0249, -0.0238,  0.0207,  0.0197, -0.0008,  0.0252,\n         0.0236, -0.0250, -0.0016, -0.0488,  0.0355,  0.0330,  0.0408, -0.0184,\n         0.0242, -0.0281, -0.0265,  0.0440,  0.0259,  0.0048,  0.0335,  0.0224,\n        -0.0096,  0.0038, -0.0328, -0.0227, -0.0233, -0.0065, -0.0307, -0.0357]), 'meta_learner.transductive_net.classifier.0.weight': tensor([[ 0.1085,  0.0156, -0.0471,  ..., -0.1017,  0.0493,  0.0873],\n        [ 0.0354, -0.0721, -0.0485,  ...,  0.0648, -0.0231, -0.1220],\n        [ 0.1213,  0.1006, -0.0341,  ...,  0.0488,  0.0830, -0.0966],\n        ...,\n        [-0.0381,  0.0148, -0.0434,  ...,  0.0175, -0.1205,  0.1147],\n        [ 0.0795,  0.1178,  0.0491,  ...,  0.0258,  0.0279, -0.0075],\n        [ 0.0990,  0.1180,  0.0064,  ..., -0.0272,  0.0402,  0.1051]]), 'meta_learner.transductive_net.classifier.0.bias': tensor([ 0.1112, -0.0530,  0.0907, -0.0695,  0.0863,  0.0175,  0.0762,  0.0895,\n         0.0733, -0.0286,  0.0249, -0.1232, -0.0718, -0.0238, -0.0476,  0.1137,\n         0.1165, -0.1087, -0.0273,  0.0712,  0.0125,  0.0819, -0.0658,  0.0951,\n        -0.0122,  0.0415,  0.0650, -0.0236,  0.0802, -0.0329, -0.0891, -0.0337,\n        -0.0798, -0.0302, -0.0576, -0.0181, -0.0642, -0.0276, -0.1159, -0.0442,\n         0.0878, -0.1041,  0.0163,  0.0508,  0.0442, -0.0354, -0.0848, -0.0764,\n        -0.0022,  0.0648,  0.0271,  0.0570, -0.0838, -0.0303, -0.0457, -0.0958,\n         0.0126,  0.0030,  0.0649,  0.0663,  0.0143,  0.0908, -0.0300,  0.1184]), 'meta_learner.transductive_net.classifier.3.weight': tensor([[-0.0011,  0.0530,  0.0833,  ...,  0.0172,  0.1173,  0.0410],\n        [ 0.0229, -0.0916,  0.0875,  ...,  0.0041,  0.0674, -0.0159],\n        [-0.0606, -0.0712,  0.1146,  ..., -0.1209, -0.0626,  0.1214],\n        ...,\n        [-0.0090, -0.0842, -0.0798,  ...,  0.0431, -0.0653, -0.1103],\n        [-0.0592,  0.0982, -0.1119,  ..., -0.1050, -0.0414, -0.0382],\n        [ 0.0714, -0.0597,  0.0671,  ...,  0.0912,  0.1072, -0.0822]]), 'meta_learner.transductive_net.classifier.3.bias': tensor([ 0.1082, -0.0661,  0.0478, -0.0855, -0.0357,  0.0472, -0.0883, -0.0870,\n        -0.0385, -0.0806, -0.0841,  0.0650, -0.0438,  0.1012, -0.0844,  0.0403,\n        -0.0835,  0.1149, -0.0098, -0.0235,  0.0694,  0.1113, -0.0759,  0.0156,\n         0.0996,  0.0961, -0.0559,  0.0328, -0.0759, -0.0719, -0.0359,  0.0462]), 'meta_learner.transductive_net.classifier.6.weight': tensor([[ 0.1284, -0.1497,  0.1353, -0.1463, -0.1261, -0.0082, -0.1502, -0.1567,\n         -0.0605,  0.0483,  0.0248,  0.0201, -0.0427, -0.0143,  0.0269,  0.0456,\n          0.1181, -0.1279,  0.0664,  0.1330,  0.1603, -0.1196,  0.0169, -0.1042,\n         -0.0470, -0.0358, -0.0604,  0.1609, -0.0006, -0.1350,  0.0209,  0.0585],\n        [-0.1260, -0.0087, -0.1290, -0.1400, -0.1081, -0.1212,  0.1194,  0.1337,\n         -0.0851,  0.0497,  0.1536, -0.1392,  0.1634,  0.1404, -0.1297, -0.0764,\n         -0.1703, -0.0717,  0.1139,  0.1243, -0.0473, -0.0174, -0.0898,  0.0098,\n          0.0984,  0.0768, -0.1139,  0.1659,  0.1370,  0.0119, -0.0950, -0.0763]]), 'meta_learner.transductive_net.classifier.6.bias': tensor([-0.1467,  0.1756]), 'meta_learner.transductive_net.self_attention.in_proj_weight': tensor([[ 0.0560, -0.0110,  0.1262,  ..., -0.0739,  0.0892, -0.0892],\n        [ 0.1225, -0.0455, -0.1320,  ...,  0.0843,  0.0888, -0.0447],\n        [ 0.1030, -0.1291,  0.0709,  ..., -0.0472, -0.0222, -0.1319],\n        ...,\n        [ 0.0135,  0.1169, -0.1436,  ..., -0.1479,  0.0629, -0.0233],\n        [-0.1214,  0.0149, -0.1176,  ...,  0.1028,  0.1536, -0.0091],\n        [-0.0507,  0.1140, -0.0501,  ...,  0.0925, -0.0384,  0.1366]]), 'meta_learner.transductive_net.self_attention.in_proj_bias': tensor([-9.8781e-03,  3.5160e-03, -6.7359e-04,  1.9222e-03,  1.9620e-03,\n         4.4758e-03,  2.1934e-03,  4.2547e-03, -7.1306e-03, -2.8776e-03,\n         4.3815e-03,  2.2353e-03, -4.1788e-03, -6.0860e-04, -2.2239e-03,\n        -2.9587e-03, -9.4150e-03,  6.8387e-03, -2.5040e-03,  5.3663e-03,\n        -2.5450e-03,  1.4137e-02,  1.5573e-03, -2.9124e-03,  6.5681e-03,\n         4.8095e-03,  1.2791e-02, -5.2570e-03, -4.9747e-03, -4.4059e-03,\n        -5.6287e-03,  7.8030e-03, -6.0607e-03, -2.6234e-03,  3.0741e-03,\n         2.8124e-04,  4.4060e-03, -2.9236e-03,  6.7456e-03,  9.3979e-03,\n         1.2820e-02, -1.8492e-03, -2.3116e-03, -7.3260e-03, -1.2039e-02,\n         7.9568e-03,  5.3187e-03,  6.4830e-04, -4.5973e-03, -6.4365e-03,\n        -3.9605e-03, -3.4095e-03,  5.5446e-04,  5.3564e-03, -5.4745e-03,\n        -3.5678e-03,  2.4254e-03,  4.3204e-03, -4.5242e-03,  2.6713e-03,\n        -3.8808e-03, -9.9373e-03, -1.1811e-02, -3.9845e-03, -9.1270e-05,\n        -6.0107e-06,  1.3298e-04, -3.2104e-05,  2.6880e-04, -1.1378e-04,\n        -1.1476e-04, -1.1998e-05,  1.5723e-05,  4.7027e-05,  4.0365e-05,\n         4.6450e-06,  5.2480e-05, -8.1313e-05,  7.2136e-05, -1.2371e-05,\n        -9.5131e-05, -6.3089e-05,  7.0332e-05,  1.4614e-04, -9.2987e-05,\n        -8.3315e-05,  1.4501e-04, -7.6045e-05,  1.4604e-04,  4.5136e-06,\n         3.0032e-05, -1.0216e-05,  6.6528e-06, -8.3415e-05, -1.0614e-04,\n         1.8707e-04, -5.9894e-06, -3.0558e-05,  2.0170e-04, -1.1195e-04,\n         1.3196e-05, -5.5562e-06,  5.3796e-05,  8.0053e-05,  5.2796e-05,\n         1.0021e-04,  1.9811e-04, -9.6664e-05, -1.1612e-04,  5.4814e-05,\n        -9.8847e-05,  1.3156e-05, -1.9882e-04,  3.3948e-05,  8.5228e-05,\n         3.4607e-05,  2.7090e-04,  4.7453e-06,  3.2912e-05, -7.0583e-05,\n         8.6614e-06, -1.3984e-04,  1.4906e-04,  6.2033e-05,  3.5584e-04,\n        -2.6777e-05, -6.3981e-05, -8.2060e-05, -2.1708e-04,  1.6449e-04,\n         3.0997e-04, -8.6297e-04, -2.9581e-04,  5.6452e-05,  9.5987e-05,\n         6.9800e-04, -3.2438e-04,  7.0824e-04, -5.5571e-04,  4.5424e-04,\n        -2.3304e-04,  5.8799e-04,  2.3643e-04, -3.8514e-04,  6.1737e-04,\n         1.3567e-03, -1.8845e-04,  2.5284e-04, -5.6863e-04,  3.1580e-04,\n        -2.8999e-04,  6.2487e-05,  4.5788e-04,  2.9451e-04,  8.6708e-04,\n        -3.2973e-04,  3.1822e-05, -7.3970e-04,  4.7142e-05,  7.4198e-06,\n        -1.6605e-05,  4.3600e-05,  3.7484e-05, -8.8935e-04, -1.0809e-04,\n        -3.3802e-05,  1.3456e-04, -1.2592e-04,  6.8563e-04,  5.3460e-04,\n         7.0116e-04, -3.4173e-04, -1.0821e-04, -3.2103e-05,  2.5824e-04,\n         8.8225e-04,  3.2391e-04, -2.1382e-04,  5.7388e-04, -2.0850e-03,\n        -3.1772e-04, -4.7617e-04, -9.2938e-05,  9.0610e-04, -2.4558e-04,\n        -8.0644e-04, -1.3498e-04,  3.4064e-04,  5.4806e-05, -5.5454e-04,\n        -4.4048e-04,  3.2041e-04]), 'meta_learner.transductive_net.self_attention.out_proj.weight': tensor([[-0.0012, -0.0865, -0.0581,  ...,  0.0589,  0.0044, -0.1301],\n        [-0.0003, -0.0209, -0.0822,  ..., -0.0276, -0.1188, -0.0169],\n        [ 0.0048,  0.0179, -0.1236,  ...,  0.0809, -0.0727, -0.0903],\n        ...,\n        [ 0.0284,  0.0569,  0.0379,  ..., -0.0925,  0.0988, -0.1175],\n        [ 0.0388, -0.1008, -0.0856,  ...,  0.0020,  0.1079, -0.0042],\n        [-0.0309, -0.0997, -0.0850,  ..., -0.0992,  0.0391, -0.1261]]), 'meta_learner.transductive_net.self_attention.out_proj.bias': tensor([-3.2294e-04,  1.5954e-04,  1.1158e-04,  5.9015e-05, -8.4368e-04,\n         1.3584e-04, -1.6823e-04, -3.9694e-04, -2.4799e-04,  2.6454e-04,\n        -4.4178e-04,  5.9703e-04, -9.5560e-05, -6.9839e-04, -1.2579e-04,\n        -7.7468e-04, -4.7455e-04, -3.3306e-04, -4.7978e-04,  2.1456e-04,\n        -1.2610e-03, -3.6017e-04,  3.8248e-04, -4.1742e-04, -1.4347e-04,\n        -5.1482e-04,  3.3193e-04,  6.2277e-04, -4.6503e-04,  4.7413e-04,\n        -1.4941e-04,  1.0246e-03, -6.8150e-04, -3.2594e-04,  2.4763e-04,\n        -9.1969e-05, -4.0268e-04,  1.2021e-04,  5.2468e-04, -4.0260e-04,\n         9.7010e-05, -4.2104e-04, -4.1100e-04, -1.5099e-04,  6.3747e-05,\n         1.7269e-04, -2.3611e-04,  8.6790e-05,  7.7824e-05, -2.1801e-04,\n         5.5421e-04,  1.1977e-04, -2.9777e-05, -6.2269e-04, -6.6640e-05,\n        -2.2027e-04,  2.6114e-04, -1.2259e-04,  4.6381e-05, -3.9310e-04,\n         1.0952e-04, -3.0281e-04, -4.3009e-04,  2.0600e-04]), 'meta_learner.transductive_net.layer_norm.weight': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'meta_learner.transductive_net.layer_norm.bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}, sample_count=14916, training_loss=np.float64(0.12393162727355958), validation_accuracy=np.float64(0.7220000123977661), validation_precision=0.0, validation_recall=0.0, validation_f1_score=0.0, timestamp=1760251410.2776632, model_hash='9cb54b9e4b77026187012e6e04ffe7be16fe0f8cbed47c5c58faacf018d06c63', ipfs_cid='QmU7aBtcBts3BZXKQVZMs7YF23dBYPMhm8HdujuiPbRJbS', blockchain_tx_hash='7cd8eab2ed8f3f0318ab2caf77b74da0800e8d4c64b6bfd2a0fc7b66d5c0bcbb')",
        "ClientUpdate(client_id='client_2', model_parameters={'meta_learner.transductive_net.feature_extractors.0.0.weight': tensor([[ 0.0734,  0.0698, -0.1199,  ..., -0.0633, -0.0765,  0.0453],\n        [-0.0208, -0.0016, -0.0199,  ..., -0.0025,  0.0828,  0.0662],\n        [ 0.0046, -0.1117, -0.0441,  ...,  0.0103,  0.1136, -0.0814],\n        ...,\n        [ 0.0829,  0.0172, -0.0086,  ..., -0.0867,  0.0104, -0.0133],\n        [ 0.0180, -0.0793,  0.0765,  ..., -0.0927, -0.0957, -0.1131],\n        [ 0.0570, -0.0090,  0.0502,  ..., -0.0072,  0.0687, -0.1236]]), 'meta_learner.transductive_net.feature_extractors.0.0.bias': tensor([ 0.0120, -0.1137, -0.0739, -0.0671, -0.0948,  0.0442,  0.0647,  0.1040,\n         0.0517, -0.0387, -0.0150,  0.0453,  0.0765, -0.0859,  0.1140, -0.0771,\n         0.0746,  0.0746,  0.0720, -0.0137, -0.0790, -0.0798, -0.0560,  0.0379,\n        -0.1188,  0.0126, -0.0962, -0.0614,  0.0924, -0.0477,  0.0520,  0.0110,\n        -0.0317,  0.1184,  0.0784,  0.0449,  0.0040,  0.0595,  0.0375,  0.0072,\n         0.0921, -0.1259,  0.0673, -0.0548,  0.0579,  0.0307,  0.0173, -0.0928,\n        -0.0283, -0.0748, -0.1119, -0.0088,  0.0850,  0.0089,  0.0402,  0.0439,\n        -0.0792,  0.1328,  0.0522, -0.1238,  0.0567, -0.1253, -0.1248, -0.1029,\n         0.1156,  0.0261,  0.0312, -0.0896,  0.0459,  0.0763, -0.0402, -0.1151,\n         0.0887, -0.0546, -0.1227, -0.0245,  0.0647,  0.0810, -0.0597,  0.0047,\n         0.0695, -0.0748, -0.0886,  0.1167, -0.0242,  0.0558,  0.0391, -0.0003,\n         0.0326, -0.0264,  0.0191, -0.0702, -0.0839,  0.0640, -0.0174,  0.1308,\n         0.0934,  0.0047,  0.0478,  0.1110,  0.0606, -0.1106, -0.0710,  0.0447,\n        -0.0369, -0.0790, -0.0387, -0.0023, -0.0109, -0.1040, -0.0072,  0.0265,\n        -0.0323, -0.0236,  0.0464, -0.0517, -0.0318, -0.0850,  0.0924, -0.0477,\n        -0.0060,  0.1110,  0.1177, -0.0114,  0.1196,  0.0839,  0.0622, -0.0843]), 'meta_learner.transductive_net.feature_extractors.1.0.weight': tensor([[-0.0756, -0.0780,  0.1065,  ..., -0.0675, -0.0580, -0.0871],\n        [-0.0630,  0.1250, -0.0949,  ..., -0.0933,  0.0423, -0.0666],\n        [-0.0505, -0.0399,  0.1181,  ..., -0.0688, -0.0211, -0.0785],\n        ...,\n        [ 0.0955,  0.1117, -0.1148,  ..., -0.1073,  0.0843, -0.0996],\n        [ 0.1085, -0.0606,  0.0127,  ...,  0.0199, -0.0776,  0.0076],\n        [-0.0738, -0.0644,  0.0289,  ...,  0.1081, -0.0165, -0.0156]]), 'meta_learner.transductive_net.feature_extractors.1.0.bias': tensor([-0.0485,  0.0778,  0.0372, -0.0674,  0.0680, -0.1039,  0.0853,  0.0758,\n         0.0490,  0.0354,  0.0834,  0.0752,  0.0849, -0.1169,  0.0124,  0.0632,\n        -0.0104, -0.0572, -0.1018,  0.0554,  0.1156,  0.0304, -0.0613,  0.0342,\n        -0.0703, -0.1119,  0.0434,  0.0011,  0.0595,  0.0243, -0.0105, -0.0251,\n         0.0089, -0.0312,  0.1050, -0.0745, -0.0320,  0.0342, -0.0115,  0.0114,\n         0.0615,  0.0633,  0.0037,  0.0896,  0.0067, -0.1066,  0.0582,  0.0171,\n         0.1278,  0.0749, -0.0742,  0.0524, -0.0815, -0.0408, -0.0827,  0.0571,\n         0.0261,  0.0304, -0.0438,  0.0449, -0.0696, -0.0446, -0.0626,  0.1226]), 'meta_learner.transductive_net.feature_extractors.2.0.weight': tensor([[ 0.0553, -0.0874, -0.1165,  ..., -0.1204, -0.0990,  0.1147],\n        [-0.0445, -0.1146, -0.1311,  ...,  0.0247,  0.1142,  0.1176],\n        [-0.0256,  0.0635, -0.1194,  ...,  0.0705,  0.0631, -0.0278],\n        ...,\n        [-0.0812, -0.0617, -0.0695,  ...,  0.0365,  0.0175,  0.0239],\n        [-0.0673,  0.0288,  0.0505,  ..., -0.0002,  0.0646, -0.0943],\n        [-0.0753,  0.0115,  0.0453,  ..., -0.0088,  0.0465, -0.0590]]), 'meta_learner.transductive_net.feature_extractors.2.0.bias': tensor([-3.0163e-02, -2.8727e-02, -5.3664e-02, -8.0021e-02,  2.7013e-02,\n         1.0635e-01, -6.1889e-02, -4.5453e-02, -7.5823e-02,  4.0547e-02,\n        -9.1415e-02, -6.3184e-02, -6.3816e-02, -3.1540e-02,  7.7309e-02,\n        -1.1239e-01,  4.0369e-02, -3.5245e-02, -4.9981e-02, -1.3779e-02,\n        -1.0332e-01,  6.2223e-02,  1.2824e-01,  3.6018e-02,  4.9768e-02,\n        -1.2691e-02, -2.4064e-02,  6.2256e-02,  9.2846e-02,  3.3718e-02,\n        -8.0484e-02,  1.1085e-01, -2.3444e-02, -1.1643e-01,  7.2557e-02,\n         1.1869e-01,  8.4780e-03,  1.1786e-01,  5.0937e-03,  3.4730e-02,\n        -4.7385e-02, -4.5039e-02,  4.8475e-02, -4.5959e-02,  8.2756e-03,\n        -6.9928e-02,  2.8021e-02,  7.1467e-02,  5.9272e-02,  1.3100e-02,\n        -6.1256e-02, -5.8196e-03,  1.1025e-02, -2.8568e-02, -8.4089e-02,\n        -3.0172e-02, -6.9303e-03,  1.0777e-01, -4.6053e-02,  3.9548e-03,\n         9.9300e-02,  1.5035e-02,  2.3568e-02,  3.3721e-02, -9.7529e-02,\n         5.2093e-02,  4.3290e-02,  7.4478e-03, -6.7445e-02, -2.6136e-02,\n         8.0861e-02,  7.6678e-02, -5.7627e-02, -5.2946e-02,  6.3853e-02,\n         3.5871e-02, -1.3861e-02,  4.6247e-02,  4.7280e-02,  8.9435e-02,\n         5.2850e-02,  4.6339e-02, -1.4007e-02, -8.3256e-02, -1.0027e-01,\n         7.2634e-02,  9.1041e-02,  4.9659e-02, -3.3316e-02, -6.4150e-02,\n         1.2501e-04,  3.2554e-02, -9.6479e-02,  9.2753e-02, -1.1060e-01,\n        -1.1046e-01,  1.0767e-01,  8.7648e-02,  7.7981e-02, -1.0702e-01,\n         3.5022e-02, -9.3574e-02,  1.8764e-02,  5.1846e-02, -5.5469e-02,\n         1.0610e-01, -1.1708e-01,  4.8701e-02, -2.8375e-02,  2.1931e-02,\n         3.3422e-02, -8.6607e-02,  4.1039e-02,  1.1780e-01,  8.1965e-02,\n        -4.1474e-02, -6.6808e-02,  1.1849e-01, -4.5262e-02, -6.7099e-02,\n         1.0083e-01,  1.6171e-02,  3.0502e-02,  6.2695e-02,  4.3303e-02,\n        -8.1653e-02, -4.0577e-02, -1.1660e-01, -1.2142e-01,  6.5763e-04,\n         7.7304e-02,  7.3714e-02,  6.5526e-02,  1.1928e-01, -7.6932e-02,\n         3.3247e-02,  9.4755e-02, -3.3802e-02,  3.3281e-02, -1.6318e-02,\n        -6.1283e-02, -7.6880e-02,  4.1776e-02, -8.6990e-02,  1.0188e-01,\n        -1.2195e-01,  1.0718e-01,  6.8302e-02, -1.7132e-02,  1.0041e-01,\n         1.5839e-02,  4.3799e-02, -1.0676e-01,  3.6058e-02, -3.0215e-02,\n         7.8662e-02,  9.3287e-02,  9.5597e-02, -7.0401e-02,  7.7647e-02,\n         7.1814e-02, -1.0252e-01,  4.5389e-02, -9.3993e-02,  5.3765e-02,\n         3.7064e-02,  6.4392e-02,  2.3924e-02,  4.3236e-02, -2.9637e-02,\n         5.6812e-02,  4.8196e-02, -1.0733e-01,  7.9272e-02,  3.5044e-02,\n        -3.4142e-02,  3.7412e-02, -8.3361e-02, -5.9377e-02,  5.2743e-02,\n         1.0085e-01, -7.3801e-02, -1.1427e-01,  4.9794e-02,  1.3646e-02,\n        -5.4935e-02, -1.0395e-02, -1.9636e-02,  7.9695e-02,  6.8908e-02,\n         9.6331e-02, -5.1977e-02, -5.8971e-02,  4.8453e-02, -9.3645e-03,\n        -4.6500e-02, -3.1350e-02, -3.2794e-03, -7.5906e-02,  1.2882e-01,\n        -2.6571e-02, -1.1514e-01,  1.1619e-02,  4.1021e-02, -3.9914e-02,\n        -9.0085e-02,  6.7251e-02,  2.1084e-02, -3.5877e-02, -1.0379e-01,\n         6.0383e-02, -6.0922e-02, -3.8986e-02, -1.1489e-01, -6.2571e-02,\n        -1.0433e-01, -9.2545e-02,  2.8260e-02, -9.8924e-02, -6.1727e-02,\n        -6.5852e-02, -4.8047e-02, -4.9657e-02,  9.9765e-02,  1.5420e-02,\n         4.2386e-02,  1.2658e-01, -1.2467e-01, -7.0156e-02, -2.4266e-03,\n         1.7217e-02, -2.8978e-02, -1.1284e-01,  1.0967e-01,  1.3317e-01,\n         1.6307e-02,  1.1754e-01,  1.2024e-01, -8.2936e-02,  6.8309e-02,\n        -9.9556e-02,  7.9389e-03,  3.3446e-02,  5.5015e-02,  1.0094e-01,\n         1.1152e-01,  3.5433e-02,  1.0279e-01, -1.1871e-01,  1.5485e-02,\n        -4.2796e-02, -9.5859e-02, -1.0813e-01,  2.9687e-02,  5.1298e-02,\n         2.0993e-02]), 'meta_learner.transductive_net.feature_projection.0.weight': tensor([[ 0.0022, -0.0310,  0.0135,  ..., -0.0183, -0.0409,  0.0322],\n        [ 0.0217,  0.0276, -0.0405,  ..., -0.0221,  0.0396,  0.0081],\n        [-0.0078, -0.0240, -0.0259,  ..., -0.0424,  0.0092,  0.0429],\n        ...,\n        [ 0.0016,  0.0448, -0.0186,  ...,  0.0221,  0.0326, -0.0065],\n        [-0.0469, -0.0164,  0.0368,  ...,  0.0457,  0.0335, -0.0531],\n        [-0.0147, -0.0350, -0.0033,  ...,  0.0295, -0.0218,  0.0264]]), 'meta_learner.transductive_net.feature_projection.0.bias': tensor([ 0.0109,  0.0281,  0.0276, -0.0306, -0.0138, -0.0142, -0.0114,  0.0332,\n         0.0216, -0.0164, -0.0099, -0.0065,  0.0352,  0.0426, -0.0071, -0.0213,\n         0.0274, -0.0365, -0.0266,  0.0241,  0.0199, -0.0067, -0.0427, -0.0418,\n        -0.0463, -0.0036, -0.0165, -0.0231,  0.0186, -0.0108,  0.0375, -0.0059,\n        -0.0441, -0.0204,  0.0239, -0.0314,  0.0248,  0.0127,  0.0081,  0.0168,\n         0.0262, -0.0139, -0.0042, -0.0446,  0.0454,  0.0327,  0.0306, -0.0016,\n         0.0257, -0.0205, -0.0287,  0.0530,  0.0310, -0.0067,  0.0430,  0.0428,\n        -0.0106, -0.0117, -0.0193, -0.0331, -0.0264, -0.0153, -0.0219, -0.0456]), 'meta_learner.transductive_net.classifier.0.weight': tensor([[ 0.1085,  0.0156, -0.0471,  ..., -0.1017,  0.0493,  0.0873],\n        [ 0.0354, -0.0721, -0.0485,  ...,  0.0648, -0.0231, -0.1220],\n        [ 0.1213,  0.1006, -0.0341,  ...,  0.0488,  0.0830, -0.0966],\n        ...,\n        [-0.0381,  0.0148, -0.0434,  ...,  0.0175, -0.1205,  0.1147],\n        [ 0.0795,  0.1178,  0.0491,  ...,  0.0258,  0.0279, -0.0075],\n        [ 0.0990,  0.1180,  0.0064,  ..., -0.0272,  0.0402,  0.1051]]), 'meta_learner.transductive_net.classifier.0.bias': tensor([ 0.1112, -0.0530,  0.0907, -0.0695,  0.0863,  0.0175,  0.0762,  0.0895,\n         0.0733, -0.0286,  0.0249, -0.1232, -0.0718, -0.0238, -0.0476,  0.1137,\n         0.1165, -0.1087, -0.0273,  0.0712,  0.0125,  0.0819, -0.0658,  0.0951,\n        -0.0122,  0.0415,  0.0650, -0.0236,  0.0802, -0.0329, -0.0891, -0.0337,\n        -0.0798, -0.0302, -0.0576, -0.0181, -0.0642, -0.0276, -0.1159, -0.0442,\n         0.0878, -0.1041,  0.0163,  0.0508,  0.0442, -0.0354, -0.0848, -0.0764,\n        -0.0022,  0.0648,  0.0271,  0.0570, -0.0838, -0.0303, -0.0457, -0.0958,\n         0.0126,  0.0030,  0.0649,  0.0663,  0.0143,  0.0908, -0.0300,  0.1184]), 'meta_learner.transductive_net.classifier.3.weight': tensor([[-0.0011,  0.0530,  0.0833,  ...,  0.0172,  0.1173,  0.0410],\n        [ 0.0229, -0.0916,  0.0875,  ...,  0.0041,  0.0674, -0.0159],\n        [-0.0606, -0.0712,  0.1146,  ..., -0.1209, -0.0626,  0.1214],\n        ...,\n        [-0.0090, -0.0842, -0.0798,  ...,  0.0431, -0.0653, -0.1103],\n        [-0.0592,  0.0982, -0.1119,  ..., -0.1050, -0.0414, -0.0382],\n        [ 0.0714, -0.0597,  0.0671,  ...,  0.0912,  0.1072, -0.0822]]), 'meta_learner.transductive_net.classifier.3.bias': tensor([ 0.1082, -0.0661,  0.0478, -0.0855, -0.0357,  0.0472, -0.0883, -0.0870,\n        -0.0385, -0.0806, -0.0841,  0.0650, -0.0438,  0.1012, -0.0844,  0.0403,\n        -0.0835,  0.1149, -0.0098, -0.0235,  0.0694,  0.1113, -0.0759,  0.0156,\n         0.0996,  0.0961, -0.0559,  0.0328, -0.0759, -0.0719, -0.0359,  0.0462]), 'meta_learner.transductive_net.classifier.6.weight': tensor([[ 0.1284, -0.1497,  0.1353, -0.1463, -0.1261, -0.0082, -0.1502, -0.1567,\n         -0.0605,  0.0483,  0.0248,  0.0201, -0.0427, -0.0143,  0.0269,  0.0456,\n          0.1181, -0.1279,  0.0664,  0.1330,  0.1603, -0.1196,  0.0169, -0.1042,\n         -0.0470, -0.0358, -0.0604,  0.1609, -0.0006, -0.1350,  0.0209,  0.0585],\n        [-0.1260, -0.0087, -0.1290, -0.1400, -0.1081, -0.1212,  0.1194,  0.1337,\n         -0.0851,  0.0497,  0.1536, -0.1392,  0.1634,  0.1404, -0.1297, -0.0764,\n         -0.1703, -0.0717,  0.1139,  0.1243, -0.0473, -0.0174, -0.0898,  0.0098,\n          0.0984,  0.0768, -0.1139,  0.1659,  0.1370,  0.0119, -0.0950, -0.0763]]), 'meta_learner.transductive_net.classifier.6.bias': tensor([-0.1467,  0.1756]), 'meta_learner.transductive_net.self_attention.in_proj_weight': tensor([[ 0.0674, -0.0212,  0.1372,  ..., -0.0742,  0.0888, -0.0801],\n        [ 0.1124, -0.0375, -0.1314,  ...,  0.0847,  0.0886, -0.0395],\n        [ 0.1043, -0.1303,  0.0705,  ..., -0.0638, -0.0230, -0.1517],\n        ...,\n        [ 0.0060,  0.1164, -0.1425,  ..., -0.1552,  0.0568, -0.0326],\n        [-0.1185,  0.0175, -0.1329,  ...,  0.1055,  0.1437,  0.0025],\n        [-0.0600,  0.1092, -0.0575,  ...,  0.0915, -0.0347,  0.1452]]), 'meta_learner.transductive_net.self_attention.in_proj_bias': tensor([ 1.0261e-02,  3.6178e-03,  1.2051e-03, -3.0435e-03, -7.9759e-03,\n         3.0897e-04, -5.1928e-03, -1.3809e-02,  5.2834e-03, -1.7959e-03,\n         2.6285e-03, -2.0314e-03, -3.4017e-04, -8.2423e-03, -2.5285e-03,\n        -3.9059e-03,  8.3306e-03,  8.5039e-03,  2.7293e-03, -2.6980e-03,\n         1.5597e-03,  6.2315e-04,  1.9806e-03, -2.8542e-03, -5.5212e-03,\n         5.2819e-03, -3.6874e-03,  1.6197e-03,  2.7627e-04,  4.5320e-03,\n         2.1851e-03, -3.9730e-04,  5.5296e-03,  8.9722e-04,  7.4653e-03,\n         1.5864e-03,  5.1240e-03,  1.1271e-02, -8.0060e-03,  9.3561e-04,\n        -4.2321e-03,  6.2262e-03,  6.9098e-03, -3.2887e-03, -4.7896e-03,\n        -2.3899e-03, -2.1019e-03,  1.9670e-03,  5.6737e-04,  9.8631e-03,\n        -1.3482e-02,  1.0312e-02, -3.9455e-03,  1.5021e-03,  1.2135e-03,\n        -3.1954e-03, -2.4633e-04,  3.2176e-03, -4.1088e-03, -2.9458e-03,\n        -6.1411e-03,  7.9871e-03, -1.1232e-02,  6.7995e-04, -4.9961e-05,\n        -6.6776e-06,  2.4214e-05,  9.1996e-05,  4.8555e-05, -9.2225e-06,\n        -5.9669e-05, -2.5271e-05, -1.5962e-05,  1.1364e-05, -7.7334e-05,\n         2.0266e-05,  6.6692e-06,  1.0619e-05, -9.9841e-05, -3.7610e-06,\n        -5.4712e-05, -1.9466e-05, -8.4951e-05, -2.7217e-05,  2.6573e-06,\n        -1.6976e-06, -2.8648e-05, -1.1193e-05, -6.3681e-05,  2.7854e-06,\n         1.7560e-05, -5.9631e-05, -5.7448e-05, -6.4916e-05, -1.7922e-05,\n         9.7371e-06,  3.2180e-05,  1.9968e-05,  5.2381e-05, -1.8879e-05,\n         8.0648e-06,  6.4921e-05,  7.1660e-05, -1.5275e-05, -6.5872e-05,\n         5.8447e-05, -2.8962e-05,  7.9480e-05, -4.3015e-05,  4.0109e-05,\n         9.2833e-05, -3.5362e-05, -1.0229e-04, -4.6215e-05,  8.6068e-06,\n         5.8992e-06,  5.5272e-05, -8.6706e-05,  1.9338e-05,  2.8212e-05,\n        -3.0359e-06,  1.5924e-05, -9.5272e-05,  3.0646e-05,  7.9238e-05,\n        -6.4707e-05, -2.1563e-05,  3.2317e-05,  4.7984e-04,  1.0115e-04,\n        -2.8552e-05,  4.8354e-05, -8.1823e-04, -3.9542e-05, -3.8134e-04,\n        -1.5841e-04, -3.9469e-04,  6.5371e-05,  2.3555e-04,  1.5012e-04,\n        -3.9308e-05, -4.3873e-04, -6.3809e-04, -1.0205e-04,  1.1483e-04,\n        -1.2055e-04, -1.7675e-04, -2.6583e-04, -3.8598e-05,  6.8058e-04,\n        -2.7989e-04, -1.5969e-04,  1.9471e-04, -1.1241e-04, -1.4469e-04,\n         2.4843e-04,  2.7035e-04,  1.3792e-04,  3.0182e-04,  4.1087e-04,\n        -2.1532e-04, -4.5886e-04,  2.6925e-05, -2.0429e-05,  4.8243e-04,\n         1.2028e-04, -1.1032e-04, -4.7336e-04,  1.8531e-04, -4.1052e-04,\n         1.0572e-04, -1.3499e-04, -3.7210e-04,  5.3224e-05,  6.4349e-04,\n         5.1878e-04, -3.7343e-04,  2.6048e-04, -2.5689e-04,  9.7000e-05,\n         2.2427e-04, -1.1167e-04, -3.4510e-04, -6.3907e-05,  2.6481e-04,\n         4.7444e-04, -1.7102e-04, -1.4059e-04,  2.6874e-04, -1.8410e-04,\n         1.3791e-04,  1.7284e-04]), 'meta_learner.transductive_net.self_attention.out_proj.weight': tensor([[-0.0183, -0.0917, -0.0560,  ...,  0.0558,  0.0299, -0.1174],\n        [-0.0059, -0.0104, -0.0706,  ..., -0.0336, -0.1118, -0.0076],\n        [ 0.0058,  0.0200, -0.1333,  ...,  0.0608, -0.0769, -0.0833],\n        ...,\n        [ 0.0453,  0.0684,  0.0225,  ..., -0.0974,  0.0985, -0.1128],\n        [ 0.0373, -0.1105, -0.0742,  ...,  0.0056,  0.1115, -0.0089],\n        [-0.0201, -0.1012, -0.0818,  ..., -0.1004,  0.0407, -0.1162]]), 'meta_learner.transductive_net.self_attention.out_proj.bias': tensor([-5.6759e-04,  8.7137e-05,  3.3677e-04,  3.5700e-04, -2.2480e-04,\n         4.6192e-04, -4.9050e-04, -2.5446e-04, -3.5964e-04, -1.9161e-05,\n        -3.8501e-04,  5.8797e-04,  1.9353e-04,  6.9623e-04,  9.4368e-04,\n        -2.1293e-04, -3.7951e-04,  3.0390e-04, -2.8078e-04, -1.1145e-04,\n        -4.9339e-04, -4.5528e-04,  4.2801e-04, -4.0391e-04,  1.3507e-04,\n        -2.8953e-04, -1.6320e-04,  3.3874e-04, -6.2459e-06, -5.1890e-05,\n        -4.2085e-04, -2.2466e-04, -2.3955e-04,  4.4377e-05,  4.2865e-04,\n         1.5265e-06,  4.7677e-04,  6.5185e-04,  3.2703e-04,  4.7851e-05,\n        -5.3624e-04,  2.0575e-04, -4.6306e-04, -1.4248e-04,  4.6657e-05,\n        -5.3422e-04, -2.2688e-04,  2.1700e-04, -6.4433e-05, -8.6636e-05,\n        -2.6851e-04, -7.9745e-05, -2.2000e-04, -7.9793e-05, -4.9124e-04,\n         7.1899e-05, -9.3232e-05, -8.5715e-05,  1.5777e-04, -4.4143e-04,\n        -4.1621e-04, -1.9588e-04, -9.2192e-05,  6.6892e-05]), 'meta_learner.transductive_net.layer_norm.weight': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'meta_learner.transductive_net.layer_norm.bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}, sample_count=122410, training_loss=np.float64(0.17374931335449217), validation_accuracy=np.float64(0.5040000069141388), validation_precision=0.0, validation_recall=0.0, validation_f1_score=0.0, timestamp=1760251413.7995548, model_hash='6a84b563ca7ee410deda2dec73ac8aacbf0d47eb9fa1117e79952f7db84744d6', ipfs_cid='QmaqASLqf6dkCgBDK5MX9VQxPbum5wrxDoSuz2wnfw8oAg', blockchain_tx_hash='858a5f7cf2dcdc45676f6296b9057019f106815cc29d44b81bed56ae2532b417')",
        "ClientUpdate(client_id='client_3', model_parameters={'meta_learner.transductive_net.feature_extractors.0.0.weight': tensor([[ 0.0655,  0.0614, -0.1262,  ..., -0.0662, -0.0777,  0.0453],\n        [-0.0042,  0.0150, -0.0033,  ..., -0.0038,  0.0700,  0.0662],\n        [ 0.0142, -0.1020, -0.0408,  ...,  0.0003,  0.1078, -0.0814],\n        ...,\n        [ 0.0863,  0.0211, -0.0114,  ..., -0.0896,  0.0122, -0.0133],\n        [ 0.0150, -0.0824,  0.0615,  ..., -0.0900, -0.0756, -0.1131],\n        [ 0.0443, -0.0217,  0.0293,  ..., -0.0144,  0.0860, -0.1236]]), 'meta_learner.transductive_net.feature_extractors.0.0.bias': tensor([ 0.0183, -0.1303, -0.0836, -0.0717, -0.1062,  0.0516,  0.0569,  0.1134,\n         0.0502, -0.0387, -0.0184,  0.0625,  0.0651, -0.0791,  0.1195, -0.0753,\n         0.0751,  0.0675,  0.0642, -0.0154, -0.0779, -0.0894, -0.0495,  0.0425,\n        -0.1248,  0.0200, -0.1063, -0.0528,  0.0808, -0.0601,  0.0632,  0.0167,\n        -0.0284,  0.1216,  0.0886,  0.0640,  0.0013,  0.0689,  0.0306, -0.0033,\n         0.1082, -0.1184,  0.0672, -0.0579,  0.0534,  0.0262,  0.0175, -0.0957,\n        -0.0232, -0.0852, -0.1226,  0.0021,  0.0695,  0.0238,  0.0378,  0.0364,\n        -0.0690,  0.1233,  0.0517, -0.1326,  0.0558, -0.1160, -0.1261, -0.0976,\n         0.1083,  0.0239,  0.0364, -0.0784,  0.0541,  0.0637, -0.0416, -0.1213,\n         0.0781, -0.0418, -0.1311, -0.0238,  0.0454,  0.0726, -0.0730, -0.0048,\n         0.0794, -0.0744, -0.0970,  0.1199, -0.0234,  0.0643,  0.0252,  0.0028,\n         0.0222, -0.0089,  0.0296, -0.0740, -0.0912,  0.0610, -0.0237,  0.1156,\n         0.0878, -0.0013,  0.0355,  0.0947,  0.0425, -0.1078, -0.0767,  0.0380,\n        -0.0264, -0.0753, -0.0469, -0.0125, -0.0202, -0.1012, -0.0209,  0.0235,\n        -0.0401, -0.0137,  0.0328, -0.0431, -0.0312, -0.0638,  0.0924, -0.0578,\n        -0.0180,  0.1212,  0.1204, -0.0294,  0.1200,  0.0867,  0.0653, -0.0830]), 'meta_learner.transductive_net.feature_extractors.1.0.weight': tensor([[-0.0667, -0.0691,  0.1063,  ..., -0.0494, -0.0570, -0.0871],\n        [-0.0770,  0.1109, -0.1014,  ..., -0.1052,  0.0520, -0.0666],\n        [-0.0482, -0.0376,  0.1074,  ..., -0.0489, -0.0239, -0.0785],\n        ...,\n        [ 0.0921,  0.1083, -0.1045,  ..., -0.0946,  0.0748, -0.0996],\n        [ 0.1074, -0.0632,  0.0129,  ...,  0.0275, -0.0908,  0.0076],\n        [-0.0767, -0.0672,  0.0275,  ...,  0.1080, -0.0148, -0.0156]]), 'meta_learner.transductive_net.feature_extractors.1.0.bias': tensor([-0.0574,  0.0844,  0.0349, -0.0559,  0.0645, -0.0965,  0.0807,  0.0716,\n         0.0498,  0.0262,  0.0750,  0.0934,  0.0897, -0.1277,  0.0151,  0.0596,\n        -0.0067, -0.0568, -0.1088,  0.0537,  0.1143,  0.0097, -0.0658,  0.0231,\n        -0.0851, -0.1051,  0.0597,  0.0120,  0.0604,  0.0172, -0.0151, -0.0329,\n         0.0132, -0.0227,  0.0877, -0.0668, -0.0316,  0.0383,  0.0038,  0.0131,\n         0.0519,  0.0667,  0.0093,  0.0785,  0.0008, -0.1057,  0.0654,  0.0192,\n         0.1192,  0.0752, -0.0739,  0.0621, -0.0812, -0.0342, -0.0771,  0.0783,\n         0.0143,  0.0329, -0.0360,  0.0537, -0.0611, -0.0548, -0.0587,  0.1255]), 'meta_learner.transductive_net.feature_extractors.2.0.weight': tensor([[ 0.0551, -0.0883, -0.1227,  ..., -0.1074, -0.0882,  0.1147],\n        [-0.0480, -0.1181, -0.1347,  ...,  0.0269,  0.1190,  0.1176],\n        [-0.0309,  0.0596, -0.1286,  ...,  0.0699,  0.0718, -0.0278],\n        ...,\n        [-0.0758, -0.0563, -0.0644,  ...,  0.0364,  0.0090,  0.0239],\n        [-0.0790,  0.0171,  0.0502,  ..., -0.0059,  0.0682, -0.0943],\n        [-0.0570,  0.0299,  0.0637,  ...,  0.0010,  0.0305, -0.0590]]), 'meta_learner.transductive_net.feature_extractors.2.0.bias': tensor([-3.4321e-02, -2.5157e-02, -5.0105e-02, -7.1781e-02,  1.6956e-02,\n         1.0952e-01, -6.5386e-02, -4.0808e-02, -7.5039e-02,  4.6006e-02,\n        -9.2824e-02, -5.1648e-02, -4.4503e-02, -5.3478e-02,  7.4716e-02,\n        -1.2731e-01,  3.7031e-02, -3.5795e-02, -6.4938e-02, -6.0917e-03,\n        -1.0057e-01,  6.8018e-02,  1.2624e-01,  3.2202e-02,  3.6796e-02,\n        -2.0800e-02, -2.2364e-02,  3.9346e-02,  8.4151e-02,  2.8995e-02,\n        -8.3933e-02,  1.2148e-01, -2.8136e-02, -1.2951e-01,  7.2309e-02,\n         1.2561e-01,  2.1262e-02,  1.1884e-01,  1.9793e-02,  2.2444e-02,\n        -4.7580e-02, -4.6402e-02,  5.3756e-02, -3.9376e-02,  5.4520e-03,\n        -7.6315e-02,  4.2799e-02,  8.4604e-02,  4.8898e-02,  1.8325e-03,\n        -6.9150e-02, -8.7480e-03,  1.6550e-02, -2.0686e-02, -7.4765e-02,\n        -2.7476e-02,  5.6691e-03,  1.1374e-01, -5.1091e-02, -9.4874e-03,\n         9.1009e-02,  1.8111e-03,  3.4367e-02,  3.1777e-02, -9.4661e-02,\n         5.2921e-02,  5.2364e-02, -1.7435e-05, -6.6184e-02, -2.2182e-02,\n         9.6219e-02,  7.1088e-02, -5.3018e-02, -6.0122e-02,  6.6398e-02,\n         5.1574e-02, -2.0441e-02,  3.1128e-02,  5.4450e-02,  8.6382e-02,\n         5.8601e-02,  5.0468e-02, -1.1575e-02, -9.0563e-02, -9.8209e-02,\n         7.6082e-02,  8.9259e-02,  4.7167e-02, -2.4164e-02, -7.2882e-02,\n        -3.8857e-03,  3.3895e-02, -9.5684e-02,  8.3486e-02, -1.0288e-01,\n        -1.0854e-01,  8.9438e-02,  9.1491e-02,  8.4686e-02, -1.0290e-01,\n         3.7064e-02, -8.8174e-02,  2.7016e-02,  5.1626e-02, -6.0696e-02,\n         9.8416e-02, -1.0305e-01,  5.8095e-02, -3.4660e-02,  3.4390e-02,\n         3.1701e-02, -6.9518e-02,  4.1241e-02,  1.0673e-01,  8.2605e-02,\n        -5.0177e-02, -6.0495e-02,  1.1795e-01, -2.9690e-02, -5.9403e-02,\n         8.6320e-02,  2.4442e-02,  2.7390e-02,  6.1896e-02,  4.5840e-02,\n        -7.5222e-02, -4.1704e-02, -1.1008e-01, -1.2068e-01, -8.6218e-04,\n         6.9765e-02,  7.5991e-02,  5.8243e-02,  1.1760e-01, -8.9017e-02,\n         3.5690e-02,  1.0182e-01, -3.3011e-02,  3.4273e-02, -2.8177e-02,\n        -6.2501e-02, -6.6352e-02,  3.8407e-02, -7.7669e-02,  1.0912e-01,\n        -1.3230e-01,  1.0160e-01,  6.2670e-02, -1.3322e-02,  1.0451e-01,\n         1.7227e-02,  4.1514e-02, -1.0100e-01,  3.7624e-02, -3.3202e-02,\n         7.2504e-02,  9.8047e-02,  8.2961e-02, -6.9758e-02,  7.1517e-02,\n         6.5617e-02, -8.1183e-02,  3.4144e-02, -1.0240e-01,  3.1964e-02,\n         3.5679e-02,  6.7145e-02,  1.3711e-02,  5.2213e-02, -3.3769e-02,\n         4.9650e-02,  3.7275e-02, -1.2210e-01,  8.1556e-02,  4.8574e-02,\n        -4.0306e-02,  3.3458e-02, -9.1353e-02, -6.7350e-02,  7.0366e-02,\n         1.0448e-01, -7.5400e-02, -1.1237e-01,  4.7770e-02,  1.5833e-02,\n        -5.0237e-02, -8.3681e-03, -2.1636e-02,  7.0521e-02,  6.3138e-02,\n         7.7297e-02, -5.4410e-02, -5.7706e-02,  4.5878e-02, -8.2157e-03,\n        -3.8152e-02, -4.3513e-02, -3.5865e-03, -6.4582e-02,  1.3021e-01,\n        -2.1350e-02, -1.0329e-01,  1.4226e-02,  4.2039e-02, -4.3414e-02,\n        -8.6450e-02,  9.1831e-02,  2.9853e-02, -3.5689e-02, -1.1301e-01,\n         6.7117e-02, -6.6263e-02, -5.7629e-02, -1.2218e-01, -5.7558e-02,\n        -1.0235e-01, -8.3920e-02,  3.8161e-02, -1.0412e-01, -6.0853e-02,\n        -5.9698e-02, -6.1290e-02, -5.6838e-02,  1.0086e-01,  2.4539e-02,\n         4.0986e-02,  1.2269e-01, -1.2187e-01, -8.5508e-02,  1.2984e-02,\n         1.4475e-02, -3.6611e-02, -1.1524e-01,  1.0308e-01,  1.2603e-01,\n         1.5197e-02,  1.1432e-01,  1.0720e-01, -8.8032e-02,  7.6709e-02,\n        -1.0402e-01,  6.4800e-03,  2.6383e-02,  5.7794e-02,  1.0028e-01,\n         1.1529e-01,  3.1553e-02,  9.6586e-02, -1.2868e-01,  1.7214e-02,\n        -3.6168e-02, -8.9886e-02, -1.2894e-01,  2.4333e-02,  6.2965e-02,\n         2.6216e-03]), 'meta_learner.transductive_net.feature_projection.0.weight': tensor([[ 0.0015, -0.0271,  0.0122,  ..., -0.0170, -0.0415,  0.0335],\n        [ 0.0252,  0.0222, -0.0503,  ..., -0.0362,  0.0328,  0.0101],\n        [-0.0170, -0.0301, -0.0358,  ..., -0.0366,  0.0080,  0.0268],\n        ...,\n        [ 0.0052,  0.0382, -0.0203,  ...,  0.0356,  0.0334, -0.0096],\n        [-0.0354, -0.0174,  0.0268,  ...,  0.0489,  0.0339, -0.0336],\n        [-0.0144, -0.0287, -0.0033,  ...,  0.0191, -0.0260,  0.0194]]), 'meta_learner.transductive_net.feature_projection.0.bias': tensor([ 0.0203,  0.0365,  0.0099, -0.0221, -0.0137, -0.0114, -0.0178,  0.0301,\n         0.0276, -0.0169, -0.0139, -0.0169,  0.0380,  0.0473, -0.0128, -0.0142,\n         0.0229, -0.0328, -0.0203,  0.0277,  0.0175, -0.0026, -0.0471, -0.0422,\n        -0.0383, -0.0055, -0.0116, -0.0142,  0.0263, -0.0037,  0.0385, -0.0047,\n        -0.0473, -0.0280,  0.0255, -0.0179,  0.0097,  0.0089,  0.0020,  0.0175,\n         0.0316, -0.0304,  0.0044, -0.0494,  0.0475,  0.0199,  0.0292, -0.0020,\n         0.0471, -0.0175, -0.0359,  0.0358,  0.0254, -0.0038,  0.0516,  0.0361,\n        -0.0107, -0.0054, -0.0251, -0.0263, -0.0147, -0.0062, -0.0199, -0.0527]), 'meta_learner.transductive_net.classifier.0.weight': tensor([[ 0.1085,  0.0156, -0.0471,  ..., -0.1017,  0.0493,  0.0873],\n        [ 0.0354, -0.0721, -0.0485,  ...,  0.0648, -0.0231, -0.1220],\n        [ 0.1213,  0.1006, -0.0341,  ...,  0.0488,  0.0830, -0.0966],\n        ...,\n        [-0.0381,  0.0148, -0.0434,  ...,  0.0175, -0.1205,  0.1147],\n        [ 0.0795,  0.1178,  0.0491,  ...,  0.0258,  0.0279, -0.0075],\n        [ 0.0990,  0.1180,  0.0064,  ..., -0.0272,  0.0402,  0.1051]]), 'meta_learner.transductive_net.classifier.0.bias': tensor([ 0.1112, -0.0530,  0.0907, -0.0695,  0.0863,  0.0175,  0.0762,  0.0895,\n         0.0733, -0.0286,  0.0249, -0.1232, -0.0718, -0.0238, -0.0476,  0.1137,\n         0.1165, -0.1087, -0.0273,  0.0712,  0.0125,  0.0819, -0.0658,  0.0951,\n        -0.0122,  0.0415,  0.0650, -0.0236,  0.0802, -0.0329, -0.0891, -0.0337,\n        -0.0798, -0.0302, -0.0576, -0.0181, -0.0642, -0.0276, -0.1159, -0.0442,\n         0.0878, -0.1041,  0.0163,  0.0508,  0.0442, -0.0354, -0.0848, -0.0764,\n        -0.0022,  0.0648,  0.0271,  0.0570, -0.0838, -0.0303, -0.0457, -0.0958,\n         0.0126,  0.0030,  0.0649,  0.0663,  0.0143,  0.0908, -0.0300,  0.1184]), 'meta_learner.transductive_net.classifier.3.weight': tensor([[-0.0011,  0.0530,  0.0833,  ...,  0.0172,  0.1173,  0.0410],\n        [ 0.0229, -0.0916,  0.0875,  ...,  0.0041,  0.0674, -0.0159],\n        [-0.0606, -0.0712,  0.1146,  ..., -0.1209, -0.0626,  0.1214],\n        ...,\n        [-0.0090, -0.0842, -0.0798,  ...,  0.0431, -0.0653, -0.1103],\n        [-0.0592,  0.0982, -0.1119,  ..., -0.1050, -0.0414, -0.0382],\n        [ 0.0714, -0.0597,  0.0671,  ...,  0.0912,  0.1072, -0.0822]]), 'meta_learner.transductive_net.classifier.3.bias': tensor([ 0.1082, -0.0661,  0.0478, -0.0855, -0.0357,  0.0472, -0.0883, -0.0870,\n        -0.0385, -0.0806, -0.0841,  0.0650, -0.0438,  0.1012, -0.0844,  0.0403,\n        -0.0835,  0.1149, -0.0098, -0.0235,  0.0694,  0.1113, -0.0759,  0.0156,\n         0.0996,  0.0961, -0.0559,  0.0328, -0.0759, -0.0719, -0.0359,  0.0462]), 'meta_learner.transductive_net.classifier.6.weight': tensor([[ 0.1284, -0.1497,  0.1353, -0.1463, -0.1261, -0.0082, -0.1502, -0.1567,\n         -0.0605,  0.0483,  0.0248,  0.0201, -0.0427, -0.0143,  0.0269,  0.0456,\n          0.1181, -0.1279,  0.0664,  0.1330,  0.1603, -0.1196,  0.0169, -0.1042,\n         -0.0470, -0.0358, -0.0604,  0.1609, -0.0006, -0.1350,  0.0209,  0.0585],\n        [-0.1260, -0.0087, -0.1290, -0.1400, -0.1081, -0.1212,  0.1194,  0.1337,\n         -0.0851,  0.0497,  0.1536, -0.1392,  0.1634,  0.1404, -0.1297, -0.0764,\n         -0.1703, -0.0717,  0.1139,  0.1243, -0.0473, -0.0174, -0.0898,  0.0098,\n          0.0984,  0.0768, -0.1139,  0.1659,  0.1370,  0.0119, -0.0950, -0.0763]]), 'meta_learner.transductive_net.classifier.6.bias': tensor([-0.1467,  0.1756]), 'meta_learner.transductive_net.self_attention.in_proj_weight': tensor([[ 0.0844, -0.0193,  0.1439,  ..., -0.0874,  0.0892, -0.0850],\n        [ 0.1372, -0.0375, -0.1102,  ...,  0.0789,  0.0851, -0.0353],\n        [ 0.1021, -0.1341,  0.0683,  ..., -0.0593, -0.0328, -0.1533],\n        ...,\n        [ 0.0078,  0.1136, -0.1396,  ..., -0.1591,  0.0669, -0.0362],\n        [-0.1368,  0.0200, -0.1251,  ...,  0.1049,  0.1553, -0.0085],\n        [-0.0579,  0.1212, -0.0523,  ...,  0.0898, -0.0244,  0.1306]]), 'meta_learner.transductive_net.self_attention.in_proj_bias': tensor([ 9.2290e-03, -5.9338e-04,  4.1542e-03,  1.3282e-03,  2.7937e-03,\n        -7.4369e-05,  3.6961e-03,  5.3638e-03,  2.8429e-03, -1.5420e-03,\n         2.7751e-03, -3.1596e-03, -1.0097e-03,  5.9367e-04,  1.9559e-03,\n         6.9489e-03,  3.7524e-03,  2.9355e-03,  1.1324e-03, -8.4395e-03,\n         1.1539e-02, -7.6109e-04,  8.6298e-03,  2.6840e-03,  6.6140e-03,\n        -4.1833e-03,  2.5401e-04, -7.3877e-04, -8.8241e-03, -2.8994e-04,\n        -7.2194e-04, -9.2683e-04,  1.1291e-02,  4.9435e-03,  1.1254e-02,\n         1.5040e-03,  1.6668e-03, -1.0929e-03,  2.3807e-03, -1.8511e-04,\n        -4.9926e-03,  4.8292e-03, -1.1446e-04, -1.7632e-02, -1.2471e-02,\n         3.1520e-03, -2.6074e-03,  6.1047e-04,  2.4999e-03,  1.5710e-03,\n        -6.9652e-03, -5.7197e-03,  1.2462e-03, -3.3845e-03,  9.7101e-03,\n         8.9456e-03, -2.3175e-03,  1.1492e-02, -7.4986e-03,  2.6947e-03,\n        -7.0025e-04, -1.9803e-03, -8.9626e-03,  7.7892e-03,  1.6785e-05,\n        -2.0417e-05, -1.6767e-05,  2.3970e-05,  5.6334e-05, -1.6650e-05,\n        -6.1611e-05,  4.1157e-05,  1.4008e-04,  6.0129e-05,  4.2097e-05,\n         8.3524e-05, -1.7333e-05,  1.4400e-05, -7.0719e-05,  6.3924e-05,\n         3.9271e-05,  5.0577e-05,  1.9737e-05, -5.3246e-05, -7.2227e-05,\n         4.5594e-05,  2.3033e-05,  1.7921e-05,  2.0568e-05, -2.1175e-05,\n        -3.2246e-06,  1.5811e-04,  5.2630e-05,  4.1338e-05,  8.6210e-05,\n         6.1834e-05,  2.0817e-05, -4.8559e-05,  5.8127e-05,  5.6134e-05,\n         8.6205e-05,  1.9665e-04,  1.5261e-05,  7.5835e-05,  1.7109e-05,\n        -1.0053e-05, -1.0344e-04, -1.5968e-05,  4.0637e-06,  1.3613e-04,\n        -2.4539e-05,  2.3472e-05, -1.2971e-04, -3.4960e-06,  9.9927e-06,\n        -6.0236e-05,  8.7266e-05, -3.8160e-05,  5.4086e-05,  1.5128e-06,\n        -4.3456e-06, -1.4080e-04,  5.2557e-05,  6.0845e-05,  4.8627e-05,\n         1.1048e-04, -1.0457e-04,  4.0384e-06, -2.1544e-04, -3.8672e-05,\n         3.2942e-04, -2.1364e-04,  2.6126e-05,  3.5005e-04, -2.6086e-04,\n        -1.0421e-04,  1.0359e-04, -9.9352e-04, -2.6031e-04,  2.6372e-04,\n        -5.4340e-05,  3.3718e-04,  1.1229e-04, -4.0793e-04,  5.5731e-04,\n         2.0948e-04,  6.0077e-04, -1.0567e-04, -5.6667e-04, -1.4467e-04,\n        -5.3054e-04, -9.4345e-05,  9.3810e-06,  5.9610e-05,  2.5733e-04,\n        -2.4370e-04, -4.3097e-04, -1.9778e-04, -1.8013e-04, -8.5017e-05,\n        -5.0987e-04,  2.9014e-04, -5.2081e-04,  2.7635e-04, -5.3378e-05,\n        -1.2649e-04, -2.6304e-04, -7.0500e-04, -3.4936e-05, -1.9168e-04,\n         4.9134e-04, -5.5742e-05, -4.7122e-04,  3.1318e-04,  5.1352e-04,\n         1.3373e-04,  1.0921e-03,  1.5669e-04, -5.2744e-04, -2.5440e-04,\n         2.8584e-04,  7.1530e-04, -1.0322e-04, -5.8044e-05, -6.7524e-04,\n        -2.5368e-04,  1.8836e-04, -3.9838e-04, -3.3104e-04,  1.0383e-04,\n        -3.7850e-04, -4.5106e-05]), 'meta_learner.transductive_net.self_attention.out_proj.weight': tensor([[-0.0128, -0.1002, -0.0543,  ...,  0.0546,  0.0126, -0.1174],\n        [-0.0081, -0.0272, -0.0648,  ..., -0.0394, -0.1170, -0.0075],\n        [ 0.0106,  0.0209, -0.1211,  ...,  0.0683, -0.0821, -0.0916],\n        ...,\n        [ 0.0400,  0.0729,  0.0271,  ..., -0.0956,  0.1006, -0.1230],\n        [ 0.0232, -0.1131, -0.0683,  ...,  0.0056,  0.1091, -0.0025],\n        [-0.0253, -0.0939, -0.0768,  ..., -0.0958,  0.0407, -0.1168]]), 'meta_learner.transductive_net.self_attention.out_proj.bias': tensor([-4.3631e-04, -9.2783e-05, -9.8910e-05,  1.1022e-04,  1.7712e-04,\n         3.0057e-04, -4.2926e-04, -5.7373e-04,  7.1251e-05, -5.1257e-04,\n         2.6125e-05, -1.4464e-05, -2.6042e-04,  3.2139e-04,  4.7758e-05,\n         3.9664e-04, -4.0498e-05, -9.3012e-04,  1.3936e-04, -7.7808e-05,\n        -1.2569e-04, -2.8810e-04,  3.6865e-04,  1.3931e-05,  9.7170e-05,\n         3.2485e-04,  5.8282e-05, -3.6998e-04,  4.6142e-04, -2.5244e-04,\n         8.6186e-05,  2.6849e-04,  1.9802e-04,  1.7591e-05, -2.3267e-04,\n        -1.5068e-04, -4.2810e-04,  2.2128e-04, -2.3874e-04,  9.3168e-05,\n        -1.7540e-04, -1.1532e-04,  1.2645e-04, -1.6126e-04,  4.4835e-05,\n        -3.5110e-05, -5.0902e-04,  1.4994e-04, -1.6870e-04,  4.6680e-04,\n         2.4183e-04, -5.9105e-04, -3.0694e-04,  1.9463e-04,  2.4810e-04,\n         1.9471e-04,  3.4007e-04, -2.9983e-04,  4.4883e-04,  4.5133e-04,\n        -1.4102e-04,  1.2360e-04, -3.3615e-04, -7.9285e-04]), 'meta_learner.transductive_net.layer_norm.weight': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'meta_learner.transductive_net.layer_norm.bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}, sample_count=12670, training_loss=np.float64(0.1354872850328684), validation_accuracy=np.float64(0.6920000052452088), validation_precision=0.0, validation_recall=0.0, validation_f1_score=0.0, timestamp=1760251417.2987995, model_hash='83e19ee0b035441c1512c5e9e0ae93dfb1b428deeaa9cd87cfe13419cc3c2745', ipfs_cid='QmckSfRGsEGoVmkKF1FSjs4d3ke9cHkgykYZerbD3RNXBh', blockchain_tx_hash='401fb94d7f75235b1b0e2d70f89bc45a2dfef3f0663331c182100657847af7c2')"
      ],
      "aggregation_result": "AggregationResult(round_number=0, aggregated_parameters={}, client_contributions={'client_1': 0.09944265180404811, 'client_2': 0.816088429024774, 'client_3': 0.0844689191711779}, aggregation_time=0.003519773483276367, model_hash='model_round_0_1760251426', ipfs_cid='Qmf65iLqALhdRPqSXvNv2rp1qWBtZ1NhXd4jkt1fniEYnq', blockchain_tx_hash='a8efd46caf97d15c1a15f882e02ff1572aa390812b7d47f07535661975e3a83c')",
      "timestamp": 1760251430.0438142
    }
  ],
  "incentive_history": [
    {
      "round_number": 1,
      "total_rewards": 100.0,
      "individual_rewards": {
        "client_1": 35.913671742837934,
        "client_2": 29.10906982235147,
        "client_3": 34.9772584348106
      },
      "contribution_scores": {
        "client_1": 0.8054000086784363,
        "client_2": 0.6528000048398972,
        "client_3": 0.7844000036716461
      },
      "timestamp": 1760251430.0438142
    }
  ],
  "client_addresses": {},
  "config": {
    "data_path": "../DNN-EdgeIIoT-dataset.csv",
    "zero_day_attack": "DDoS_UDP",
    "available_attacks": [
      "DDoS_UDP",
      "DDoS_ICMP",
      "SQL_injection",
      "Password",
      "Vulnerability_scanner",
      "DDoS_TCP",
      "DDoS_HTTP",
      "Uploading",
      "Backdoor",
      "Port_Scanning",
      "XSS",
      "Ransomware",
      "MITM",
      "Fingerprinting"
    ],
    "input_dim": 62,
    "hidden_dim": 128,
    "embedding_dim": 64,
    "use_fully_decentralized": false,
    "support_weight": 0.3,
    "test_weight": 0.7,
    "n_way": 2,
    "k_shot": 5,
    "n_query": 15,
    "n_tasks": 10,
    "num_clients": 3,
    "num_rounds": 1,
    "learning_rate": 0.001,
    "ethereum_rpc_url": "http://localhost:8545",
    "contract_address": "0x1234567890123456789012345678901234567890",
    "ipfs_url": "http://localhost:5001",
    "enable_incentives": true,
    "incentive_contract_address": "0x1234567890123456789012345678901234567890",
    "private_key": "0x1234567890123456789012345678901234567890123456789012345678901234",
    "aggregator_address": "0x1234567890123456789012345678901234567890",
    "batch_size": 32,
    "ttt_steps": 200,
    "support_size": 50,
    "query_size": 450,
    "device": "cuda",
    "enable_blockchain": true,
    "max_samples_per_client": 50000,
    "use_data_sampling": true
  }
}