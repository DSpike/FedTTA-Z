{
  "base_model": {
    "accuracy_mean": 0.5,
    "accuracy_std": 0.0002448999942794808,
    "macro_f1_mean": 0.3333333688746723,
    "macro_f1_std": 0.00027211109721144377,
    "mcc_mean": 0.0,
    "mcc_std": 0.0,
    "confusion_matrix": [
      [
        0,
        833
      ],
      [
        0,
        833
      ]
    ],
    "roc_curve": {
      "fpr": [
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.003601440576230492,
        0.003601440576230492,
        0.006002400960384154,
        0.006002400960384154,
        0.03241296518607443,
        0.03481392557022809,
        0.12845138055222088,
        0.13085234093637454,
        0.13805522208883553,
        0.1404561824729892,
        0.1716686674669868,
        0.1716686674669868,
        0.19687875150060025,
        0.1992797118847539,
        0.23169267707082833,
        0.23169267707082833,
        0.24129651860744297,
        0.24129651860744297,
        0.2460984393757503,
        0.24849939975990396,
        0.2785114045618247,
        0.2785114045618247,
        0.2809123649459784,
        0.28331332533013204,
        0.3709483793517407,
        0.37334933973589435,
        0.3997599039615846,
        0.4021608643457383,
        0.40456182472989194,
        0.4069627851140456,
        0.4129651860744298,
        0.41536614645858344,
        0.43937575030012005,
        0.4417767106842737,
        0.46938775510204084,
        0.4717887154861945,
        0.49819927971188477,
        0.5006002400960384,
        0.5426170468187275,
        0.5450180072028812,
        0.5966386554621849,
        0.5990396158463386,
        0.6602641056422569,
        0.6626650660264105,
        0.6818727490996399,
        0.6842737094837935,
        0.6986794717887155,
        0.7010804321728692,
        0.7106842737094838,
        0.7130852340936374,
        0.7298919567827131,
        0.7298919567827131,
        0.7310924369747899,
        0.7310924369747899,
        0.7575030012004802,
        0.7575030012004802,
        0.7683073229291717,
        0.7683073229291717,
        0.7743097238895558,
        0.7743097238895558,
        0.7779111644657863,
        0.78031212484994,
        0.7839135654261705,
        0.7863145258103241,
        0.7911164465786314,
        0.7935174069627852,
        0.7995198079231692,
        0.7995198079231692,
        0.8055222088835534,
        0.8079231692677071,
        0.8103241296518607,
        0.8127250900360145,
        0.8139255702280912,
        0.8139255702280912,
        0.8283313325330132,
        0.8283313325330132,
        0.8319327731092437,
        0.8319327731092437,
        0.8379351740696278,
        0.8379351740696278,
        0.843937575030012,
        0.843937575030012,
        0.8463385354141657,
        0.8463385354141657,
        0.8475390156062425,
        0.8475390156062425,
        0.8487394957983193,
        0.8487394957983193,
        0.8499399759903962,
        0.8499399759903962,
        0.851140456182473,
        0.851140456182473,
        0.8523409363745498,
        0.8523409363745498,
        0.8535414165666266,
        0.8535414165666266,
        0.8547418967587035,
        0.8547418967587035,
        0.8559423769507803,
        0.8559423769507803,
        0.957983193277311,
        0.9603841536614646,
        0.9711884753901561,
        0.9735894357743097,
        1.0
      ],
      "tpr": [
        0.0,
        0.0012004801920768306,
        0.003601440576230492,
        0.009603841536614645,
        0.014405762304921969,
        0.01800720288115246,
        0.02040816326530612,
        0.024009603841536616,
        0.028811524609843937,
        0.030012004801920768,
        0.03481392557022809,
        0.03721488595438175,
        0.04201680672268908,
        0.05402160864345738,
        0.058823529411764705,
        0.061224489795918366,
        0.06362545018007203,
        0.06482593037214886,
        0.07202881152460984,
        0.07563025210084033,
        0.07803121248499399,
        0.08163265306122448,
        0.11644657863145258,
        0.11884753901560624,
        0.12244897959183673,
        0.12484993997599039,
        0.13445378151260504,
        0.13925570228091236,
        0.1452581032412965,
        0.14765906362545017,
        0.16806722689075632,
        0.17046818727490998,
        0.18007202881152462,
        0.18487394957983194,
        0.18967587034813926,
        0.19207683073229292,
        0.19807923169267708,
        0.20048019207683074,
        0.21008403361344538,
        0.21248499399759904,
        0.21968787515006002,
        0.22208883553421369,
        0.22448979591836735,
        0.226890756302521,
        0.23649459783913565,
        0.2388955582232893,
        0.25090036014405764,
        0.2533013205282113,
        0.2545018007202881,
        0.2617046818727491,
        0.27130852340936373,
        0.2737094837935174,
        0.27490996398559425,
        0.2773109243697479,
        0.2785114045618247,
        0.2809123649459784,
        0.28211284513805523,
        0.28691476590636256,
        0.2893157262905162,
        0.2917166866746699,
        0.297719087635054,
        0.30012004801920766,
        0.3097238895558223,
        0.31212484993997597,
        0.3157262905162065,
        0.3169267707082833,
        0.31932773109243695,
        0.32653061224489793,
        0.3289315726290516,
        0.3517406962785114,
        0.35414165666266506,
        0.3577430972388956,
        0.36014405762304924,
        0.368547418967587,
        0.3709483793517407,
        0.3745498199279712,
        0.37695078031212487,
        0.4141656662665066,
        0.41656662665066024,
        0.4261704681872749,
        0.42857142857142855,
        0.4369747899159664,
        0.44057623049219685,
        0.4429771908763505,
        0.45858343337334934,
        0.46338535414165666,
        0.4789915966386555,
        0.48139255702280914,
        0.4885954381752701,
        0.4909963985594238,
        0.4921968787515006,
        0.49459783913565425,
        0.5138055222088835,
        0.5162064825930373,
        0.5330132052821128,
        0.5354141656662665,
        0.5414165666266506,
        0.5438175270108043,
        0.5462184873949579,
        0.5486194477791116,
        0.5522208883553421,
        0.5558223289315727,
        0.5570228091236494,
        0.5594237695078031,
        0.575030012004802,
        0.5798319327731093,
        0.5822328931572629,
        0.5846338535414166,
        0.6350540216086434,
        0.6386554621848739,
        0.6422569027611045,
        0.6446578631452581,
        0.6650660264105642,
        0.6674669867947179,
        0.6866746698679472,
        0.6890756302521008,
        0.7202881152460985,
        0.7226890756302521,
        0.7274909963985594,
        0.7298919567827131,
        0.7623049219687875,
        0.7647058823529411,
        0.7779111644657863,
        0.78031212484994,
        0.7815126050420168,
        0.7839135654261705,
        0.8307322929171669,
        0.8331332533013205,
        0.8415366146458584,
        0.843937575030012,
        0.8487394957983193,
        0.851140456182473,
        0.8619447779111644,
        0.8643457382953181,
        0.8679471788715486,
        0.8703481392557023,
        0.8763505402160864,
        0.8787515006002401,
        0.8823529411764706,
        0.8847539015606243,
        0.8907563025210085,
        0.8931572629051621,
        0.9411764705882353,
        0.9411764705882353,
        0.9423769507803121,
        0.9423769507803121,
        0.943577430972389,
        0.943577430972389,
        0.943577430972389,
        0.943577430972389,
        0.943577430972389,
        0.943577430972389,
        0.943577430972389,
        0.943577430972389,
        0.9447779111644657,
        0.9447779111644657,
        0.9447779111644657,
        0.9447779111644657,
        0.9459783913565426,
        0.9459783913565426,
        0.9471788715486195,
        0.9471788715486195,
        0.9471788715486195,
        0.9471788715486195,
        0.9483793517406963,
        0.9483793517406963,
        0.9483793517406963,
        0.9483793517406963,
        0.9483793517406963,
        0.9483793517406963,
        0.9483793517406963,
        0.9483793517406963,
        0.9483793517406963,
        0.9483793517406963,
        0.9483793517406963,
        0.9483793517406963,
        0.9483793517406963,
        0.9483793517406963,
        0.9483793517406963,
        0.9483793517406963,
        0.9483793517406963,
        0.9483793517406963,
        0.9483793517406963,
        0.9483793517406963,
        0.9483793517406963,
        0.9483793517406963,
        0.9483793517406963,
        0.9483793517406963,
        0.9483793517406963,
        0.9483793517406963,
        0.9483793517406963,
        0.9483793517406963,
        0.9483793517406963,
        0.9483793517406963,
        0.9495798319327731,
        0.9495798319327731,
        0.9507803121248499,
        0.9507803121248499,
        0.9519807923169268,
        0.9519807923169268,
        0.9531812725090036,
        0.9531812725090036,
        0.9543817527010804,
        0.9543817527010804,
        0.9543817527010804,
        0.9543817527010804,
        0.9543817527010804,
        0.9543817527010804,
        0.9543817527010804,
        0.9543817527010804,
        0.9567827130852341,
        0.9567827130852341,
        0.9567827130852341,
        0.9567827130852341,
        0.9567827130852341,
        0.9567827130852341,
        0.957983193277311,
        0.957983193277311,
        0.9591836734693877,
        0.9591836734693877,
        0.9615846338535414,
        0.9615846338535414,
        0.9627851140456183,
        0.9627851140456183,
        0.963985594237695,
        0.963985594237695,
        0.9651860744297719,
        0.9651860744297719,
        0.9675870348139256,
        0.9675870348139256,
        0.9687875150060024,
        0.9687875150060024,
        0.9771908763505402,
        0.9771908763505402,
        0.9807923169267707,
        0.9807923169267707,
        0.985594237695078,
        0.985594237695078,
        0.9891956782713085,
        0.9891956782713085,
        0.9951980792316927,
        0.9963985594237695,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0
      ],
      "thresholds": [
          null,
        0.535500705242157,
        0.5355002880096436,
        0.5354989767074585,
        0.5354985594749451,
        0.5354982018470764,
        0.5354981422424316,
        0.535497784614563,
        0.5354974269866943,
        0.5354973673820496,
        0.53549724817276,
        0.5354969501495361,
        0.5354967713356018,
        0.535495400428772,
        0.5354951620101929,
        0.5354949831962585,
        0.5354949235916138,
        0.535494863986969,
        0.5354941487312317,
        0.5354939103126526,
        0.535493791103363,
        0.5354937314987183,
        0.5354633331298828,
        0.5354627370834351,
        0.535461962223053,
        0.5354610085487366,
        0.5354580283164978,
        0.5354563593864441,
        0.5354539155960083,
        0.5354537963867188,
        0.5354477167129517,
        0.5354472994804382,
        0.5354449152946472,
        0.5354444980621338,
        0.5354430079460144,
        0.5354428887367249,
        0.5354417562484741,
        0.5354410409927368,
        0.5354381799697876,
        0.5354377627372742,
        0.5354359745979309,
        0.5354359149932861,
        0.5354357957839966,
        0.5354355573654175,
        0.535432755947113,
        0.5354326367378235,
        0.5354294776916504,
        0.5354292392730713,
        0.535429060459137,
        0.5354283452033997,
        0.5354267954826355,
        0.535426676273346,
        0.5354263186454773,
        0.5354261994361877,
        0.5354259014129639,
        0.5354257225990295,
        0.5354255437850952,
        0.5354252457618713,
        0.5354243516921997,
        0.5354241132736206,
        0.5354233384132385,
        0.5354230999946594,
        0.5354210138320923,
        0.5354206562042236,
        0.5354205965995789,
        0.5354202389717102,
        0.5354195833206177,
        0.5354177951812744,
        0.5354174375534058,
        0.5354140996932983,
        0.5354139804840088,
        0.5354130864143372,
        0.5354129672050476,
        0.5354109406471252,
        0.5354108214378357,
        0.5354104042053223,
        0.5354103446006775,
        0.535402774810791,
        0.5354025959968567,
        0.5354018211364746,
        0.5354015231132507,
        0.5354002118110657,
        0.5353987216949463,
        0.5353983044624329,
        0.5353947877883911,
        0.5353944301605225,
        0.5353897213935852,
        0.5353893637657166,
        0.5353870391845703,
        0.5353869199752808,
        0.535386860370636,
        0.5353866815567017,
        0.5353803038597107,
        0.5353798866271973,
        0.5353758931159973,
        0.535375714302063,
        0.535373866558075,
        0.5353730916976929,
        0.5353726744651794,
        0.5353725552558899,
        0.5353714227676392,
        0.5353713631629944,
        0.5353711843490601,
        0.5353702902793884,
        0.5353657603263855,
        0.5353654026985168,
        0.5353647470474243,
        0.5353642106056213,
        0.5353534817695618,
        0.5353532433509827,
        0.5353524088859558,
        0.535352349281311,
        0.535345196723938,
        0.535344660282135,
        0.5353361368179321,
        0.5353343486785889,
        0.5353220701217651,
        0.5353215932846069,
        0.535319447517395,
        0.5353193879127502,
        0.5352989435195923,
        0.5352988839149475,
        0.5352939963340759,
        0.5352936387062073,
        0.5352935194969177,
        0.535293459892273,
        0.5352783799171448,
        0.5352766513824463,
        0.5352734923362732,
        0.5352729558944702,
        0.5352714657783508,
        0.535271406173706,
        0.5352689623832703,
        0.5352684855461121,
        0.5352669358253479,
        0.5352661609649658,
        0.535264253616333,
        0.53526371717453,
        0.5352621674537659,
        0.5352619886398315,
        0.5352597832679749,
        0.5352593660354614,
        0.5352240204811096,
        0.5352171063423157,
        0.5351870656013489,
        0.5350804924964905,
        0.5350795984268188,
        0.535018801689148,
        0.535018265247345,
        0.5349474549293518,
        0.5349467396736145,
        0.5349382162094116,
        0.5349374413490295,
        0.5348676443099976,
        0.5348672270774841,
        0.5348321199417114,
        0.5348286628723145,
        0.5347930788993835,
        0.5347927808761597,
        0.534778892993927,
        0.5347782373428345,
        0.5347718000411987,
        0.534771203994751,
        0.534741997718811,
        0.5347403883934021,
        0.5347346663475037,
        0.5347344875335693,
        0.5346617102622986,
        0.534660816192627,
        0.5346469879150391,
        0.5346466898918152,
        0.5346465110778809,
        0.5346464514732361,
        0.5346441864967346,
        0.5346437096595764,
        0.534632682800293,
        0.5346326231956482,
        0.5346200466156006,
        0.5346199870109558,
        0.53460294008255,
        0.534602165222168,
        0.53456711769104,
        0.5345644354820251,
        0.5345258116722107,
        0.5345249772071838,
        0.53449946641922,
        0.5344988107681274,
        0.5344917178153992,
        0.5344911813735962,
        0.5344846248626709,
        0.5344836115837097,
        0.5344803333282471,
        0.5344789624214172,
        0.5344716310501099,
        0.5344710350036621,
        0.5344706773757935,
        0.5344699621200562,
        0.5344536304473877,
        0.5344524383544922,
        0.5344457030296326,
        0.5344440937042236,
        0.5344363451004028,
        0.5344361662864685,
        0.5344344973564148,
        0.5344343185424805,
        0.5344340801239014,
        0.534433901309967,
        0.5344328284263611,
        0.5344312191009521,
        0.5344281196594238,
        0.5344274640083313,
        0.5344253182411194,
        0.5344250202178955,
        0.5344234108924866,
        0.5344229340553284,
        0.534421980381012,
        0.5344215631484985,
        0.5344136357307434,
        0.5344130992889404,
        0.5344120264053345,
        0.5344110131263733,
        0.5344061255455017,
        0.5344046950340271,
        0.5343983769416809,
        0.5343974828720093,
        0.5343947410583496,
        0.5343944430351257,
        0.5343940258026123,
        0.5343906283378601,
        0.5343900918960571,
        0.5343899726867676,
        0.534389853477478,
        0.5343858003616333,
        0.534384548664093,
        0.5343840718269348,
        0.53438401222229,
        0.5343810319900513,
        0.5343807339668274,
        0.5343765020370483,
        0.5343759059906006,
        0.5343745350837708,
        0.5343742966651917,
        0.5343719124794006,
        0.5341609716415405,
        0.5341604948043823,
        0.5341562032699585,
        0.5341556072235107,
        0.5340314507484436
      ]
    },
    "roc_auc": 0.9557731856247902,
    "optimal_threshold": 0.5352240204811096,
    "precision_mean": 0.5,
    "recall_mean": 1.0
  },
  "ttt_model": {
    "accuracy_mean": 0.9998000000000001,
    "accuracy_std": 0.00040000000000000034,
    "macro_f1_mean": 0.9997999997999998,
    "macro_f1_std": 0.00040000040000038873,
    "mcc_mean": 0.9996003992011977,
    "mcc_std": 0.0007992015976047818,
    "confusion_matrix": [
      [
        500,
        0
      ],
      [
        0,
        500
      ]
    ],
    "roc_curve": {
      "fpr": [
        0.0,
        0.0,
        0.234,
        0.246,
        1.0
      ],
      "tpr": [
        0.0,
        1.0,
        1.0,
        1.0,
        1.0
      ],
      "thresholds": [
          null,
        1.0,
        5.605193857299268e-45,
        1.401298464324817e-45,
        0.0
      ]
    },
    "roc_auc": 1.0,
    "optimal_threshold": 1.0,
    "ttt_adaptation_data": {
      "steps": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50,
        51,
        52,
        53,
        54,
        55,
        56,
        57,
        58,
        59,
        60,
        61,
        62,
        63,
        64,
        65,
        66,
        67,
        68,
        69,
        70,
        71,
        72,
        73,
        74,
        75,
        76,
        77,
        78,
        79,
        80,
        81,
        82,
        83,
        84,
        85,
        86,
        87,
        88,
        89,
        90,
        91,
        92,
        93,
        94,
        95,
        96,
        97,
        98,
        99,
        100,
        101,
        102,
        103,
        104,
        105,
        106,
        107,
        108,
        109,
        110,
        111,
        112,
        113,
        114,
        115,
        116,
        117,
        118,
        119,
        120,
        121,
        122,
        123,
        124,
        125,
        126,
        127,
        128,
        129,
        130,
        131,
        132,
        133,
        134,
        135,
        136,
        137,
        138,
        139,
        140,
        141,
        142,
        143,
        144,
        145,
        146,
        147,
        148,
        149,
        150,
        151,
        152,
        153,
        154,
        155,
        156,
        157,
        158,
        159,
        160,
        161,
        162,
        163,
        164,
        165,
        166,
        167,
        168,
        169,
        170,
        171,
        172,
        173,
        174,
        175,
        176,
        177,
        178,
        179,
        180,
        181,
        182,
        183,
        184,
        185,
        186,
        187,
        188,
        189,
        190,
        191,
        192,
        193,
        194,
        195,
        196,
        197,
        198,
        199
      ],
      "total_losses": [
        0.6974409222602844,
        0.6935396194458008,
        0.6922172904014587,
        0.6891898512840271,
        0.6900436878204346,
        0.6871317625045776,
        0.6748405694961548,
        0.6670123338699341,
        0.6614867448806763,
        0.6458075642585754,
        0.6332198977470398,
        0.6105422377586365,
        0.5876967310905457,
        0.554385244846344,
        0.531826913356781,
        0.48698821663856506,
        0.4581761062145233,
        0.40812841057777405,
        0.3675929605960846,
        0.3220761716365814,
        0.28409039974212646,
        0.24430660903453827,
        0.20866072177886963,
        0.1721833199262619,
        0.14156918227672577,
        0.1237509474158287,
        0.08879005163908005,
        0.07414717972278595,
        0.0642998218536377,
        0.04541144520044327,
        0.03564951941370964,
        0.030834494158625603,
        0.02334175817668438,
        0.016792235895991325,
        0.016678795218467712,
        0.014500143937766552,
        0.009639004245400429,
        0.008550282567739487,
        0.006956311874091625,
        0.006872296333312988,
        0.007446129806339741,
        0.005352693609893322,
        0.003089368110522628,
        0.003331150161102414,
        0.004142432007938623,
        0.0028657186776399612,
        0.0019815503619611263,
        0.003861917881295085,
        0.003536537056788802,
        0.0017287309747189283,
        0.0017657680436968803,
        0.0020012848544865847,
        0.0028617563657462597,
        0.0024453874211758375,
        0.001144783804193139,
        0.002049035392701626,
        0.0014705449575558305,
        0.0017656557029113173,
        0.001002619625069201,
        0.000834152044262737,
        0.0019041551277041435,
        0.0014976036036387086,
        0.000977391260676086,
        0.0009338544332422316,
        0.0002602271270006895,
        0.0014582588337361813,
        0.0003468651557341218,
        0.0016120433574542403,
        0.0005794957396574318,
        0.0017373862210661173,
        0.0006711884634569287,
        0.0016011577099561691,
        0.0007431181729771197,
        0.0006541237817145884,
        0.0007874977309256792,
        0.0011583658633753657,
        0.0008811419829726219,
        0.0013602632097899914,
        0.0002143950405297801,
        0.0009452212834730744,
        0.0014327001990750432,
        0.0005585853359661996,
        0.0007875121664255857,
        0.00043476399150677025,
        0.0009851022623479366,
        0.0008680629543960094,
        0.0006308817537501454,
        0.00080939318286255,
        0.001317816087976098,
        0.00020811008289456367,
        0.0008413819596171379,
        0.0009235760080628097,
        0.0008559564594179392,
        0.00029666084446944296,
        0.00048691153642721474,
        0.000513874227181077,
        0.0002912598429247737,
        0.0005169946234673262,
        0.0003275696362834424,
        0.0005694818682968616,
        0.00026562652783468366,
        0.00020950954058207572,
        0.0006856377003714442,
        0.0010313126258552074,
        0.0004832721606362611,
        0.0008910948527045548,
        0.00017390969151165336,
        0.0011149317724630237,
        0.00019999142386950552,
        0.0006860965513624251,
        0.000940745638217777,
        0.0003832301590591669,
        0.0010912700090557337,
        0.002527005271986127,
        0.0003538137534633279,
        0.0007906095706857741,
        0.00012035290274070576,
        0.00012067182979080826,
        0.0002147548511857167,
        0.00031600729562342167,
        0.0005219347658567131,
        0.0002293694269610569,
        0.00019865341892000288,
        0.00045345109538175166,
        0.00020283172489143908,
        0.0007768163341097534,
        0.00046956428559497,
        0.0005026921862736344,
        0.0008193604298867285,
        0.0002303262590430677,
        0.0007363513577729464,
        0.0001076272819773294,
        0.0004211021587252617,
        0.0002642505569383502,
        0.0007254256051965058,
        0.000779791153036058,
        0.0005346901598386467,
        0.0006859131972305477,
        0.0003253057657275349,
        0.00033455147058703005,
        0.0001958822103915736,
        0.0007409998215734959,
        0.00012573922867886722,
        0.0002476741501595825,
        0.0003863663296215236,
        0.00017617756384424865,
        0.0018643202492967248,
        0.0006307287258096039,
        0.00038840810884721577,
        0.00045418814988806844,
        0.0002939340774901211,
        0.00021046384063083678,
        0.00027807633159682155,
        0.00028035277500748634,
        0.00019484138465486467,
        0.0005163316382095218,
        0.00035407699760980904,
        0.0001357932051178068,
        7.574185292469338e-05,
        0.00012684380635619164,
        0.0013542226515710354,
        0.0005518189282156527,
        0.0009663128876127303,
        0.00022149679716676474,
        0.00012930108641739935,
        0.0004314311081543565,
        0.00023765441437717527,
        0.0002751107094809413,
        0.0008162397425621748,
        0.0009507735958322883,
        0.00019861714099533856,
        0.00042968924390152097,
        0.0009811784839257598,
        0.0010676451493054628,
        0.0003728723095264286,
        0.00038263422902673483,
        0.00012751610483974218,
        0.0004951063310727477,
        0.0004000102635473013,
        0.00018440582789480686,
        0.0006767056765966117,
        0.00035723819746635854,
        0.0007626489386893809,
        0.00040843759779818356,
        0.0008574945386499166,
        0.0007487137336283922,
        0.0002477859961800277,
        0.0002044408756773919,
        0.00033050982165150344,
        0.0008831598679535091,
        0.00017442581884097308,
        0.0008455926435999572,
        0.0003689811856020242,
        0.0008769006235525012,
        0.0005389856523834169,
        0.0006507021025754511,
        0.00031063330243341625,
        0.0002547251642681658,
        0.0005592289962805808,
        0.00017368090630043298
      ],
      "support_losses": [
        0.6974409222602844,
        0.6935396194458008,
        0.6922172904014587,
        0.6891898512840271,
        0.6900436878204346,
        0.6871317625045776,
        0.6748405694961548,
        0.6670123338699341,
        0.6614867448806763,
        0.6458075642585754,
        0.6332198977470398,
        0.6105422377586365,
        0.5876967310905457,
        0.554385244846344,
        0.531826913356781,
        0.48698821663856506,
        0.4581761062145233,
        0.40812841057777405,
        0.3675929605960846,
        0.3220761716365814,
        0.28409039974212646,
        0.24430660903453827,
        0.20866072177886963,
        0.1721833199262619,
        0.14156918227672577,
        0.1237509474158287,
        0.08879005163908005,
        0.07414717972278595,
        0.0642998218536377,
        0.04541144520044327,
        0.03564951941370964,
        0.030834494158625603,
        0.02334175817668438,
        0.016792235895991325,
        0.016678795218467712,
        0.014500143937766552,
        0.009639004245400429,
        0.008550282567739487,
        0.006956311874091625,
        0.006872296333312988,
        0.007446129806339741,
        0.005352693609893322,
        0.003089368110522628,
        0.003331150161102414,
        0.004142432007938623,
        0.0028657186776399612,
        0.0019815503619611263,
        0.003861917881295085,
        0.003536537056788802,
        0.0017287309747189283,
        0.0017657680436968803,
        0.0020012848544865847,
        0.0028617563657462597,
        0.0024453874211758375,
        0.001144783804193139,
        0.002049035392701626,
        0.0014705449575558305,
        0.0017656557029113173,
        0.001002619625069201,
        0.000834152044262737,
        0.0019041551277041435,
        0.0014976036036387086,
        0.000977391260676086,
        0.0009338544332422316,
        0.0002602271270006895,
        0.0014582588337361813,
        0.0003468651557341218,
        0.0016120433574542403,
        0.0005794957396574318,
        0.0017373862210661173,
        0.0006711884634569287,
        0.0016011577099561691,
        0.0007431181729771197,
        0.0006541237817145884,
        0.0007874977309256792,
        0.0011583658633753657,
        0.0008811419829726219,
        0.0013602632097899914,
        0.0002143950405297801,
        0.0009452212834730744,
        0.0014327001990750432,
        0.0005585853359661996,
        0.0007875121664255857,
        0.00043476399150677025,
        0.0009851022623479366,
        0.0008680629543960094,
        0.0006308817537501454,
        0.00080939318286255,
        0.001317816087976098,
        0.00020811008289456367,
        0.0008413819596171379,
        0.0009235760080628097,
        0.0008559564594179392,
        0.00029666084446944296,
        0.00048691153642721474,
        0.000513874227181077,
        0.0002912598429247737,
        0.0005169946234673262,
        0.0003275696362834424,
        0.0005694818682968616,
        0.00026562652783468366,
        0.00020950954058207572,
        0.0006856377003714442,
        0.0010313126258552074,
        0.0004832721606362611,
        0.0008910948527045548,
        0.00017390969151165336,
        0.0011149317724630237,
        0.00019999142386950552,
        0.0006860965513624251,
        0.000940745638217777,
        0.0003832301590591669,
        0.0010912700090557337,
        0.002527005271986127,
        0.0003538137534633279,
        0.0007906095706857741,
        0.00012035290274070576,
        0.00012067182979080826,
        0.0002147548511857167,
        0.00031600729562342167,
        0.0005219347658567131,
        0.0002293694269610569,
        0.00019865341892000288,
        0.00045345109538175166,
        0.00020283172489143908,
        0.0007768163341097534,
        0.00046956428559497,
        0.0005026921862736344,
        0.0008193604298867285,
        0.0002303262590430677,
        0.0007363513577729464,
        0.0001076272819773294,
        0.0004211021587252617,
        0.0002642505569383502,
        0.0007254256051965058,
        0.000779791153036058,
        0.0005346901598386467,
        0.0006859131972305477,
        0.0003253057657275349,
        0.00033455147058703005,
        0.0001958822103915736,
        0.0007409998215734959,
        0.00012573922867886722,
        0.0002476741501595825,
        0.0003863663296215236,
        0.00017617756384424865,
        0.0018643202492967248,
        0.0006307287258096039,
        0.00038840810884721577,
        0.00045418814988806844,
        0.0002939340774901211,
        0.00021046384063083678,
        0.00027807633159682155,
        0.00028035277500748634,
        0.00019484138465486467,
        0.0005163316382095218,
        0.00035407699760980904,
        0.0001357932051178068,
        7.574185292469338e-05,
        0.00012684380635619164,
        0.0013542226515710354,
        0.0005518189282156527,
        0.0009663128876127303,
        0.00022149679716676474,
        0.00012930108641739935,
        0.0004314311081543565,
        0.00023765441437717527,
        0.0002751107094809413,
        0.0008162397425621748,
        0.0009507735958322883,
        0.00019861714099533856,
        0.00042968924390152097,
        0.0009811784839257598,
        0.0010676451493054628,
        0.0003728723095264286,
        0.00038263422902673483,
        0.00012751610483974218,
        0.0004951063310727477,
        0.0004000102635473013,
        0.00018440582789480686,
        0.0006767056765966117,
        0.00035723819746635854,
        0.0007626489386893809,
        0.00040843759779818356,
        0.0008574945386499166,
        0.0007487137336283922,
        0.0002477859961800277,
        0.0002044408756773919,
        0.00033050982165150344,
        0.0008831598679535091,
        0.00017442581884097308,
        0.0008455926435999572,
        0.0003689811856020242,
        0.0008769006235525012,
        0.0005389856523834169,
        0.0006507021025754511,
        0.00031063330243341625,
        0.0002547251642681658,
        0.0005592289962805808,
        0.00017368090630043298
      ],
      "consistency_losses": [
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0
      ]
    },
    "precision_mean": 1.0,
    "recall_mean": 1.0
  },
  "dataset_info": {
    "name": "Edge-IIoTset",
    "total_samples": 100306,
    "evaluated_samples": 10000,
    "features": 61,
    "attack_types": 15,
    "zero_day_attack": "Password",
    "zero_day_stats": {
      "zero_day_attack": "Password",
      "zero_day_samples": 50153,
      "zero_day_percentage": 8.320793439326547,
      "total_attack_samples": 602743,
      "normal_samples": 1615643,
      "total_samples": 2218386,
      "available_attacks": [
        "Normal",
        "DDoS_UDP",
        "DDoS_ICMP",
        "SQL_injection",
        "Password",
        "Vulnerability_scanner",
        "DDoS_TCP",
        "DDoS_HTTP",
        "Uploading",
        "Backdoor",
        "Port_Scanning",
        "XSS",
        "Ransomware",
        "Fingerprinting",
        "MITM"
      ]
    }
  },
  "final_global_model": {
    "accuracy": 0.9998,
    "f1_score": 0.9997999999920001,
    "mcc": 0.9996000799680095,
    "roc_auc": 0.9998,
    "optimal_threshold": 0.5,
    "roc_curve": {
      "fpr": [
        0.0,
        0.0004,
        1.0
      ],
      "tpr": [
        0.0,
        1.0,
        1.0
      ],
      "thresholds": [
          null,
        0.9999998807907104,
        1.0000000116860974e-07
      ]
    },
    "confusion_matrix": [
      [
        2499,
        1
      ],
      [
        0,
        2500
      ]
    ],
    "test_samples": 5000,
    "dataset_info": {
      "name": "Edge-IIoTset",
      "total_samples": 100306,
      "evaluated_samples": 5000,
      "features": 61,
      "attack_types": 15,
      "zero_day_attack": "Password"
    }
  },
  "training_history": [
    {
      "round_number": 0,
      "client_updates": [
        "ClientUpdate(client_id='client_1', model_parameters={'meta_learner.transductive_net.feature_extractors.0.0.weight': tensor([[ 0.0053, -0.0601,  0.1012,  ...,  0.1116,  0.1089, -0.1126],\n        [ 0.0073, -0.0206,  0.0544,  ..., -0.0288, -0.0815,  0.0435],\n        [ 0.0746, -0.0185,  0.0446,  ..., -0.1044, -0.0184,  0.1176],\n        ...,\n        [-0.0578,  0.0608,  0.0493,  ...,  0.0178, -0.0288,  0.0814],\n        [-0.0300, -0.0204, -0.0574,  ...,  0.0788,  0.0952, -0.0470],\n        [ 0.1192, -0.1041,  0.1352,  ...,  0.0474,  0.0447, -0.0725]]), 'meta_learner.transductive_net.feature_extractors.0.0.bias': tensor([ 0.1281, -0.0687,  0.0214,  0.1011,  0.0626,  0.0628,  0.0523,  0.0265,\n         0.0466, -0.0907,  0.0568,  0.0733,  0.0695,  0.0210,  0.1158, -0.0092,\n        -0.0285,  0.0513, -0.0839, -0.1123,  0.0584, -0.1087, -0.0533,  0.0377,\n        -0.1221,  0.0788, -0.0378, -0.0602,  0.0797,  0.0781, -0.1209,  0.0234,\n        -0.1299,  0.0780,  0.0468,  0.0509,  0.1060, -0.0990,  0.0345,  0.0580,\n        -0.0323, -0.1190, -0.1052,  0.0978, -0.0524, -0.1016,  0.0917, -0.0196,\n        -0.1010,  0.0502,  0.1017, -0.1049, -0.1304,  0.1080,  0.0507,  0.0186,\n         0.0359, -0.0558, -0.0888, -0.0835,  0.1132, -0.1219,  0.0505, -0.0116,\n        -0.0584, -0.1125, -0.1020,  0.1062,  0.0517, -0.0904,  0.0749,  0.0100,\n        -0.0614,  0.0580,  0.1328,  0.0345,  0.0812, -0.0666,  0.0760,  0.1131,\n        -0.0584, -0.1039, -0.0946,  0.0293,  0.0765,  0.0031, -0.0499, -0.0798,\n        -0.0546, -0.0686, -0.0379, -0.0595, -0.0318, -0.1239, -0.1214, -0.1074,\n        -0.0353,  0.0484, -0.0355, -0.0494, -0.1072, -0.0544, -0.0578, -0.0143,\n        -0.0348,  0.0796, -0.0521,  0.1175,  0.0464,  0.1161,  0.0870, -0.0394,\n        -0.0423,  0.0702, -0.0674,  0.0401,  0.0342,  0.0751, -0.0668, -0.0434,\n        -0.0729, -0.0446,  0.0263,  0.0828, -0.0762,  0.0111,  0.0048,  0.0872]), 'meta_learner.transductive_net.feature_extractors.1.0.weight': tensor([[-0.0534, -0.0790, -0.0134,  ..., -0.0081,  0.1020, -0.0337],\n        [-0.0692, -0.1242,  0.0972,  ..., -0.0125, -0.0414, -0.1002],\n        [-0.0338, -0.0171,  0.0312,  ..., -0.0935,  0.0956,  0.1234],\n        ...,\n        [-0.0967, -0.0383, -0.0997,  ...,  0.0326, -0.0295,  0.0179],\n        [-0.0096,  0.0912,  0.0754,  ..., -0.0533,  0.1033,  0.1166],\n        [-0.0435,  0.0822, -0.0035,  ..., -0.0820, -0.0457,  0.0346]]), 'meta_learner.transductive_net.feature_extractors.1.0.bias': tensor([-0.0003, -0.0334, -0.0404,  0.0885,  0.0989, -0.0421, -0.1148,  0.0041,\n         0.0908,  0.0798, -0.0295,  0.0113, -0.1000,  0.1207,  0.1036, -0.0096,\n         0.0621, -0.1254, -0.0702,  0.0135, -0.0395,  0.0706, -0.0857,  0.1227,\n         0.0452,  0.0294,  0.0820,  0.1043,  0.0046,  0.0656,  0.0183, -0.0306,\n         0.1027,  0.0544, -0.0439,  0.0400,  0.0946, -0.0073,  0.0879, -0.1094,\n         0.0340, -0.1110, -0.0678, -0.0880,  0.0333,  0.0050,  0.0251,  0.0241,\n         0.0570,  0.0824,  0.0108,  0.0227, -0.0664,  0.1119, -0.1347, -0.0290,\n         0.1145,  0.0239,  0.0998, -0.0795,  0.0660,  0.0467, -0.1114,  0.0610]), 'meta_learner.transductive_net.feature_extractors.2.0.weight': tensor([[-0.0672, -0.1190,  0.0116,  ..., -0.0534,  0.0865, -0.0729],\n        [-0.0607,  0.1404, -0.0180,  ...,  0.0320, -0.0370, -0.0979],\n        [ 0.0237, -0.1242,  0.0322,  ...,  0.0757,  0.0562, -0.0095],\n        ...,\n        [ 0.0463,  0.1006, -0.0067,  ..., -0.0242, -0.0938, -0.0772],\n        [-0.0391,  0.0761, -0.1217,  ..., -0.0186, -0.0866, -0.0374],\n        [-0.1005, -0.0847,  0.0181,  ...,  0.0012, -0.0799, -0.1207]]), 'meta_learner.transductive_net.feature_extractors.2.0.bias': tensor([-0.0813, -0.1205, -0.0716, -0.0914, -0.0526, -0.0851, -0.0818, -0.1158,\n        -0.0749,  0.0559,  0.0275, -0.1006,  0.0312,  0.0689, -0.1352, -0.0939,\n         0.0596,  0.1120,  0.1177,  0.0678, -0.0331,  0.0324,  0.0094,  0.0724,\n        -0.0870,  0.0175, -0.0936, -0.0999, -0.0558,  0.1145, -0.0217,  0.1168,\n         0.0866, -0.0419,  0.0824,  0.1048,  0.0459,  0.1372,  0.0251, -0.0727,\n         0.0591,  0.0683, -0.0023,  0.1207,  0.0507, -0.0230,  0.0509, -0.0478,\n        -0.0831, -0.1092, -0.1268, -0.1114,  0.0638,  0.0092,  0.0325,  0.1038,\n         0.0655, -0.0400, -0.0395, -0.0730,  0.0494, -0.0538, -0.0459,  0.1105,\n        -0.1334,  0.0676,  0.1030,  0.0238,  0.1001, -0.0947, -0.0942,  0.0421,\n         0.0326,  0.0451, -0.0141, -0.0365, -0.0525, -0.1190,  0.0181,  0.0654,\n         0.1273,  0.0962,  0.0831, -0.0375,  0.0647, -0.0409,  0.0803,  0.1200,\n         0.1079, -0.1070, -0.0635, -0.0994,  0.0824, -0.0025,  0.0157,  0.0398,\n         0.0879, -0.0260, -0.0928, -0.0310, -0.0452, -0.0965, -0.0061, -0.0599,\n        -0.0883, -0.0904,  0.0437, -0.0937, -0.0570,  0.0518, -0.0892, -0.0144,\n         0.1148, -0.1119,  0.0714, -0.0499,  0.0834,  0.1414,  0.0837,  0.0954,\n        -0.0473, -0.0601, -0.0689,  0.1325, -0.0574,  0.1200,  0.0862, -0.0333,\n        -0.1229, -0.0497,  0.0896,  0.1176,  0.0049, -0.0543,  0.0073,  0.0522,\n        -0.0691,  0.1329,  0.0311, -0.0458,  0.0176, -0.0076,  0.0100, -0.0106,\n         0.0887, -0.0435, -0.0591,  0.0945, -0.1051,  0.0945,  0.1145,  0.1080,\n         0.1013,  0.1159,  0.0986, -0.0196, -0.1252, -0.0426,  0.1034,  0.1077,\n         0.0083,  0.0944,  0.1030, -0.0685, -0.0008,  0.0187, -0.1117,  0.0036,\n         0.0243, -0.0174,  0.0475,  0.0768, -0.1172, -0.1211, -0.0827, -0.0604,\n         0.0715, -0.0676, -0.1094, -0.0848, -0.0445,  0.0886,  0.1115,  0.0562,\n        -0.0952, -0.1130, -0.0534,  0.0718, -0.0783, -0.0466,  0.0740,  0.0621,\n        -0.1204,  0.0434, -0.0165, -0.0550, -0.0340,  0.1044, -0.0780,  0.0056,\n         0.1076, -0.0614, -0.0615,  0.0637, -0.0479,  0.0688,  0.0527,  0.1060,\n        -0.0187,  0.0691, -0.1057, -0.0199,  0.0622, -0.0383, -0.0145, -0.0426,\n         0.0927, -0.0906, -0.0723,  0.0376, -0.0038, -0.1098,  0.0023, -0.0159,\n         0.0314,  0.1197, -0.0522, -0.0290, -0.1130, -0.0910, -0.0354,  0.1108,\n        -0.0302,  0.0361, -0.0639,  0.1181,  0.0495, -0.1302,  0.0750,  0.0962,\n         0.1192,  0.1117, -0.0165,  0.0213,  0.0716,  0.0490, -0.0887,  0.0787,\n         0.1269, -0.0583,  0.0381,  0.0583, -0.0144,  0.0714,  0.0225, -0.0553]), 'meta_learner.transductive_net.feature_projection.0.weight': tensor([[ 0.0400,  0.0177, -0.0334,  ...,  0.0059,  0.0242,  0.0324],\n        [ 0.0293, -0.0246, -0.0241,  ..., -0.0189, -0.0247, -0.0325],\n        [ 0.0057, -0.0160, -0.0166,  ..., -0.0016,  0.0131,  0.0015],\n        ...,\n        [-0.0157, -0.0009, -0.0054,  ...,  0.0339, -0.0071,  0.0053],\n        [-0.0308, -0.0155, -0.0322,  ...,  0.0187, -0.0198,  0.0182],\n        [ 0.0048, -0.0410,  0.0359,  ...,  0.0405, -0.0180, -0.0431]]), 'meta_learner.transductive_net.feature_projection.0.bias': tensor([-8.9944e-03, -3.4073e-02,  8.0999e-03, -2.5911e-03, -1.8947e-02,\n        -1.2765e-02, -5.1635e-02,  6.2026e-03,  3.4956e-03, -1.3895e-02,\n        -3.4283e-02,  1.1360e-02, -4.4939e-02,  1.9684e-02,  4.5832e-02,\n        -2.9175e-02, -3.2916e-02, -1.1276e-02,  5.0065e-02,  7.7720e-03,\n        -5.9363e-03,  5.7802e-02, -1.0297e-02, -1.4391e-02,  2.4584e-02,\n         9.9258e-04, -3.8055e-02,  5.2979e-02, -4.8561e-02,  1.2162e-02,\n         6.1609e-03,  1.0360e-02,  2.3637e-02, -3.1863e-02, -4.3141e-05,\n        -1.7708e-02,  3.9484e-02,  4.8371e-03, -2.4419e-02, -3.5167e-02,\n        -2.2070e-03, -3.7696e-03, -2.6523e-02,  4.8935e-03,  1.5929e-02,\n         2.7011e-02, -8.2339e-03, -3.4895e-03,  4.4799e-02, -3.0725e-02,\n         1.1124e-02, -3.7826e-03,  4.4906e-02,  4.7026e-02, -3.8847e-02,\n         1.5689e-02, -5.4667e-03,  3.9282e-02, -4.4424e-02,  3.6143e-02,\n        -6.5452e-03, -7.7030e-03, -4.6942e-02,  3.3143e-02]), 'meta_learner.transductive_net.classifier.0.weight': tensor([[ 0.0703,  0.0697,  0.0922,  ..., -0.0416, -0.0311,  0.0999],\n        [ 0.0569, -0.0969, -0.0429,  ..., -0.0748,  0.0100,  0.0011],\n        [ 0.0398,  0.1078, -0.0833,  ..., -0.0290, -0.0791, -0.0982],\n        ...,\n        [ 0.0966,  0.1088,  0.0473,  ...,  0.0775, -0.0447,  0.0787],\n        [ 0.0355, -0.0126,  0.0234,  ..., -0.0598,  0.0644, -0.0055],\n        [ 0.1132, -0.0504, -0.1144,  ..., -0.0983, -0.1195, -0.0846]]), 'meta_learner.transductive_net.classifier.0.bias': tensor([ 0.1138,  0.0649,  0.0593,  0.0925, -0.0604,  0.0044, -0.0251, -0.1079,\n         0.0520,  0.0655, -0.0625,  0.0400, -0.0849,  0.0571, -0.0212, -0.0057,\n         0.1047, -0.1061, -0.0581,  0.0623, -0.0457,  0.1094, -0.0861, -0.1199,\n        -0.0167, -0.0115, -0.0181,  0.0887, -0.0312,  0.0269, -0.0935,  0.1192,\n         0.0063, -0.0678,  0.0253,  0.0032,  0.0304, -0.0890,  0.0666, -0.0189,\n        -0.0413,  0.0606, -0.0377, -0.0068, -0.1031,  0.1105,  0.1003,  0.0999,\n        -0.0829, -0.0271,  0.0206, -0.0304,  0.1205, -0.1212,  0.0709, -0.0597,\n         0.0827, -0.0910,  0.0450, -0.0652, -0.1010, -0.0907, -0.0740, -0.0296]), 'meta_learner.transductive_net.classifier.3.weight': tensor([[ 0.0581, -0.0077,  0.0869,  ...,  0.0767, -0.0894,  0.1157],\n        [ 0.1216,  0.0175, -0.0305,  ..., -0.0195, -0.1163, -0.0166],\n        [-0.0979,  0.0845, -0.0759,  ..., -0.0679, -0.0911,  0.1217],\n        ...,\n        [-0.0597, -0.1056, -0.0752,  ...,  0.1194,  0.0441, -0.0319],\n        [-0.0463, -0.0187, -0.0429,  ..., -0.1193, -0.0066, -0.1054],\n        [-0.0471,  0.1040, -0.0764,  ..., -0.0525, -0.1056, -0.0868]]), 'meta_learner.transductive_net.classifier.3.bias': tensor([ 0.0272,  0.0057, -0.1170, -0.0974, -0.1119,  0.0483, -0.0874, -0.0552,\n        -0.1040, -0.0464,  0.0390,  0.0848,  0.1120,  0.0961, -0.0872,  0.0255,\n        -0.1059,  0.1008, -0.0965,  0.1200,  0.0697, -0.0756, -0.0111, -0.0798,\n         0.0721,  0.0815, -0.0511, -0.0650, -0.1112,  0.0385,  0.0511,  0.1089]), 'meta_learner.transductive_net.classifier.6.weight': tensor([[-0.0113, -0.1656, -0.0381,  0.1019,  0.0301, -0.0915,  0.0025,  0.0741,\n         -0.1465, -0.0398,  0.0989, -0.1202,  0.0292,  0.0376,  0.0902, -0.0221,\n          0.0337, -0.1151,  0.0821,  0.1389,  0.0146, -0.0421,  0.1137,  0.1439,\n         -0.1216, -0.0532,  0.1248,  0.0474, -0.1664, -0.0239,  0.0306, -0.1510],\n        [-0.1726, -0.1167, -0.0470,  0.1048,  0.0537,  0.1050, -0.0156, -0.1622,\n         -0.0264, -0.0968,  0.0316,  0.1678, -0.1365,  0.1258, -0.1492, -0.0365,\n          0.0422,  0.1028, -0.0496,  0.0207, -0.1530, -0.1102, -0.1318, -0.1721,\n          0.1252, -0.0673,  0.1689, -0.0398, -0.0824,  0.1574,  0.1612, -0.1705]]), 'meta_learner.transductive_net.classifier.6.bias': tensor([-0.1295,  0.0185]), 'meta_learner.transductive_net.self_attention.in_proj_weight': tensor([[ 0.0833,  0.0337, -0.0255,  ...,  0.0280, -0.0243, -0.0514],\n        [-0.1569, -0.0815,  0.1112,  ..., -0.0785, -0.0944,  0.0561],\n        [-0.1115, -0.0639, -0.1562,  ..., -0.0676,  0.0867,  0.0273],\n        ...,\n        [-0.1295,  0.0695, -0.0251,  ..., -0.0518, -0.0960, -0.0362],\n        [-0.0672,  0.1472, -0.1445,  ..., -0.1230, -0.0289,  0.0360],\n        [-0.0241, -0.0109, -0.1178,  ...,  0.0734,  0.0822, -0.1291]]), 'meta_learner.transductive_net.self_attention.in_proj_bias': tensor([ 9.5308e-03,  2.4517e-03, -1.2120e-02, -6.2794e-03,  7.6360e-04,\n         3.0979e-03, -3.5613e-03, -9.2365e-04,  1.1422e-02, -1.1506e-03,\n        -9.8042e-03,  3.6073e-03, -8.8528e-03, -9.8568e-03,  1.2440e-03,\n         5.4207e-03, -2.5246e-03,  4.2407e-03,  2.6682e-03,  8.4129e-04,\n        -3.8722e-03,  9.1027e-03, -7.8181e-03,  6.1553e-04,  1.2408e-02,\n        -3.9707e-03, -2.8527e-03,  4.3802e-03, -1.1069e-02, -1.0660e-02,\n         4.1536e-03,  6.5093e-03, -7.8164e-03, -2.9656e-03, -5.7669e-03,\n         3.5466e-03,  1.3257e-02, -3.6377e-03,  3.0297e-03, -2.1297e-03,\n         6.6841e-03, -7.1362e-03,  6.4571e-03,  5.0922e-04, -3.1492e-03,\n        -2.6331e-03, -6.1053e-03,  7.3971e-03,  5.3513e-03, -3.5596e-04,\n        -8.7123e-03,  7.4527e-03, -6.9155e-03, -2.6544e-03, -4.9652e-03,\n        -8.7937e-03, -9.9695e-03, -4.3533e-03,  1.2995e-03,  9.6241e-04,\n        -7.9362e-03,  2.3704e-03,  2.7131e-03,  6.7872e-03,  1.8371e-06,\n         7.4530e-05,  3.3598e-05, -1.2584e-05,  1.1726e-05,  1.0474e-04,\n        -2.3340e-05, -5.0616e-05,  3.6851e-05, -1.4867e-05,  5.5313e-05,\n        -6.9026e-05,  3.0820e-05, -7.6618e-05, -5.4628e-05,  3.4704e-05,\n         6.8622e-05,  1.2131e-04, -1.3844e-05,  1.2395e-05,  7.1210e-06,\n         2.8839e-05,  1.4635e-05, -1.3696e-05, -1.1707e-04, -3.7361e-05,\n        -5.1827e-05,  5.3949e-05,  3.1174e-05,  4.1301e-05, -5.6577e-05,\n         7.5180e-05,  8.9772e-05,  6.6697e-06,  2.9182e-05, -1.3030e-04,\n         8.8111e-06,  3.0717e-05, -1.5721e-04, -2.2883e-04, -5.1086e-07,\n        -3.7358e-06, -8.2848e-05, -5.6134e-05,  1.3344e-04,  7.2420e-05,\n        -1.0839e-05,  9.4049e-05,  6.2369e-05, -9.5791e-06,  1.6282e-04,\n         1.5162e-04,  1.0394e-04,  1.1082e-04, -8.1720e-05, -4.8502e-05,\n        -1.0775e-04, -5.1907e-05, -2.3365e-05,  1.4334e-04,  2.6599e-05,\n         1.5930e-04,  2.7186e-05,  2.1175e-04, -5.4373e-04,  1.4205e-04,\n         1.2778e-04, -1.1395e-04,  2.3915e-04,  1.2910e-04,  1.9905e-04,\n        -2.3685e-04,  5.0659e-04, -4.5193e-05,  2.2005e-05,  2.0109e-04,\n         6.0747e-04, -4.5562e-05, -3.2885e-04,  3.1194e-04, -8.5238e-04,\n        -4.1949e-04, -3.1649e-04,  8.3719e-05,  3.7358e-04,  3.0973e-04,\n        -5.7095e-04, -3.8223e-05, -3.8434e-05, -5.5489e-04, -1.5579e-04,\n        -9.8351e-05,  5.5588e-05, -6.7744e-05, -9.2482e-05, -5.3937e-06,\n         1.4720e-04, -2.0527e-04, -3.1152e-04,  7.0408e-04, -1.6702e-04,\n        -1.0190e-04, -1.2690e-04,  1.9879e-04,  4.6172e-04, -3.0228e-05,\n        -8.1960e-04,  3.2984e-04, -5.4612e-04,  1.2883e-04,  7.7401e-05,\n         4.6405e-04, -3.3499e-04, -1.8587e-04,  2.4864e-04, -5.3601e-04,\n        -3.2359e-04,  6.2077e-04,  2.0390e-04,  3.0332e-05, -1.0571e-04,\n         3.7953e-05,  1.8961e-04, -3.3244e-04, -3.0779e-04,  7.2551e-04,\n        -2.2412e-04,  7.9904e-05]), 'meta_learner.transductive_net.self_attention.out_proj.weight': tensor([[-0.1312,  0.1041, -0.0943,  ...,  0.1175, -0.0352,  0.1171],\n        [ 0.0296,  0.1181, -0.0692,  ..., -0.0990, -0.0194,  0.0387],\n        [ 0.0334,  0.1053, -0.0199,  ..., -0.1236, -0.1066, -0.0732],\n        ...,\n        [ 0.0666,  0.0020,  0.0141,  ...,  0.0284,  0.0922, -0.0349],\n        [ 0.0276, -0.0222, -0.1135,  ...,  0.0678,  0.1243, -0.0323],\n        [ 0.0107, -0.0570, -0.1002,  ..., -0.0101,  0.1151,  0.0214]]), 'meta_learner.transductive_net.self_attention.out_proj.bias': tensor([-1.4030e-04,  1.8379e-04,  1.2291e-05, -2.2762e-05,  2.1230e-04,\n         7.9336e-04,  4.9999e-05,  3.4792e-04, -3.8349e-04, -3.8310e-04,\n         7.5738e-04,  4.8414e-04, -7.8628e-05,  4.4718e-04, -3.1278e-05,\n        -7.9937e-05,  6.2851e-06, -4.9615e-05,  4.3166e-04,  1.9634e-04,\n         2.4466e-04,  1.9513e-04, -3.0628e-04,  4.2387e-04,  6.4592e-04,\n        -1.8971e-04,  1.2589e-04, -6.9717e-05, -3.7823e-04,  2.9018e-04,\n        -1.9144e-04, -2.2908e-04,  1.7517e-04, -7.0691e-04,  3.5444e-05,\n        -4.6561e-04, -7.0190e-04, -4.6664e-04,  6.3581e-04, -5.3247e-04,\n        -1.2643e-04,  6.6742e-04,  2.2294e-04, -2.3317e-04, -2.3085e-04,\n        -6.8951e-04, -5.7566e-05,  8.1318e-04, -4.9944e-04, -1.1871e-04,\n        -2.4977e-04,  2.1332e-04, -3.1546e-04,  1.6960e-04, -9.4064e-05,\n         3.3287e-04,  1.5058e-04,  7.2895e-05,  4.3902e-04,  3.3921e-04,\n        -2.6106e-04, -1.6440e-04, -3.5727e-05, -1.7925e-05]), 'meta_learner.transductive_net.layer_norm.weight': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'meta_learner.transductive_net.layer_norm.bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}, sample_count=66386, training_loss=np.float64(0.1616992297768593), validation_accuracy=np.float64(0.6180000078678131), validation_precision=0.0, validation_recall=0.0, validation_f1_score=0.0, timestamp=1760224210.3479962, model_hash='e1b872d459e9cec3d76dc20a32393331c452ed19715bcc655463bb0661b87787', ipfs_cid=None, blockchain_tx_hash=None)",
        "ClientUpdate(client_id='client_2', model_parameters={'meta_learner.transductive_net.feature_extractors.0.0.weight': tensor([[ 0.0143, -0.0510,  0.0983,  ...,  0.1100,  0.1127, -0.1126],\n        [-0.0092, -0.0371,  0.0470,  ..., -0.0384, -0.0799,  0.0435],\n        [ 0.0658, -0.0273,  0.0316,  ..., -0.0940, -0.0116,  0.1176],\n        ...,\n        [-0.0598,  0.0592,  0.0555,  ...,  0.0110, -0.0474,  0.0814],\n        [-0.0423, -0.0327, -0.0697,  ...,  0.0689,  0.1243, -0.0470],\n        [ 0.1229, -0.1004,  0.1216,  ...,  0.0538,  0.0540, -0.0725]]), 'meta_learner.transductive_net.feature_extractors.0.0.bias': tensor([ 0.1190, -0.0523,  0.0302,  0.1191,  0.0729,  0.0472,  0.0594,  0.0147,\n         0.0476, -0.0939,  0.0564,  0.0713,  0.0850,  0.0210,  0.1228, -0.0213,\n        -0.0371,  0.0623, -0.0935, -0.0924,  0.0569, -0.1268, -0.0543,  0.0378,\n        -0.1363,  0.0867, -0.0401, -0.0568,  0.0747,  0.0644, -0.1286,  0.0318,\n        -0.1252,  0.0680,  0.0543,  0.0449,  0.1061, -0.1051,  0.0422,  0.0621,\n        -0.0204, -0.1119, -0.1127,  0.1009, -0.0562, -0.0930,  0.0884, -0.0159,\n        -0.1073,  0.0403,  0.0965, -0.1162, -0.1192,  0.1051,  0.0650,  0.0219,\n         0.0416, -0.0571, -0.0926, -0.0957,  0.0988, -0.1365,  0.0515,  0.0033,\n        -0.0447, -0.1304, -0.1009,  0.1078,  0.0533, -0.0959,  0.0873,  0.0142,\n        -0.0639,  0.0467,  0.1154,  0.0419,  0.0830, -0.0546,  0.0890,  0.1219,\n        -0.0641, -0.1022, -0.0973,  0.0321,  0.0873,  0.0197, -0.0414, -0.0819,\n        -0.0638, -0.0613, -0.0309, -0.0561, -0.0329, -0.1262, -0.1204, -0.1058,\n        -0.0241,  0.0490, -0.0403, -0.0596, -0.1037, -0.0671, -0.0478, -0.0167,\n        -0.0442,  0.0782, -0.0435,  0.1035,  0.0551,  0.1157,  0.0874, -0.0452,\n        -0.0273,  0.0748, -0.0625,  0.0270,  0.0422,  0.0777, -0.0529, -0.0605,\n        -0.0759, -0.0379,  0.0446,  0.0759, -0.0728,  0.0190,  0.0171,  0.0867]), 'meta_learner.transductive_net.feature_extractors.1.0.weight': tensor([[-0.0539, -0.0796, -0.0049,  ..., -0.0067,  0.1012, -0.0337],\n        [-0.0711, -0.1261,  0.1008,  ..., -0.0129, -0.0420, -0.1002],\n        [-0.0374, -0.0206,  0.0264,  ..., -0.0879,  0.1082,  0.1234],\n        ...,\n        [-0.0828, -0.0244, -0.1004,  ...,  0.0540, -0.0320,  0.0179],\n        [-0.0087,  0.0920,  0.0662,  ..., -0.0584,  0.1039,  0.1166],\n        [-0.0409,  0.0850, -0.0044,  ..., -0.0856, -0.0563,  0.0346]]), 'meta_learner.transductive_net.feature_extractors.1.0.bias': tensor([ 0.0002, -0.0315, -0.0368,  0.0914,  0.0936, -0.0482, -0.1017, -0.0018,\n         0.0736,  0.0612, -0.0338,  0.0214, -0.1047,  0.1263,  0.1033, -0.0143,\n         0.0655, -0.1104, -0.0694,  0.0023, -0.0317,  0.0555, -0.0893,  0.1287,\n         0.0537,  0.0263,  0.0947,  0.1058,  0.0092,  0.0691,  0.0294, -0.0356,\n         0.0909,  0.0474, -0.0342,  0.0535,  0.0969,  0.0074,  0.0937, -0.1038,\n         0.0296, -0.1246, -0.0658, -0.0822,  0.0426,  0.0151,  0.0281,  0.0243,\n         0.0612,  0.0745,  0.0187,  0.0206, -0.0883,  0.1167, -0.1248, -0.0414,\n         0.1182,  0.0180,  0.1029, -0.0772,  0.0585,  0.0328, -0.1131,  0.0619]), 'meta_learner.transductive_net.feature_extractors.2.0.weight': tensor([[-0.0704, -0.1221,  0.0085,  ..., -0.0561,  0.0901, -0.0729],\n        [-0.0701,  0.1311, -0.0307,  ...,  0.0367, -0.0447, -0.0979],\n        [ 0.0184, -0.1295,  0.0208,  ...,  0.0880,  0.0627, -0.0095],\n        ...,\n        [ 0.0476,  0.1018, -0.0091,  ..., -0.0290, -0.1011, -0.0772],\n        [-0.0431,  0.0719, -0.1169,  ..., -0.0079, -0.0914, -0.0374],\n        [-0.1132, -0.0974,  0.0266,  ...,  0.0033, -0.0882, -0.1207]]), 'meta_learner.transductive_net.feature_extractors.2.0.bias': tensor([-0.0781, -0.1079, -0.0663, -0.0940, -0.0604, -0.0897, -0.0805, -0.1226,\n        -0.0805,  0.0596,  0.0195, -0.1037,  0.0407,  0.0697, -0.1408, -0.1010,\n         0.0471,  0.1172,  0.1131,  0.0634, -0.0477,  0.0432,  0.0227,  0.0681,\n        -0.0870,  0.0190, -0.1037, -0.1086, -0.0647,  0.1153, -0.0203,  0.1218,\n         0.0896, -0.0538,  0.0764,  0.0951,  0.0337,  0.1199,  0.0308, -0.0789,\n         0.0482,  0.0698,  0.0113,  0.1240,  0.0549, -0.0225,  0.0625, -0.0520,\n        -0.0723, -0.1137, -0.1296, -0.0925,  0.0751,  0.0172,  0.0328,  0.1000,\n         0.0513, -0.0372, -0.0316, -0.0617,  0.0412, -0.0553, -0.0478,  0.1071,\n        -0.1255,  0.0653,  0.1021,  0.0161,  0.1063, -0.0914, -0.0966,  0.0484,\n         0.0380,  0.0335, -0.0134, -0.0446, -0.0588, -0.1190,  0.0157,  0.0644,\n         0.1173,  0.0894,  0.0901, -0.0508,  0.0675, -0.0538,  0.0898,  0.1180,\n         0.1099, -0.1021, -0.0622, -0.1052,  0.0808, -0.0130,  0.0248,  0.0342,\n         0.0856, -0.0125, -0.0911, -0.0219, -0.0354, -0.1089, -0.0123, -0.0494,\n        -0.0833, -0.1018,  0.0475, -0.0867, -0.0459,  0.0640, -0.0851, -0.0235,\n         0.1211, -0.1261,  0.0725, -0.0395,  0.0671,  0.1370,  0.0978,  0.0892,\n        -0.0428, -0.0677, -0.0850,  0.1284, -0.0618,  0.1128,  0.0921, -0.0336,\n        -0.1217, -0.0443,  0.0777,  0.1103,  0.0002, -0.0684,  0.0112,  0.0453,\n        -0.0517,  0.1211,  0.0322, -0.0441,  0.0019, -0.0169,  0.0099, -0.0116,\n         0.0864, -0.0524, -0.0694,  0.0982, -0.0882,  0.0922,  0.1006,  0.1011,\n         0.1111,  0.1101,  0.0896, -0.0319, -0.1396, -0.0571,  0.0974,  0.0991,\n         0.0217,  0.0862,  0.1045, -0.0738,  0.0129,  0.0422, -0.1117,  0.0036,\n         0.0208, -0.0109,  0.0610,  0.0777, -0.1085, -0.1245, -0.0804, -0.0702,\n         0.0809, -0.0794, -0.1048, -0.0755, -0.0466,  0.0913,  0.1071,  0.0572,\n        -0.1083, -0.1081, -0.0672,  0.0706, -0.0810, -0.0450,  0.0790,  0.0576,\n        -0.1211,  0.0261, -0.0250, -0.0615, -0.0305,  0.0912, -0.0822,  0.0083,\n         0.1014, -0.0603, -0.0578,  0.0781, -0.0603,  0.0727,  0.0399,  0.1088,\n        -0.0249,  0.0789, -0.1098, -0.0261,  0.0655, -0.0498, -0.0117, -0.0468,\n         0.0941, -0.0836, -0.0678,  0.0487, -0.0153, -0.1034, -0.0122, -0.0297,\n         0.0256,  0.1059, -0.0643, -0.0234, -0.1272, -0.0928, -0.0452,  0.1166,\n        -0.0369,  0.0242, -0.0678,  0.0987,  0.0554, -0.1169,  0.0679,  0.0908,\n         0.1294,  0.1205, -0.0137,  0.0116,  0.0707,  0.0476, -0.1025,  0.0771,\n         0.1208, -0.0692,  0.0426,  0.0720, -0.0203,  0.0680,  0.0178, -0.0426]), 'meta_learner.transductive_net.feature_projection.0.weight': tensor([[ 0.0373,  0.0267, -0.0281,  ...,  0.0100,  0.0374,  0.0279],\n        [ 0.0327, -0.0359, -0.0163,  ..., -0.0229, -0.0129, -0.0404],\n        [ 0.0068, -0.0271, -0.0195,  ..., -0.0171,  0.0265, -0.0074],\n        ...,\n        [-0.0132, -0.0057, -0.0210,  ...,  0.0178,  0.0065,  0.0065],\n        [-0.0149, -0.0101, -0.0332,  ...,  0.0181, -0.0185,  0.0293],\n        [-0.0027, -0.0334,  0.0337,  ...,  0.0346, -0.0211, -0.0463]]), 'meta_learner.transductive_net.feature_projection.0.bias': tensor([ 0.0031, -0.0294,  0.0070,  0.0151, -0.0149, -0.0138, -0.0437,  0.0060,\n         0.0012, -0.0087, -0.0293,  0.0223, -0.0381,  0.0073,  0.0512, -0.0171,\n        -0.0380, -0.0266,  0.0337,  0.0120, -0.0006,  0.0465, -0.0030, -0.0158,\n         0.0403, -0.0113, -0.0267,  0.0526, -0.0385,  0.0202, -0.0010,  0.0064,\n         0.0278, -0.0306,  0.0096, -0.0248,  0.0408,  0.0142, -0.0158, -0.0371,\n         0.0196,  0.0004, -0.0225,  0.0208,  0.0117, -0.0010, -0.0150,  0.0017,\n         0.0463, -0.0380,  0.0120,  0.0120,  0.0475,  0.0335, -0.0330,  0.0238,\n        -0.0060,  0.0365, -0.0571,  0.0238, -0.0075, -0.0109, -0.0457,  0.0330]), 'meta_learner.transductive_net.classifier.0.weight': tensor([[ 0.0703,  0.0697,  0.0922,  ..., -0.0416, -0.0311,  0.0999],\n        [ 0.0569, -0.0969, -0.0429,  ..., -0.0748,  0.0100,  0.0011],\n        [ 0.0398,  0.1078, -0.0833,  ..., -0.0290, -0.0791, -0.0982],\n        ...,\n        [ 0.0966,  0.1088,  0.0473,  ...,  0.0775, -0.0447,  0.0787],\n        [ 0.0355, -0.0126,  0.0234,  ..., -0.0598,  0.0644, -0.0055],\n        [ 0.1132, -0.0504, -0.1144,  ..., -0.0983, -0.1195, -0.0846]]), 'meta_learner.transductive_net.classifier.0.bias': tensor([ 0.1138,  0.0649,  0.0593,  0.0925, -0.0604,  0.0044, -0.0251, -0.1079,\n         0.0520,  0.0655, -0.0625,  0.0400, -0.0849,  0.0571, -0.0212, -0.0057,\n         0.1047, -0.1061, -0.0581,  0.0623, -0.0457,  0.1094, -0.0861, -0.1199,\n        -0.0167, -0.0115, -0.0181,  0.0887, -0.0312,  0.0269, -0.0935,  0.1192,\n         0.0063, -0.0678,  0.0253,  0.0032,  0.0304, -0.0890,  0.0666, -0.0189,\n        -0.0413,  0.0606, -0.0377, -0.0068, -0.1031,  0.1105,  0.1003,  0.0999,\n        -0.0829, -0.0271,  0.0206, -0.0304,  0.1205, -0.1212,  0.0709, -0.0597,\n         0.0827, -0.0910,  0.0450, -0.0652, -0.1010, -0.0907, -0.0740, -0.0296]), 'meta_learner.transductive_net.classifier.3.weight': tensor([[ 0.0581, -0.0077,  0.0869,  ...,  0.0767, -0.0894,  0.1157],\n        [ 0.1216,  0.0175, -0.0305,  ..., -0.0195, -0.1163, -0.0166],\n        [-0.0979,  0.0845, -0.0759,  ..., -0.0679, -0.0911,  0.1217],\n        ...,\n        [-0.0597, -0.1056, -0.0752,  ...,  0.1194,  0.0441, -0.0319],\n        [-0.0463, -0.0187, -0.0429,  ..., -0.1193, -0.0066, -0.1054],\n        [-0.0471,  0.1040, -0.0764,  ..., -0.0525, -0.1056, -0.0868]]), 'meta_learner.transductive_net.classifier.3.bias': tensor([ 0.0272,  0.0057, -0.1170, -0.0974, -0.1119,  0.0483, -0.0874, -0.0552,\n        -0.1040, -0.0464,  0.0390,  0.0848,  0.1120,  0.0961, -0.0872,  0.0255,\n        -0.1059,  0.1008, -0.0965,  0.1200,  0.0697, -0.0756, -0.0111, -0.0798,\n         0.0721,  0.0815, -0.0511, -0.0650, -0.1112,  0.0385,  0.0511,  0.1089]), 'meta_learner.transductive_net.classifier.6.weight': tensor([[-0.0113, -0.1656, -0.0381,  0.1019,  0.0301, -0.0915,  0.0025,  0.0741,\n         -0.1465, -0.0398,  0.0989, -0.1202,  0.0292,  0.0376,  0.0902, -0.0221,\n          0.0337, -0.1151,  0.0821,  0.1389,  0.0146, -0.0421,  0.1137,  0.1439,\n         -0.1216, -0.0532,  0.1248,  0.0474, -0.1664, -0.0239,  0.0306, -0.1510],\n        [-0.1726, -0.1167, -0.0470,  0.1048,  0.0537,  0.1050, -0.0156, -0.1622,\n         -0.0264, -0.0968,  0.0316,  0.1678, -0.1365,  0.1258, -0.1492, -0.0365,\n          0.0422,  0.1028, -0.0496,  0.0207, -0.1530, -0.1102, -0.1318, -0.1721,\n          0.1252, -0.0673,  0.1689, -0.0398, -0.0824,  0.1574,  0.1612, -0.1705]]), 'meta_learner.transductive_net.classifier.6.bias': tensor([-0.1295,  0.0185]), 'meta_learner.transductive_net.self_attention.in_proj_weight': tensor([[ 0.0920,  0.0379, -0.0161,  ...,  0.0341, -0.0218, -0.0518],\n        [-0.1508, -0.0830,  0.1112,  ..., -0.0791, -0.0910,  0.0620],\n        [-0.1282, -0.0768, -0.1474,  ..., -0.0785,  0.0728,  0.0335],\n        ...,\n        [-0.1234,  0.0533, -0.0220,  ..., -0.0682, -0.1002, -0.0313],\n        [-0.0626,  0.1424, -0.1281,  ..., -0.1456, -0.0331,  0.0295],\n        [-0.0284, -0.0044, -0.1266,  ...,  0.0904,  0.0835, -0.1213]]), 'meta_learner.transductive_net.self_attention.in_proj_bias': tensor([-4.3098e-03, -6.0438e-03,  5.5405e-03,  6.8444e-03, -3.7676e-03,\n         7.8283e-03, -4.9185e-03,  9.1747e-03,  3.8118e-03,  1.1575e-02,\n         3.3448e-03,  5.3047e-03,  3.0103e-03, -5.2223e-03,  9.7793e-03,\n        -3.2993e-03, -1.4536e-02, -3.5556e-03, -5.6181e-03,  5.8522e-03,\n         6.9455e-03,  1.4014e-02,  1.1269e-02, -1.2945e-02, -4.7934e-03,\n        -2.5420e-03, -3.3313e-03, -8.0332e-03,  5.3483e-03,  6.0213e-03,\n        -9.6211e-03, -6.7718e-03, -4.8201e-03, -4.4158e-03, -2.2941e-03,\n        -5.3146e-03, -4.9115e-03,  4.6667e-03,  8.6054e-03, -6.7562e-03,\n        -4.6198e-03,  4.3603e-03, -3.1050e-03, -9.9950e-03, -2.3734e-03,\n        -1.8511e-03,  1.0047e-04,  7.0004e-04, -1.0614e-02,  1.7064e-03,\n        -1.3600e-02,  1.9447e-03, -8.0620e-03, -1.1713e-02,  8.5092e-04,\n        -2.4730e-03, -1.0978e-02,  4.6881e-03,  4.5263e-03, -1.2530e-03,\n        -4.9219e-04,  6.8228e-03, -1.5172e-04,  2.6950e-03,  8.2757e-05,\n        -6.9808e-05,  7.2133e-05,  1.2274e-05,  2.7985e-05,  6.8383e-05,\n        -1.0333e-04, -3.6136e-06, -8.3275e-05, -7.9449e-06,  9.2812e-05,\n        -1.4905e-04,  3.5013e-05, -5.9847e-05, -3.5100e-06,  6.3084e-05,\n         3.0297e-05, -5.9285e-05, -5.0231e-05,  8.8762e-05, -4.3272e-05,\n         4.1953e-05, -3.6136e-05,  1.0985e-04, -4.9507e-05, -8.6782e-05,\n        -3.0896e-05, -6.1214e-05,  3.3845e-05,  2.5783e-05, -1.0082e-04,\n        -6.8209e-05, -2.5446e-05, -2.7724e-05, -8.3600e-05,  6.9128e-05,\n         4.0785e-05, -7.2670e-05, -5.1897e-05,  3.6766e-05, -5.6094e-05,\n        -4.7305e-05,  3.0104e-05, -4.4112e-05,  2.8402e-05, -1.0877e-05,\n        -3.1878e-05, -4.5758e-05,  1.2060e-05, -4.6389e-05,  2.5494e-05,\n        -3.4271e-05, -4.3194e-05,  1.0904e-05,  3.8671e-05,  1.1258e-05,\n         4.4669e-05,  2.4601e-05, -9.0002e-05,  2.1890e-05, -8.7603e-05,\n        -3.7560e-05,  5.5426e-06, -4.1496e-06, -4.6154e-04, -1.0663e-04,\n         5.9710e-04, -3.0155e-04,  2.1170e-04,  2.9824e-04, -6.5876e-04,\n         5.4215e-04,  6.9927e-04,  2.8324e-04,  4.4779e-04, -5.5618e-05,\n         2.2897e-05,  9.9520e-05,  3.0360e-04, -5.6583e-04,  5.2330e-04,\n         9.2359e-05,  1.0494e-04,  7.4549e-05,  6.3698e-04,  1.2672e-04,\n        -4.7290e-05,  6.2141e-04,  1.1244e-04,  5.8039e-04,  2.1838e-05,\n         2.7457e-04,  3.0671e-04, -3.7601e-04,  1.9277e-04, -2.1441e-04,\n         8.5436e-04,  4.2720e-04, -5.4201e-04, -6.0218e-04,  2.3526e-04,\n        -1.5742e-04,  3.8215e-04, -2.4815e-04, -2.2687e-04,  5.3972e-05,\n         2.9913e-04, -5.7191e-05, -3.3987e-04, -1.2731e-04, -2.5466e-04,\n         2.9478e-04,  1.0761e-04,  9.1528e-06, -3.4244e-04, -2.0556e-04,\n        -3.6413e-04,  1.0223e-04,  2.0139e-04,  3.3738e-04,  8.3041e-04,\n        -8.9612e-05,  1.3831e-04,  1.2839e-04,  1.0055e-04,  7.4408e-05,\n        -5.8733e-04,  6.7407e-04]), 'meta_learner.transductive_net.self_attention.out_proj.weight': tensor([[-0.1017,  0.0743, -0.0985,  ...,  0.1227, -0.0329,  0.1190],\n        [ 0.0325,  0.1241, -0.0580,  ..., -0.0905, -0.0120,  0.0263],\n        [ 0.0289,  0.1006, -0.0346,  ..., -0.1088, -0.0924, -0.0809],\n        ...,\n        [ 0.0759, -0.0038,  0.0044,  ...,  0.0168,  0.0767, -0.0261],\n        [ 0.0278, -0.0131, -0.1066,  ...,  0.0744,  0.1158, -0.0196],\n        [ 0.0106, -0.0525, -0.0912,  ..., -0.0172,  0.1246,  0.0208]]), 'meta_learner.transductive_net.self_attention.out_proj.bias': tensor([ 1.7332e-04,  3.3074e-04, -3.4161e-04, -1.7359e-04,  3.5468e-04,\n        -7.0343e-04,  8.4195e-05,  3.6683e-04,  2.7614e-04,  2.0734e-04,\n        -3.8614e-04, -2.6858e-04, -1.1403e-04, -2.5629e-04, -2.4956e-04,\n        -1.6798e-05, -1.3482e-04, -6.6891e-04, -1.4869e-04, -3.7705e-04,\n         1.6692e-04,  6.4407e-04, -3.7915e-06, -1.9919e-04, -6.4543e-04,\n         1.3357e-04, -1.4036e-05,  1.8342e-04, -1.7972e-04,  5.0148e-04,\n         1.0431e-04,  2.2218e-04, -7.1464e-04,  3.7934e-04, -6.6495e-05,\n         5.3230e-04, -2.8026e-04,  3.5579e-04,  5.1062e-04,  2.7551e-04,\n         1.4928e-04, -3.2617e-04, -3.6296e-04,  1.9671e-04,  2.1433e-04,\n         5.6868e-04,  5.2722e-05,  1.0909e-04,  4.3510e-05, -1.0200e-04,\n        -3.5822e-05,  1.4302e-04,  7.2823e-05, -4.8302e-04, -7.1149e-04,\n        -1.5364e-04,  5.4173e-04,  6.0431e-04, -1.3946e-04,  6.4940e-04,\n        -2.5498e-04,  5.2834e-05,  1.7360e-04, -2.8421e-04]), 'meta_learner.transductive_net.layer_norm.weight': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'meta_learner.transductive_net.layer_norm.bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}, sample_count=52463, training_loss=np.float64(0.12997408427298068), validation_accuracy=np.float64(0.7100000059604644), validation_precision=0.0, validation_recall=0.0, validation_f1_score=0.0, timestamp=1760224210.5737014, model_hash='3ef3e677542145f8b7b1c98faaad01ab8a9894b04dec75bbe5d986b51203bbea', ipfs_cid=None, blockchain_tx_hash=None)",
        "ClientUpdate(client_id='client_3', model_parameters={'meta_learner.transductive_net.feature_extractors.0.0.weight': tensor([[ 0.0211, -0.0442,  0.0977,  ...,  0.1201,  0.1065, -0.1126],\n        [ 0.0087, -0.0192,  0.0564,  ..., -0.0291, -0.0738,  0.0435],\n        [ 0.0549, -0.0382,  0.0329,  ..., -0.0981, -0.0005,  0.1176],\n        ...,\n        [-0.0497,  0.0690,  0.0500,  ...,  0.0231, -0.0323,  0.0814],\n        [-0.0416, -0.0320, -0.0690,  ...,  0.0713,  0.1154, -0.0470],\n        [ 0.1273, -0.0960,  0.1310,  ...,  0.0404,  0.0549, -0.0725]]), 'meta_learner.transductive_net.feature_extractors.0.0.bias': tensor([ 0.1122, -0.0701,  0.0411,  0.1140,  0.0718,  0.0608,  0.0634,  0.0235,\n         0.0438, -0.0948,  0.0458,  0.0629,  0.0850,  0.0160,  0.1218, -0.0177,\n        -0.0418,  0.0541, -0.0940, -0.1013,  0.0532, -0.1284, -0.0487,  0.0387,\n        -0.1317,  0.0844, -0.0384, -0.0633,  0.0720,  0.0754, -0.1241,  0.0286,\n        -0.1305,  0.0705,  0.0459,  0.0536,  0.1073, -0.0991,  0.0281,  0.0556,\n        -0.0178, -0.1223, -0.0938,  0.1155, -0.0460, -0.0963,  0.0978, -0.0103,\n        -0.1112,  0.0379,  0.1022, -0.1143, -0.1335,  0.1063,  0.0466,  0.0236,\n         0.0400, -0.0585, -0.0800, -0.0879,  0.1007, -0.1265,  0.0486,  0.0029,\n        -0.0532, -0.1328, -0.0910,  0.1114,  0.0549, -0.0940,  0.0818,  0.0076,\n        -0.0714,  0.0616,  0.1229,  0.0352,  0.0791, -0.0654,  0.0932,  0.1082,\n        -0.0579, -0.1011, -0.0983,  0.0236,  0.0751,  0.0109, -0.0350, -0.0862,\n        -0.0661, -0.0610, -0.0359, -0.0568, -0.0361, -0.1321, -0.1224, -0.1030,\n        -0.0308,  0.0552, -0.0430, -0.0526, -0.1185, -0.0766, -0.0557, -0.0327,\n        -0.0307,  0.0708, -0.0532,  0.1036,  0.0599,  0.1105,  0.0807, -0.0367,\n        -0.0313,  0.0748, -0.0612,  0.0354,  0.0315,  0.0773, -0.0597, -0.0422,\n        -0.0758, -0.0454,  0.0330,  0.0808, -0.0726,  0.0030,  0.0165,  0.0791]), 'meta_learner.transductive_net.feature_extractors.1.0.weight': tensor([[-0.0583, -0.0839, -0.0231,  ...,  0.0019,  0.1109, -0.0337],\n        [-0.0581, -0.1131,  0.0915,  ..., -0.0108, -0.0281, -0.1002],\n        [-0.0412, -0.0245,  0.0226,  ..., -0.0938,  0.1026,  0.1234],\n        ...,\n        [-0.0835, -0.0252, -0.0995,  ...,  0.0475, -0.0329,  0.0179],\n        [-0.0017,  0.0991,  0.0552,  ..., -0.0623,  0.1168,  0.1166],\n        [-0.0392,  0.0865,  0.0009,  ..., -0.0799, -0.0495,  0.0346]]), 'meta_learner.transductive_net.feature_extractors.1.0.bias': tensor([ 0.0046, -0.0444, -0.0330,  0.0904,  0.0996, -0.0425, -0.1053, -0.0070,\n         0.0838,  0.0688, -0.0413,  0.0220, -0.0979,  0.1360,  0.0973, -0.0073,\n         0.0560, -0.1097, -0.0630,  0.0051, -0.0435,  0.0599, -0.0929,  0.1150,\n         0.0571,  0.0247,  0.0835,  0.1027,  0.0042,  0.0600,  0.0161, -0.0348,\n         0.1016,  0.0396, -0.0417,  0.0491,  0.0923, -0.0048,  0.0756, -0.1130,\n         0.0239, -0.1193, -0.0689, -0.0729,  0.0263,  0.0084,  0.0091,  0.0176,\n         0.0627,  0.0795,  0.0191,  0.0182, -0.0743,  0.1189, -0.1258, -0.0374,\n         0.1204,  0.0240,  0.1068, -0.0754,  0.0566,  0.0336, -0.1192,  0.0566]), 'meta_learner.transductive_net.feature_extractors.2.0.weight': tensor([[-0.0792, -0.1309, -0.0003,  ..., -0.0652,  0.0984, -0.0729],\n        [-0.0705,  0.1306, -0.0278,  ...,  0.0369, -0.0431, -0.0979],\n        [ 0.0287, -0.1192,  0.0322,  ...,  0.0796,  0.0526, -0.0095],\n        ...,\n        [ 0.0362,  0.0904, -0.0227,  ..., -0.0326, -0.0906, -0.0772],\n        [-0.0463,  0.0689, -0.1289,  ..., -0.0045, -0.0942, -0.0374],\n        [-0.0971, -0.0813,  0.0143,  ..., -0.0022, -0.0786, -0.1207]]), 'meta_learner.transductive_net.feature_extractors.2.0.bias': tensor([-0.0693, -0.1108, -0.0766, -0.1069, -0.0520, -0.0849, -0.0813, -0.1217,\n        -0.0831,  0.0540,  0.0159, -0.1102,  0.0305,  0.0883, -0.1191, -0.0975,\n         0.0388,  0.1199,  0.1095,  0.0527, -0.0467,  0.0518,  0.0160,  0.0687,\n        -0.0863,  0.0077, -0.0888, -0.1013, -0.0662,  0.1235, -0.0169,  0.1142,\n         0.0918, -0.0459,  0.0613,  0.1019,  0.0310,  0.1287,  0.0280, -0.0655,\n         0.0665,  0.0652,  0.0072,  0.1052,  0.0481, -0.0133,  0.0689, -0.0559,\n        -0.0651, -0.1197, -0.1281, -0.1063,  0.0730,  0.0198,  0.0307,  0.1080,\n         0.0539, -0.0362, -0.0324, -0.0653,  0.0359, -0.0581, -0.0415,  0.0941,\n        -0.1197,  0.0637,  0.1005,  0.0136,  0.0931, -0.0985, -0.0911,  0.0428,\n         0.0255,  0.0522, -0.0042, -0.0400, -0.0527, -0.1068,  0.0221,  0.0674,\n         0.1270,  0.0822,  0.0945, -0.0473,  0.0841, -0.0469,  0.0943,  0.1231,\n         0.0913, -0.1084, -0.0636, -0.0925,  0.0876, -0.0024,  0.0219,  0.0391,\n         0.1019, -0.0214, -0.0923, -0.0185, -0.0289, -0.1116, -0.0059, -0.0570,\n        -0.0903, -0.0945,  0.0437, -0.1051, -0.0569,  0.0627, -0.0896, -0.0349,\n         0.1056, -0.1209,  0.0721, -0.0421,  0.0756,  0.1372,  0.0900,  0.0859,\n        -0.0432, -0.0475, -0.0658,  0.1185, -0.0638,  0.1239,  0.0891, -0.0387,\n        -0.1126, -0.0447,  0.0826,  0.1108,  0.0032, -0.0635,  0.0003,  0.0377,\n        -0.0589,  0.1287,  0.0300, -0.0518,  0.0141, -0.0073,  0.0146, -0.0124,\n         0.0823, -0.0367, -0.0703,  0.1016, -0.1020,  0.0843,  0.1160,  0.1123,\n         0.1174,  0.1030,  0.0971, -0.0349, -0.1341, -0.0482,  0.0962,  0.1146,\n         0.0129,  0.0773,  0.0969, -0.0630, -0.0015,  0.0217, -0.1126,  0.0062,\n         0.0223, -0.0123,  0.0541,  0.0807, -0.1195, -0.1164, -0.0778, -0.0619,\n         0.0694, -0.0866, -0.1216, -0.0677, -0.0428,  0.1013,  0.1172,  0.0603,\n        -0.0955, -0.1103, -0.0605,  0.0637, -0.0922, -0.0481,  0.0746,  0.0634,\n        -0.1232,  0.0189, -0.0220, -0.0591, -0.0164,  0.0997, -0.0767, -0.0023,\n         0.1149, -0.0510, -0.0668,  0.0777, -0.0500,  0.0797,  0.0499,  0.1086,\n        -0.0219,  0.0727, -0.1234, -0.0225,  0.0740, -0.0497, -0.0154, -0.0364,\n         0.0879, -0.0821, -0.0653,  0.0496, -0.0089, -0.1018, -0.0147, -0.0293,\n         0.0123,  0.1108, -0.0564, -0.0215, -0.1111, -0.1108, -0.0371,  0.1180,\n        -0.0349,  0.0375, -0.0822,  0.1024,  0.0640, -0.1180,  0.0718,  0.0936,\n         0.1233,  0.1281, -0.0082,  0.0172,  0.0797,  0.0478, -0.0870,  0.0659,\n         0.1139, -0.0714,  0.0520,  0.0792, -0.0243,  0.0816,  0.0297, -0.0588]), 'meta_learner.transductive_net.feature_projection.0.weight': tensor([[ 0.0310,  0.0243, -0.0284,  ...,  0.0146,  0.0355,  0.0359],\n        [ 0.0181, -0.0265, -0.0334,  ..., -0.0313, -0.0286, -0.0330],\n        [ 0.0081, -0.0213, -0.0052,  ..., -0.0069,  0.0153,  0.0057],\n        ...,\n        [-0.0038, -0.0094, -0.0135,  ...,  0.0279, -0.0059,  0.0160],\n        [-0.0104, -0.0044, -0.0261,  ...,  0.0177, -0.0159,  0.0220],\n        [-0.0124, -0.0405,  0.0441,  ...,  0.0360, -0.0180, -0.0499]]), 'meta_learner.transductive_net.feature_projection.0.bias': tensor([-0.0012, -0.0485,  0.0071, -0.0026, -0.0214, -0.0063, -0.0513,  0.0010,\n        -0.0003,  0.0010, -0.0289,  0.0051, -0.0413,  0.0101,  0.0466, -0.0246,\n        -0.0399, -0.0207,  0.0372,  0.0131, -0.0125,  0.0510,  0.0014, -0.0262,\n         0.0391, -0.0112, -0.0302,  0.0392, -0.0351,  0.0230,  0.0053,  0.0090,\n         0.0203, -0.0240,  0.0100, -0.0186,  0.0557,  0.0154, -0.0234, -0.0294,\n         0.0005,  0.0043, -0.0192,  0.0165, -0.0066,  0.0053, -0.0110, -0.0009,\n         0.0475, -0.0268,  0.0169,  0.0021,  0.0385,  0.0410, -0.0417,  0.0116,\n        -0.0087,  0.0283, -0.0469,  0.0216, -0.0099, -0.0056, -0.0376,  0.0356]), 'meta_learner.transductive_net.classifier.0.weight': tensor([[ 0.0703,  0.0697,  0.0922,  ..., -0.0416, -0.0311,  0.0999],\n        [ 0.0569, -0.0969, -0.0429,  ..., -0.0748,  0.0100,  0.0011],\n        [ 0.0398,  0.1078, -0.0833,  ..., -0.0290, -0.0791, -0.0982],\n        ...,\n        [ 0.0966,  0.1088,  0.0473,  ...,  0.0775, -0.0447,  0.0787],\n        [ 0.0355, -0.0126,  0.0234,  ..., -0.0598,  0.0644, -0.0055],\n        [ 0.1132, -0.0504, -0.1144,  ..., -0.0983, -0.1195, -0.0846]]), 'meta_learner.transductive_net.classifier.0.bias': tensor([ 0.1138,  0.0649,  0.0593,  0.0925, -0.0604,  0.0044, -0.0251, -0.1079,\n         0.0520,  0.0655, -0.0625,  0.0400, -0.0849,  0.0571, -0.0212, -0.0057,\n         0.1047, -0.1061, -0.0581,  0.0623, -0.0457,  0.1094, -0.0861, -0.1199,\n        -0.0167, -0.0115, -0.0181,  0.0887, -0.0312,  0.0269, -0.0935,  0.1192,\n         0.0063, -0.0678,  0.0253,  0.0032,  0.0304, -0.0890,  0.0666, -0.0189,\n        -0.0413,  0.0606, -0.0377, -0.0068, -0.1031,  0.1105,  0.1003,  0.0999,\n        -0.0829, -0.0271,  0.0206, -0.0304,  0.1205, -0.1212,  0.0709, -0.0597,\n         0.0827, -0.0910,  0.0450, -0.0652, -0.1010, -0.0907, -0.0740, -0.0296]), 'meta_learner.transductive_net.classifier.3.weight': tensor([[ 0.0581, -0.0077,  0.0869,  ...,  0.0767, -0.0894,  0.1157],\n        [ 0.1216,  0.0175, -0.0305,  ..., -0.0195, -0.1163, -0.0166],\n        [-0.0979,  0.0845, -0.0759,  ..., -0.0679, -0.0911,  0.1217],\n        ...,\n        [-0.0597, -0.1056, -0.0752,  ...,  0.1194,  0.0441, -0.0319],\n        [-0.0463, -0.0187, -0.0429,  ..., -0.1193, -0.0066, -0.1054],\n        [-0.0471,  0.1040, -0.0764,  ..., -0.0525, -0.1056, -0.0868]]), 'meta_learner.transductive_net.classifier.3.bias': tensor([ 0.0272,  0.0057, -0.1170, -0.0974, -0.1119,  0.0483, -0.0874, -0.0552,\n        -0.1040, -0.0464,  0.0390,  0.0848,  0.1120,  0.0961, -0.0872,  0.0255,\n        -0.1059,  0.1008, -0.0965,  0.1200,  0.0697, -0.0756, -0.0111, -0.0798,\n         0.0721,  0.0815, -0.0511, -0.0650, -0.1112,  0.0385,  0.0511,  0.1089]), 'meta_learner.transductive_net.classifier.6.weight': tensor([[-0.0113, -0.1656, -0.0381,  0.1019,  0.0301, -0.0915,  0.0025,  0.0741,\n         -0.1465, -0.0398,  0.0989, -0.1202,  0.0292,  0.0376,  0.0902, -0.0221,\n          0.0337, -0.1151,  0.0821,  0.1389,  0.0146, -0.0421,  0.1137,  0.1439,\n         -0.1216, -0.0532,  0.1248,  0.0474, -0.1664, -0.0239,  0.0306, -0.1510],\n        [-0.1726, -0.1167, -0.0470,  0.1048,  0.0537,  0.1050, -0.0156, -0.1622,\n         -0.0264, -0.0968,  0.0316,  0.1678, -0.1365,  0.1258, -0.1492, -0.0365,\n          0.0422,  0.1028, -0.0496,  0.0207, -0.1530, -0.1102, -0.1318, -0.1721,\n          0.1252, -0.0673,  0.1689, -0.0398, -0.0824,  0.1574,  0.1612, -0.1705]]), 'meta_learner.transductive_net.classifier.6.bias': tensor([-0.1295,  0.0185]), 'meta_learner.transductive_net.self_attention.in_proj_weight': tensor([[ 0.1060,  0.0349, -0.0215,  ...,  0.0448, -0.0228, -0.0507],\n        [-0.1490, -0.0730,  0.1017,  ..., -0.0767, -0.0933,  0.0579],\n        [-0.1221, -0.0587, -0.1579,  ..., -0.0744,  0.0839,  0.0264],\n        ...,\n        [-0.1253,  0.0583, -0.0224,  ..., -0.0516, -0.0895, -0.0303],\n        [-0.0666,  0.1473, -0.1409,  ..., -0.1419, -0.0264,  0.0348],\n        [-0.0126, -0.0050, -0.1165,  ...,  0.0807,  0.0787, -0.1124]]), 'meta_learner.transductive_net.self_attention.in_proj_bias': tensor([ 1.0184e-03, -9.9456e-03, -9.8727e-03, -3.4556e-03, -2.4290e-03,\n        -3.4427e-03, -7.7453e-03, -9.5480e-04, -1.1541e-03, -1.4132e-02,\n        -1.2984e-02, -4.3246e-03, -7.7823e-03,  3.4199e-03,  2.5159e-03,\n        -3.2318e-03, -2.8938e-03, -4.1477e-03,  4.8012e-03, -3.7557e-03,\n        -6.1250e-03,  6.5807e-03, -1.1702e-02,  3.9496e-03, -5.0236e-03,\n         3.3208e-03,  2.2222e-03,  2.4115e-03, -6.2164e-03, -4.1761e-03,\n         1.4414e-03,  1.1824e-02, -8.7831e-03, -2.7523e-03,  8.2362e-03,\n         5.4963e-03, -5.4249e-04, -1.2292e-04,  7.6699e-04,  5.0133e-03,\n         1.0568e-02, -8.5523e-03, -1.2575e-03, -5.3248e-03, -2.5930e-03,\n         1.0607e-02, -3.7691e-03,  1.7705e-03,  8.3029e-04, -1.4707e-03,\n        -4.7019e-03,  1.6875e-03, -4.1941e-03,  1.2583e-03, -8.9542e-03,\n         4.1416e-03, -7.2092e-04, -1.4038e-03, -3.7334e-04,  8.8421e-03,\n        -4.2896e-03,  1.0054e-02,  1.6647e-03,  6.5813e-03, -4.3616e-05,\n         2.4042e-05,  4.7534e-05, -1.4102e-05, -9.2723e-05, -3.1552e-05,\n        -3.4610e-05, -3.3447e-05,  3.6585e-05, -6.8949e-05, -5.3361e-05,\n        -1.5031e-05,  8.3008e-06,  1.7158e-05, -3.4036e-05,  1.3470e-04,\n        -6.9728e-05,  3.6133e-05, -8.4551e-05, -1.6501e-04, -4.5744e-06,\n         9.4551e-05, -8.7714e-05, -6.1604e-05,  2.2084e-05,  4.6664e-05,\n         2.5595e-05, -4.9814e-06,  2.6876e-05, -3.9493e-05, -4.0559e-05,\n         1.2219e-04, -4.5076e-05, -7.1095e-05,  9.1340e-05, -3.4925e-05,\n         1.9179e-04, -1.5389e-04,  9.1981e-05,  4.3366e-05, -2.3585e-06,\n        -6.7906e-05,  1.3724e-04, -7.8686e-05,  2.0542e-05, -3.5743e-05,\n         6.4350e-05, -7.6261e-05, -1.7272e-04, -1.9608e-06,  2.3638e-05,\n        -2.3114e-04,  2.6498e-05, -7.2027e-05, -2.4412e-05, -8.6472e-05,\n         1.0978e-04, -7.4479e-05,  2.0052e-04, -4.6320e-05, -9.7304e-05,\n        -1.5422e-04,  1.9646e-04, -1.8406e-05,  3.0074e-04,  2.0628e-04,\n        -5.6394e-04,  1.2588e-04,  1.1049e-04, -2.6887e-05,  5.2395e-04,\n         4.1356e-04,  4.6229e-04,  1.6423e-04,  1.7722e-04,  5.7114e-04,\n        -1.2205e-04,  2.9948e-04, -6.1877e-04, -2.7496e-04,  2.5535e-04,\n         6.4599e-04, -1.1872e-04,  4.9095e-04, -1.9084e-04,  1.9545e-04,\n        -4.8897e-04,  2.9452e-04, -3.5094e-04, -4.7838e-04, -5.8136e-04,\n        -1.8789e-04, -5.1706e-04, -1.6082e-04, -3.2092e-04, -1.0851e-04,\n         3.6471e-04,  3.1755e-04,  2.8286e-04,  4.3110e-04, -3.8470e-05,\n         1.1115e-04, -9.1999e-04,  1.7109e-04, -1.6025e-04,  4.4826e-04,\n        -2.8470e-04,  5.2532e-04, -4.8300e-05,  3.4990e-05, -6.9769e-04,\n         6.2672e-05,  4.7234e-04, -3.4590e-04,  6.4351e-04, -8.2468e-04,\n        -5.8182e-04,  8.8116e-05, -3.5537e-04, -2.4877e-04, -1.7114e-04,\n         5.0120e-04, -2.6942e-04, -8.5756e-05, -1.5348e-04, -1.7132e-04,\n         6.2251e-05, -3.6460e-04]), 'meta_learner.transductive_net.self_attention.out_proj.weight': tensor([[-0.1163,  0.0803, -0.1013,  ...,  0.1273, -0.0254,  0.1150],\n        [ 0.0220,  0.1239, -0.0489,  ..., -0.0822, -0.0118,  0.0243],\n        [ 0.0304,  0.1002, -0.0318,  ..., -0.1080, -0.0987, -0.0815],\n        ...,\n        [ 0.0694,  0.0111,  0.0077,  ...,  0.0236,  0.0916, -0.0299],\n        [ 0.0248, -0.0218, -0.1009,  ...,  0.0792,  0.1138, -0.0395],\n        [ 0.0115, -0.0536, -0.0909,  ..., -0.0188,  0.1224,  0.0304]]), 'meta_learner.transductive_net.self_attention.out_proj.bias': tensor([ 4.8119e-04,  1.5745e-06,  2.5803e-04, -2.8166e-04,  4.7136e-04,\n         1.9013e-04,  3.3563e-04, -7.1209e-05, -1.6919e-04, -1.7213e-04,\n        -2.3506e-04, -1.7046e-04,  2.8894e-04, -3.2769e-05,  6.1826e-04,\n        -4.6907e-05, -8.4432e-04, -1.1282e-04,  2.7377e-04, -4.0945e-04,\n        -4.2206e-04,  1.7223e-04,  1.2075e-04, -2.5573e-04,  5.7074e-04,\n         1.3833e-04,  3.8149e-04, -4.7768e-04,  1.5301e-04,  9.6462e-05,\n         5.7927e-04, -3.9589e-04,  5.2928e-05, -1.4493e-04, -1.7316e-04,\n        -2.1289e-04, -5.2645e-04,  4.4472e-05,  3.6168e-04,  2.3942e-04,\n         2.1432e-04,  1.2305e-04,  4.0033e-05, -8.0985e-05,  3.1449e-04,\n        -3.8797e-04,  1.0308e-04,  1.9851e-04,  4.8677e-04,  5.7344e-05,\n        -9.6432e-06, -3.1673e-04,  2.3206e-04,  1.2515e-04, -1.5016e-04,\n        -1.9798e-04, -1.3810e-04,  3.8057e-04,  8.5244e-04,  7.5044e-04,\n        -3.0751e-05,  5.0491e-05,  2.4631e-04, -2.3815e-04]), 'meta_learner.transductive_net.layer_norm.weight': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'meta_learner.transductive_net.layer_norm.bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}, sample_count=31148, training_loss=np.float64(0.08320440123145091), validation_accuracy=np.float64(0.8240000081062318), validation_precision=0.0, validation_recall=0.0, validation_f1_score=0.0, timestamp=1760224210.7856507, model_hash='6780dab943f17343976a9f45fe5385300ee20cba37323ac95b1ccb37c847f60a', ipfs_cid=None, blockchain_tx_hash=None)"
      ],
      "aggregation_result": "AggregationResult(round_number=0, aggregated_parameters={}, client_contributions={'client_1': 0.4425821849770329, 'client_2': 0.34976032853990413, 'client_3': 0.20765748648306298}, aggregation_time=0.0010039806365966797, model_hash='model_round_0_1760224222', ipfs_cid='Qmd1eJRkN2eWCmNNMbXoHZPMJ6aXgqbdq8Kb4MPU9Z2Ky2', blockchain_tx_hash='c0bfa810107ef03b94f293064e953b205466b09fd065bdd4662e437b35441a37')",
      "timestamp": 1760224225.2402894
    }
  ],
  "incentive_history": [],
  "client_addresses": {},
  "config": {
    "data_path": "../DNN-EdgeIIoT-dataset.csv",
    "zero_day_attack": "Password",
    "available_attacks": [
      "DDoS_UDP",
      "DDoS_ICMP",
      "SQL_injection",
      "Password",
      "Vulnerability_scanner",
      "DDoS_TCP",
      "DDoS_HTTP",
      "Uploading",
      "Backdoor",
      "Port_Scanning",
      "XSS",
      "Ransomware",
      "MITM",
      "Fingerprinting"
    ],
    "input_dim": 62,
    "hidden_dim": 128,
    "embedding_dim": 64,
    "use_fully_decentralized": false,
    "support_weight": 0.3,
    "test_weight": 0.7,
    "n_way": 2,
    "k_shot": 5,
    "n_query": 15,
    "n_tasks": 10,
    "num_clients": 3,
    "num_rounds": 1,
    "learning_rate": 0.001,
    "ethereum_rpc_url": "http://localhost:8545",
    "contract_address": "0x1234567890123456789012345678901234567890",
    "ipfs_url": "http://localhost:5001",
    "enable_incentives": true,
    "incentive_contract_address": "0x1234567890123456789012345678901234567890",
    "private_key": "0x1234567890123456789012345678901234567890123456789012345678901234",
    "aggregator_address": "0x1234567890123456789012345678901234567890",
    "batch_size": 32,
    "ttt_steps": 200,
    "support_size": 50,
    "query_size": 450,
    "device": "cuda",
    "enable_blockchain": true,
    "max_samples_per_client": 50000,
    "use_data_sampling": true
  }
}